{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Rustic AI Documentation","text":"<p>Welcome to the official documentation for Rustic AI, a powerful framework for building intelligent multi-agent systems in Python. Rustic AI provides a flexible, modular architecture for creating, deploying, and managing AI agents that can work together to solve complex problems.</p>"},{"location":"index.html#what-is-rustic-ai","title":"What is Rustic AI?","text":"<p>Rustic AI is designed to simplify the development of agent-based systems by providing:</p> <ul> <li>Guild-based Architecture: Organize agents into cohesive groups called \"guilds\" that work together toward common goals</li> <li>Dependency Injection: Easily configure and manage the resources your agents need</li> <li>State Management: Robust mechanisms for handling agent state across interactions</li> <li>Message Passing: Standardized communication between agents</li> <li>Extensibility: A plugin-based system that makes it easy to integrate with external services and AI providers</li> </ul> <p>Whether you're building a simple conversational assistant or a complex multi-agent system with specialized roles, Rustic AI provides the infrastructure you need to focus on your application logic rather than agent coordination.</p>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>New to Rustic AI? Here are the best places to begin:</p> <ul> <li>Core Concepts: Learn about the foundational architecture and concepts</li> <li>Creating Your First Agent: A step-by-step guide to building your first agent</li> <li>Creating a Guild: Learn how to organize multiple agents to work together</li> <li>Complete Client-Server Flow: Comprehensive guide for building client applications with proper API integration and real-time communication</li> </ul>"},{"location":"index.html#core-components","title":"Core Components","text":"<p>Rustic AI is built around these core components:</p> <ul> <li>Agents: The building blocks of intelligent systems that can perceive, reason, and act</li> <li>Guilds: Organized collections of agents working together toward common goals</li> <li>Messaging: Communication infrastructure for agents to exchange information<ul> <li>Socket Messaging Backend: Socket-based messaging for testing without external dependencies</li> </ul> </li> <li>Execution: How agent code gets executed within the Rustic AI framework<ul> <li>Multiprocess Execution: True parallel execution with process isolation</li> </ul> </li> <li>State Management: Managing persistence across agent interactions</li> <li>Dependencies: Resources and services that agents can access through dependency injection</li> </ul>"},{"location":"index.html#integrations","title":"Integrations","text":"<p>Rustic AI integrates with popular AI tools and services:</p> <ul> <li>LiteLLM: Unified interface for various LLM providers</li> <li>HuggingFace: Leverage HuggingFace models for text, image, and speech processing</li> <li>Playwright: Web automation and scraping capabilities</li> <li>SerpAPI: Web search integration for information retrieval</li> <li>Marvin: AI function calling and structured extraction</li> <li>Ray: Distributed and parallel execution</li> <li>Chroma: Vector database for semantic search</li> <li>Redis: Fast key-value storage for agent state</li> <li>LangChain: Utilities for working with language models</li> </ul>"},{"location":"index.html#api-reference","title":"API Reference","text":"<p>For detailed API information, check out the API Reference which provides comprehensive documentation of all public interfaces.</p>"},{"location":"index.html#showcase","title":"Showcase","text":"<p>Explore Example Applications to see Rustic AI in action and get inspiration for your own projects.</p>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>Rustic AI is an open-source project, and contributions are welcome! See our Contributing Guide to learn how you can help improve the framework. </p>"},{"location":"contributing.html","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing.html#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing.html#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/rustic-ai/python-framework/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing.html#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing.html#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing.html#write-documentation","title":"Write Documentation","text":"<p>Rustic AI could always use more documentation, whether as part of the official Rustic AI docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing.html#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/rustic-ai/python-framework/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project and that contributions   are welcome :)</li> </ul>"},{"location":"paper.html","title":"Rustic AI: A Framework for Modular and Collaborative Multi-Agent Systems","text":""},{"location":"paper.html#abstract","title":"Abstract","text":"<p>Rustic AI is a Python framework designed for building, deploying, and managing intelligent multi-agent systems (MAS). It emphasizes a modular, guild-based architecture to foster collaborative problem-solving among AI agents. Key features include robust dependency injection, comprehensive state management, standardized message passing, and a high degree of extensibility through various integrations with popular AI tools and services. Rustic AI aims to simplify the complexities inherent in developing sophisticated agent-based applications, empowering developers to create adaptive and scalable solutions for a wide range of challenges.</p>"},{"location":"paper.html#1-introduction","title":"1. Introduction","text":""},{"location":"paper.html#11-background","title":"1.1 Background","text":"<p>The rapid advancements in Artificial Intelligence (AI) have paved the way for increasingly sophisticated applications. Among these, Multi-Agent Systems (MAS) represent a powerful paradigm for tackling complex problems that are often beyond the capabilities of monolithic AI models. MAS involve multiple autonomous agents interacting within a shared environment, coordinating their actions to achieve common or individual goals.</p>"},{"location":"paper.html#12-challenges-in-multi-agent-system-development","title":"1.2 Challenges in Multi-Agent System Development","text":"<p>Developing robust and scalable MAS presents several challenges:</p> <ul> <li>Complexity: Designing, implementing, and managing the interactions of numerous autonomous agents can be exceedingly complex.</li> <li>Coordination: Ensuring effective communication, collaboration, and conflict resolution among agents is non-trivial.</li> <li>State Management: Maintaining consistent state across distributed agents and long-running interactions requires careful design.</li> <li>Integration: Incorporating diverse AI models, tools, and data sources into a cohesive system can be difficult.</li> <li>Scalability and Maintainability: As systems grow, ensuring they remain scalable and maintainable is crucial.</li> </ul>"},{"location":"paper.html#13-introducing-rustic-ai","title":"1.3 Introducing Rustic AI","text":"<p>Rustic AI is a framework engineered to address these challenges head-on. Its primary mission is to streamline the exploration and practical application of MAS across diverse domains. By offering a structured, adaptable, and developer-friendly platform, Rustic AI significantly simplifies the development, management, and deployment of complex agent-based systems.</p>"},{"location":"paper.html#14-evolution-of-agents-multi-agent-systems-and-llm-powered-agents","title":"1.4 Evolution of Agents, Multi-Agent Systems, and LLM-Powered Agents","text":"<p>The concept of autonomous agents and MAS has its roots in early AI research, aiming to solve intricate problems through distributed intelligence. Initially, agents ranged from simple reactive entities to more deliberative ones. The advent of Large Language Models (LLMs) has revolutionized the field, enabling the creation of highly capable, LLM-powered agents (e.g., AutoGPT, AgentGPT). These agents can perform complex reasoning, understand natural language, and generate human-like responses, drastically expanding the potential of MAS. Rustic AI is designed to harness these advancements, providing a robust framework for integrating LLMs and other AI technologies into collaborative multi-agent ensembles.</p>"},{"location":"paper.html#15-rustic-ais-vision","title":"1.5 Rustic AI's Vision","text":"<p>Rustic AI's vision is to empower developers and researchers to unlock the full potential of collective intelligence. We aim to provide a comprehensive yet flexible toolkit that accelerates innovation in autonomous AI, making the development of sophisticated multi-agent systems more accessible, manageable, and efficient.</p>"},{"location":"paper.html#2-core-concepts-of-rustic-ai","title":"2. Core Concepts of Rustic AI","text":"<p>Rustic AI is built upon a set of foundational concepts that define its architecture and operational paradigm.</p>"},{"location":"paper.html#21-agents","title":"2.1 Agents","text":"<p>In Rustic AI, an Agent is a computational entity designed to achieve specific goals within an environment, which may include other agents. Key characteristics of Rustic AI agents include:</p> <ul> <li>Autonomy: Agents can operate without constant human or system intervention, making decisions based on their perceived environment and internal state.</li> <li>Perception: Agents can perceive their environment through incoming messages and data streams.</li> <li>Decision-Making: Based on their programming and perceived information, agents make decisions to achieve their objectives.</li> <li>Action: Agents act upon their decisions, often by sending messages or interacting with external systems.</li> <li>Specialization: Agents are typically specialized to perform specific tasks or roles within a larger system (e.g., data retrieval, LLM interaction, user proxy).</li> <li>Statefulness: Agents can maintain internal state across interactions, allowing for memory and context awareness.</li> </ul> <p>The spectrum of agents in Rustic AI ranges from simple, rule-based components to advanced, adaptive entities that can learn and evolve their behavior. Each agent is defined by an <code>AgentSpec</code>, a declarative specification that outlines its class, properties, dependencies, and communication topics.</p>"},{"location":"paper.html#22-guilds","title":"2.2 Guilds","text":"<p>The Guild is the cornerstone of Rustic AI's architecture. A Guild is a logical grouping of agents that collaborate within a shared environment. It serves as a central hub for:</p> <ul> <li>Organizing Agents: Grouping functionally related agents into cohesive units to tackle specific tasks or workflows.</li> <li>Lifecycle Management: Controlling the registration, launching, execution, monitoring, and termination of its member agents.</li> <li>Coordinated Execution: Defining how agents run, leveraging various Execution Engines (e.g., synchronous, asynchronous, distributed).</li> <li>Message Orchestration: Facilitating communication and defining sophisticated interaction patterns between agents through a powerful Messaging System and routing rules.</li> <li>Shared Resources: Providing common Dependencies (like API clients or database connections) and State Management facilities to its member agents.</li> </ul> <p>A Guild is defined by a <code>GuildSpec</code>, a declarative blueprint typically specified in YAML or JSON, or constructed programmatically using the <code>GuildBuilder</code>. This specification details the guild's properties, its member agents (<code>AgentSpec</code> list), shared dependencies, and message routing logic.</p>"},{"location":"paper.html#23-multi-agent-systems-mas-in-rustic-ai","title":"2.3 Multi-Agent Systems (MAS) in Rustic AI","text":"<p>In Rustic AI, a Multi-Agent System is realized through one or more Guilds. Each Guild acts as a self-contained MAS or a component of a larger, interconnected system. Rustic AI's MAS approach emphasizes:</p> <ul> <li>Decentralized Control: While a Guild provides coordination, individual agents retain a degree of autonomy in their decision-making.</li> <li>Collective Intelligence: The system's overall intelligence and problem-solving capabilities emerge from the interactions and collaboration of its constituent agents.</li> <li>Modularity: Guilds and agents are modular components, allowing for flexible system design and composition.</li> </ul>"},{"location":"paper.html#24-autonomous-ai-with-rustic-ai","title":"2.4 Autonomous AI with Rustic AI","text":"<p>Rustic AI aims to facilitate the development of Autonomous AI systems. This encompasses individual agents and MAS capable of:</p> <ul> <li>Self-Guided Operation: Performing tasks and pursuing goals with minimal human intervention.</li> <li>Adaptive Decision-Making: Adjusting strategies based on new information and changing environmental conditions.</li> <li>Learning: Incorporating mechanisms for agents and guilds to learn from experience and improve performance over time. The framework provides the tools and abstractions necessary to build systems that exhibit varying degrees of autonomy, from human-supervised to fully autonomous operations.</li> </ul>"},{"location":"paper.html#3-rustic-ai-architecture-and-design","title":"3. Rustic AI Architecture and Design","text":"<p>Rustic AI's architecture is designed for modularity, flexibility, and scalability, enabling the construction of sophisticated multi-agent systems.</p>"},{"location":"paper.html#31-modular-architecture","title":"3.1 Modular Architecture","text":"<p>The framework is built around a core set of components primarily located within the <code>rustic_ai.core</code> package. These include modules for:</p> <ul> <li><code>messaging</code>: Handles inter-agent communication.</li> <li><code>state</code>: Manages agent and guild state.</li> <li><code>guild</code>: Defines the guild structure, lifecycle, and execution.</li> <li><code>agents</code>: Provides base classes and specifications for agents.</li> <li><code>utils</code>: Contains common utilities and helper functions.</li> <li><code>ui_protocol</code>: Defines standardized message formats for UI interaction.</li> </ul> <p>This modularity offers significant benefits:</p> <ul> <li>Isolation of Components: Individual modules can be developed, tested, and updated independently.</li> <li>Maintainability: Clear separation of concerns simplifies understanding and maintaining the codebase.</li> <li>Scalability: The modular design facilitates scaling by allowing different components to be distributed or optimized as needed.</li> <li>Ease of Modification and Extension: New functionalities, agent types, or integrations can be added without disrupting existing components.</li> </ul>"},{"location":"paper.html#32-guild-based-design","title":"3.2 Guild-based Design","text":""},{"location":"paper.html#321-guild-lifecycle-and-management","title":"3.2.1 Guild Lifecycle and Management","text":"<p>The lifecycle of a Guild in Rustic AI involves several stages:</p> <ol> <li>Definition (<code>GuildSpec</code>): The Guild's structure is defined in a <code>GuildSpec</code>. This can be a YAML/JSON file or created programmatically using <code>GuildBuilder</code>, <code>AgentBuilder</code>, and <code>RouteBuilder</code>.  <pre><code>from rustic_ai.core.guild.builders import GuildBuilder, AgentBuilder\n# Example:\n# agent_spec = AgentBuilder(MyAgentClass).set_name(\"my_agent\").build_spec()\n# guild_spec = GuildBuilder(\"MyGuild\").add_agent_spec(agent_spec).build_spec()\n</code></pre></li> <li>Instantiation and Launching Agents:  - <code>GuildBuilder.launch(org_id=\"myawesomeorgid\")</code>: For development and testing, this method creates a <code>Guild</code> instance and launches all its agents directly in the current environment.  - <code>GuildBuilder.bootstrap(metastore_database_url: str,org_id=\"myawesomeorgid\")</code>: For production, this method creates a <code>Guild</code> instance and launches a <code>GuildManagerAgent</code>. This system agent persists the <code>GuildSpec</code> and manages the lifecycle of other agents, enabling more robust and potentially distributed deployments.</li> <li>Interaction: Launched agents communicate via messages, orchestrated by the Guild's defined routes and messaging system.</li> <li>Shutdown: <code>guild.shutdown()</code> is used for guilds launched via <code>launch()</code>. For bootstrapped guilds, shutdown is typically managed by the environment hosting the <code>GuildManagerAgent</code>.</li> </ol>"},{"location":"paper.html#322-execution-engines","title":"3.2.2 Execution Engines","text":"<p>Guilds utilize Execution Engines to manage how agents are run. Rustic AI supports various modes, including:</p> <ul> <li>Synchronous Execution: Agents run sequentially, often used for debugging or simple workflows.</li> <li>Multithreaded Execution: Agents run in separate threads, allowing for concurrent operation.</li> <li>Distributed Execution (e.g., via Ray): Agents can be distributed across multiple processes or machines for scalability. The desired execution engine is typically specified in the <code>GuildSpec.properties</code>.</li> </ul>"},{"location":"paper.html#33-messaging-system","title":"3.3 Messaging System","text":"<p>Effective communication is vital in MAS. Rustic AI's messaging system provides:</p> <ul> <li>MessageBus: A foundational layer (often an in-memory queue or a more robust backend like Redis) that facilitates message exchange between agents.</li> <li>Standardized Message Formats: While agents can use custom Pydantic models for payloads, Rustic AI also provides <code>ui_protocol</code> types for common interactions, especially with user interfaces. Each message includes sender, recipient, topic, and payload.</li> <li>Publish/Subscribe: Agents can publish messages to specific topics and subscribe to topics of interest.</li> <li>RoutingSlips and RoutingRules: A powerful mechanism within <code>GuildSpec</code> to define how messages are processed and forwarded. This allows for:</li> <li>Content-Based Routing: Directing messages based on their content or type.</li> <li>Sequential Processing: Defining multi-step workflows (A -&gt; B -&gt; C).</li> <li>Message Transformation: Modifying message payloads between agents to ensure compatibility.</li> <li>Fan-out/Fan-in: Distributing a message to multiple agents and potentially aggregating their responses.</li> </ul>"},{"location":"paper.html#34-state-management","title":"3.4 State Management","text":"<p>Rustic AI provides robust mechanisms for managing state at both the agent and guild levels:</p> <ul> <li>Agent State: Each agent can maintain its own internal state, which can persist across multiple interactions or its entire lifecycle.</li> <li>Guild State: Guilds can have shared state accessible to their member agents.</li> <li>Persistence: The framework allows for state to be persisted using various backends (e.g., in-memory, Redis, databases), ensuring data is not lost between sessions or in case of restarts. This is configured via Dependency Injection.</li> </ul>"},{"location":"paper.html#35-dependency-injection","title":"3.5 Dependency Injection","text":"<p>Rustic AI features a sophisticated dependency injection system that simplifies the management of resources and services agents need:</p> <ul> <li><code>DependencySpec</code>: Defines how a dependency (e.g., an API client, a database connection, a configuration object) should be resolved and instantiated.</li> <li>Resolvers: Custom classes that know how to create and provide instances of specific dependencies.</li> <li>Guild-Level Dependencies: Defined in <code>GuildSpec.dependency_map</code>, these are available to all agents within the guild.</li> <li>Agent-Specific Dependencies: Can be defined in <code>AgentSpec.dependency_map</code>, overriding guild-level dependencies if names conflict. This system promotes loose coupling and makes agents more reusable and testable by decoupling them from the concrete implementation of their dependencies.</li> </ul>"},{"location":"paper.html#36-extensibility-and-integrations","title":"3.6 Extensibility and Integrations","text":"<p>Rustic AI is designed for extensibility:</p> <ul> <li>Plugin-Based System: The architecture allows for easy integration of new agent types, execution engines, messaging backends, and dependency resolvers.</li> <li>Rich Set of Integrations: Rustic AI comes with built-in support for a variety of popular AI tools and services, including:</li> <li>LLM Providers: LiteLLM for a unified interface to various LLMs (OpenAI, Anthropic, Cohere, HuggingFace models, etc.).</li> <li>HuggingFace: Direct integration with HuggingFace models for tasks like text generation (e.g., LLMPhiAgent), image generation (Stable Diffusion), image-to-image, speech-to-text, and NLP (SQuAD).</li> <li>Web Automation: PlaywrightScraperAgent for web scraping and browser automation.</li> <li>Web Search: SERPAgent for accessing search engine results.</li> <li>AI Function Calling: MarvinAgent for structured data extraction and AI function calling.</li> <li>Distributed Computing: Ray for distributed and parallel execution of agents and guilds.</li> <li>Vector Databases: Chroma for semantic search and document indexing (e.g., used by <code>VectorAgent</code>).</li> <li>Key-Value Stores: Redis for fast state management and messaging backends.</li> <li>Language Model Utilities: LangChain components for text splitting, embeddings, etc.</li> </ul>"},{"location":"paper.html#4-key-features-and-capabilities","title":"4. Key Features and Capabilities","text":""},{"location":"paper.html#41-addressing-complex-challenges-with-mas","title":"4.1 Addressing Complex Challenges with MAS","text":"<p>Rustic AI's architecture enables MAS to tackle complex problems effectively:</p> <ol> <li>Distributed Problem-Solving: Agents can operate in dispersed environments, coordinating locally and globally.</li> <li>Scalability: Distributes computational tasks among agents, handling large-scale challenges more effectively than monolithic models.</li> <li>Real-Time Adaptability: Agents can respond dynamically to changes in the environment or incoming data.</li> <li>Diverse Expertise Integration: Combines agents with varied knowledge, skills, and access to different tools/APIs for comprehensive solutions.</li> <li>Multi-Objective Optimization: Collaborative and sometimes competitive agent interactions allow exploration of broad solution spaces.</li> <li>Robustness and Fault Tolerance: The decentralized nature can enhance resilience; failure of one agent may not cripple the entire system.</li> <li>Complex and Long-Term Task Management: Suitable for tasks requiring persistent coordination over extended periods.</li> <li>Optimized Human-in-the-Loop Systems: Facilitates intelligent distribution of sub-tasks, reducing human cognitive load and enabling intuitive human-agent collaboration.</li> </ol>"},{"location":"paper.html#42-human-in-the-loop-interaction","title":"4.2 Human-in-the-Loop Interaction","text":"<p>Rustic AI explicitly supports human involvement in agent workflows. The <code>UserProxyAgent</code> serves as a typical interface between human users and a guild, allowing users to submit tasks, provide feedback, and review agent outputs. Humans can also be modeled as specialized agents within a guild, contributing their unique expertise to the decision-making process.</p>"},{"location":"paper.html#43-continuous-learning-and-adaptation","title":"4.3 Continuous Learning and Adaptation","text":"<p>While Rustic AI provides the framework, the implementation of continuous learning is often agent-specific or guild-specific. Key enablers include:</p> <ul> <li>Memory Management: Agents can be designed with short-term and long-term memory capabilities. Shared state and persistent storage (e.g., vector databases for contextual information) allow guilds to maintain historical context, crucial for learning and adaptation.</li> <li>Feedback Mechanisms: Routing rules can be set up to direct feedback (from humans or other agents) to learning components within agents.</li> <li>Evolving Guilds: The <code>GuildManagerAgent</code> can potentially update guild specifications or agent configurations based on performance metrics or new requirements, allowing guilds to evolve over time.</li> </ul>"},{"location":"paper.html#44-development-and-testing","title":"4.4 Development and Testing","text":"<p>Rustic AI prioritizes a good developer experience:</p> <ul> <li>Simplified Setup: <code>GuildBuilder</code> and <code>AgentBuilder</code> provide a fluent API for programmatically defining guilds and agents. YAML/JSON specifications offer a declarative alternative.</li> <li>How-To Guides: Documentation includes step-by-step guides for Creating Your First Agent, Creating a Guild, Dependency Injection, and more.</li> <li>Testing Utilities:</li> <li>The <code>ProbeAgent</code> is a specialized agent for testing, allowing developers to monitor and assert message flows and agent interactions within a guild.</li> <li>Comprehensive guides on Testing Agents and Writing Effective Agent Tests are provided.</li> </ul>"},{"location":"paper.html#5-use-cases-and-applications","title":"5. Use Cases and Applications","text":"<p>Rustic AI's flexible architecture makes it suitable for a wide array of applications.</p>"},{"location":"paper.html#51-example-1-anti-fraud-multi-agent-system-for-financial-transaction-monitoring","title":"5.1 Example 1: Anti-Fraud Multi-Agent System for Financial Transaction Monitoring","text":"<p>Overview: In finance, robust fraud detection is critical. An Anti-Fraud Multi-Agent System (AFMAS) built with Rustic AI can provide real-time surveillance and analysis to identify and prevent fraudulent transactions.</p> <p>Guild Composition &amp; System Architecture:</p> <ul> <li><code>UserProxyAgent</code>: Interface for fraud analysts to interact with the system, review alerts, and provide feedback.</li> <li><code>LiteLLMAgent</code> (or specialized NLP agent): To analyze textual data associated with transactions or alerts, generate summaries for analysts.</li> <li><code>PlaywrightScraperAgent</code> / <code>SERPAgent</code> (as External Data Agents - EDA): To fetch external information (e.g., checking blacklists, verifying merchant details).</li> <li>Custom Anomaly Detection Agent (TMA/HAA/UBA combined): A core agent implementing machine learning models to:</li> <li>Monitor transactions in real-time (TMA functionality).</li> <li>Analyze historical transaction data for patterns linked to fraud (HAA functionality).</li> <li>Analyze user behavior to detect unusual activities (UBA functionality). This agent might use dependencies like a vector database or a feature store.</li> <li>Response Agent (RA): An agent that takes action upon confirmed fraud detection (e.g., sends alerts, triggers account suspension via an API call).</li> <li><code>GuildManagerAgent</code>: (If deployed in a production setup) Manages the lifecycle of the fraud detection guild.</li> <li>Shared Dependencies: Connections to transaction databases, customer databases, fraud model registries, alert systems.</li> </ul> <p>Operational Flow:</p> <ol> <li>Data Ingestion: Transaction data streams into the Anomaly Detection Agent.</li> <li>Real-Time Analysis: The Anomaly Detection Agent scrutinizes each transaction against risk models, historical patterns, and user behavior baselines. EDAs provide supplementary external data.</li> <li>Alert Generation: Suspicious transactions are flagged, and alerts are generated. The LLM Agent might enrich these alerts with contextual information.</li> <li>Analyst Review: Alerts are routed to the <code>UserProxyAgent</code> for human review. Analysts investigate and confirm or dismiss fraud.</li> <li>Response Execution: If fraud is confirmed, the <code>UserProxyAgent</code> (or an automated rule) instructs the Response Agent to take appropriate action.</li> <li>Continuous Learning: Analyst feedback and new fraud patterns are used to retrain and refine the Anomaly Detection Agent's models.</li> </ol> <p>Benefits: Real-time detection, scalability to handle high transaction volumes, adaptability through model updates, holistic analysis by integrating diverse data, and cost-effectiveness through automation.</p>"},{"location":"paper.html#52-example-2-research-paper-development-guild","title":"5.2 Example 2: Research Paper Development Guild","text":"<p>Scenario: A guild to assist in developing a comprehensive research paper on a complex topic.</p> <p>Guild Composition:</p> <ul> <li><code>UserProxyAgent</code> (Lead Researcher): User defines research goals, queries, reviews drafts, and approves content.</li> <li><code>SERPAgent</code> (Information Retriever): Executes web searches based on research queries to find relevant articles, papers, and data sources.</li> <li><code>PlaywrightScraperAgent</code> (Content Extractor): Scrapes detailed information from web pages identified by the <code>SERPAgent</code>.</li> <li><code>VectorAgent</code> (Knowledge Base Manager): Indexes retrieved documents and enables semantic search over the collected research material.</li> <li><code>LiteLLMAgent</code> (Content Generator &amp; Summarizer):</li> <li>Drafts sections of the paper based on research material and user instructions.</li> <li>Summarizes lengthy articles or findings.</li> <li>Revises content based on feedback.</li> <li>Custom Formatting/Reference Agent (Tool Bot): Manages citations and ensures the paper adheres to specified formatting guidelines. This could be a simpler agent invoking existing libraries.</li> </ul> <p>Workflow:</p> <ol> <li>Initiation: The Lead Researcher (via <code>UserProxyAgent</code>) defines the research topic and initial queries.</li> <li>Information Gathering: Queries are routed to <code>SERPAgent</code>. Results are passed to <code>PlaywrightScraperAgent</code> for content extraction.</li> <li>Knowledge Base Construction: Extracted content is indexed by <code>VectorAgent</code>.</li> <li>Drafting &amp; Analysis: The Lead Researcher queries the <code>VectorAgent</code> or instructs <code>LiteLLMAgent</code> to draft sections using the knowledge base.</li> <li>Review &amp; Refinement: The Lead Researcher reviews drafts, provides feedback, and requests revisions from <code>LiteLLMAgent</code>.</li> <li>Formatting &amp; Finalization: The Formatting/Reference Agent assists with citations and formatting. The Lead Researcher conducts a final review. The guild's routing slip would manage the flow of information between these specialized agents.</li> </ol>"},{"location":"paper.html#53-example-3-customer-support-ticket-resolution-guild","title":"5.3 Example 3: Customer Support Ticket Resolution Guild","text":"<p>Scenario: A guild to efficiently categorize, analyze, and respond to customer support tickets.</p> <p>Guild Composition:</p> <ul> <li><code>UserProxyAgent</code> (Customer/Support Agent Interface): Allows customers to submit tickets and support agents to review and manage them.</li> <li>Custom Ticket Ingestion Agent: Receives new tickets from various channels (email, web form) and standardizes them.</li> <li><code>MarvinAgent</code> or <code>LiteLLMAgent</code> (Ticket Categorizer &amp; Prioritizer): Analyzes ticket content to categorize the issue, assess urgency, and route it appropriately.</li> <li><code>VectorAgent</code> (Knowledge Base Searcher): Searches existing documentation, FAQs, and past ticket resolutions for potential solutions.</li> <li><code>LiteLLMAgent</code> (Response Generator): Drafts responses to customers based on information from the knowledge base or instructions from a human agent.</li> <li>Human Support Agent (specialized agent or role via <code>UserProxyAgent</code>): Handles complex tickets, approves AI-generated responses, and provides expert assistance.</li> <li>Shared Dependencies: Access to CRM, knowledge base, ticketing system.</li> </ul> <p>Workflow:</p> <ol> <li>Ticket Ingestion &amp; Categorization: New tickets are ingested and then categorized and prioritized by an LLM/Marvin agent.</li> <li>Automated Solution Search: The <code>VectorAgent</code> searches the knowledge base for relevant solutions based on the ticket category and content.</li> <li>Response Generation: If a high-confidence solution is found, <code>LiteLLMAgent</code> drafts a response.</li> <li>Human Review/Handling:  - AI-drafted responses may be sent to a human support agent for review and approval via the <code>UserProxyAgent</code>.  - Complex tickets or those without automated solutions are routed directly to human agents.</li> <li>Communication: Approved responses are sent to the customer.</li> <li>Knowledge Base Update: New solutions or resolutions provided by human agents can be used to update the knowledge base, improving future automated responses.</li> </ol>"},{"location":"paper.html#6-getting-started-and-developer-experience","title":"6. Getting Started and Developer Experience","text":"<p>Rustic AI is designed to be accessible to developers familiar with Python.</p> <ul> <li>Installation: Typically via pip: <code>pip install rustic-ai-core</code> (and any additional packages for specific agents or integrations).</li> <li>Key Documentation:</li> <li>Core Concepts: Essential for understanding the foundational architecture.</li> <li>How-To Guides: Practical step-by-step tutorials (e.g., creating agents/guilds, dependency injection, testing).</li> <li>API Reference: Detailed documentation of public interfaces.</li> <li>Example Applications: Real-world examples and inspiration.</li> <li><code>GuildBuilder</code> and <code>AgentBuilder</code>: These fluent builder APIs simplify the programmatic definition of guilds and agents, reducing boilerplate and improving readability.</li> <li>Declarative Specifications: YAML or JSON <code>GuildSpec</code> and <code>AgentSpec</code> files offer a declarative way to define system structure, promoting clarity and ease of management.</li> </ul>"},{"location":"paper.html#7-community-open-source-and-future-directions","title":"7. Community, Open Source, and Future Directions","text":""},{"location":"paper.html#71-community-engagement-and-contributions","title":"7.1 Community Engagement and Contributions","text":"<p>Rustic AI is an open-source project that thrives on community involvement. We encourage contributions in the form of:</p> <ul> <li>Code (new features, bug fixes, new agents, integrations).</li> <li>Documentation improvements.</li> <li>Examples and use cases.</li> <li>Feedback and suggestions. Community forums and GitHub are the primary channels for engagement.</li> </ul>"},{"location":"paper.html#72-embracing-open-source-development","title":"7.2 Embracing Open Source Development","text":"<p>Our commitment to an open-source model (typically Apache 2.0 or MIT license) fosters innovation, transparency, and collaboration. It allows developers and organizations worldwide to use, modify, and contribute to Rustic AI, leading to rapid iterations and diverse perspectives that enrich the framework.</p>"},{"location":"paper.html#73-roadmap-and-future-directions","title":"7.3 Roadmap and Future Directions","text":"<p>Rustic AI is continuously evolving. Potential future directions include:</p> <ul> <li>Enhanced Agent Capabilities: More sophisticated planning, reasoning, and learning algorithms for agents.</li> <li>Advanced Guild Coordination: More complex routing patterns, dynamic guild formation, and inter-guild communication protocols.</li> <li>Expanded Integrations: Support for new AI models, data sources, and platforms.</li> <li>Improved Observability and Management Tools: Enhanced dashboards, metrics, and control planes for managing large-scale MAS deployments.</li> <li>Simplified User Experience: Further abstractions and tools to make MAS development even more accessible.</li> <li>Standardization: Efforts towards standardizing agent communication and interaction protocols to foster interoperability.</li> </ul>"},{"location":"paper.html#8-conclusion","title":"8. Conclusion","text":"<p>Rustic AI provides a powerful, flexible, and developer-friendly framework for building the next generation of intelligent multi-agent systems. Its modular architecture, centered around the Guild concept, combined with robust features like dependency injection, state management, and a rich messaging system, addresses many of the complexities traditionally associated with MAS development.</p> <p>By simplifying the creation, deployment, and management of collaborative AI agents, Rustic AI empowers developers and researchers to tackle intricate problems, automate complex workflows, and unlock new frontiers in autonomous AI. As the field of AI continues to advance, frameworks like Rustic AI will play a crucial role in harnessing the power of collective intelligence to build more adaptive, resilient, and capable systems.</p>"},{"location":"paper.html#9-references","title":"9. References","text":"<ul> <li>Rustic AI GitHub Repository: https://github.com/rusticai/ (or the specific URL if different)</li> <li>Rustic AI Official Documentation: (Link to the root of the docs site)</li> <li>(Optionally, include links to relevant academic papers or foundational concepts if appropriate for a whitepaper). </li> </ul>"},{"location":"agents/index.html","title":"Rustic AI Agents Documentation","text":"<p>Welcome to the Rustic AI Agents documentation. This section provides detailed information about the agents available in the Rustic AI framework.</p>"},{"location":"agents/index.html#what-is-an-agent","title":"What is an Agent?","text":"<p>In Rustic AI, an agent is a specialized component that performs specific tasks within a guild (multi-agent system). Each agent:</p> <ul> <li>Processes specific types of messages</li> <li>Maintains its own state</li> <li>Can interact with external services</li> <li>Communicates with other agents through a message-based system</li> </ul>"},{"location":"agents/index.html#available-agents","title":"Available Agents","text":"<p>Rustic AI includes several specialized agents for various tasks:</p>"},{"location":"agents/index.html#web-and-api-agents","title":"Web and API Agents","text":"<ul> <li>PlaywrightScraperAgent - Web scraping using Playwright</li> <li>SERPAgent - Search engine results via SerpAPI</li> </ul>"},{"location":"agents/index.html#language-model-agents","title":"Language Model Agents","text":"<ul> <li>LiteLLMAgent - Interface to various LLMs via LiteLLM</li> <li>SimpleLLMAgent - Basic LLM agent implementation</li> <li>LLMPhiAgent - Interface to Phi-2 language model</li> </ul>"},{"location":"agents/index.html#ai-media-generation","title":"AI Media Generation","text":"<ul> <li>RunwaymlStableDiffusionAgent - Image generation using Stable Diffusion</li> <li>Image2ImageAgent - Image-to-image transformation with Pix2Pix</li> <li>SpeechT5TTSAgent - Text-to-speech synthesis</li> </ul>"},{"location":"agents/index.html#nlp-agents","title":"NLP Agents","text":"<ul> <li>SquadAgent - Question answering using the SQuAD model</li> <li>MarvinAgent - Classification and data extraction</li> </ul>"},{"location":"agents/index.html#utility-agents","title":"Utility Agents","text":"<ul> <li>VectorAgent - Document indexing and similarity search</li> <li>ProbeAgent - Testing utility for monitoring agent interactions</li> </ul>"},{"location":"agents/index.html#system-agents","title":"System Agents","text":"<ul> <li>UserProxyAgent - Interface between users and the guild</li> <li>GuildManagerAgent - Manages guild state and operations</li> </ul>"},{"location":"agents/index.html#creating-custom-agents","title":"Creating Custom Agents","text":"<p>For guidance on creating your own agents, see the Creating Your First Agent guide. </p>"},{"location":"agents/core/index.html","title":"Core Agents","text":"<p>Rustic AI provides several built-in agents as part of the core package. These agents serve as foundational components for building more complex agent systems or can be used directly in your applications.</p>"},{"location":"agents/core/index.html#available-core-agents","title":"Available Core Agents","text":"<ul> <li>GuildManagerAgent - A system agent that manages the lifecycle of guilds and their agents</li> <li>UserProxyAgent - Represents human users within the agent ecosystem</li> <li>VectorAgent - Provides vector operations for semantic search and retrieval</li> <li>SimpleLLMAgent - A basic agent for integrating with language models</li> <li>ProbeAgent - A utility agent for testing and monitoring</li> </ul>"},{"location":"agents/core/index.html#using-core-agents","title":"Using Core Agents","text":"<p>Core agents can be incorporated into your guild directly by referencing their class paths in your guild specification. They provide essential functionality that many applications need out of the box.</p> <p>For custom use cases, these agents can serve as examples or be extended to create more specialized behavior.</p> <p>See the individual agent documentation pages for detailed information on each agent's capabilities and configuration options. </p>"},{"location":"agents/core/guild_manager_agent.html","title":"GuildManagerAgent","text":"<p>The <code>GuildManagerAgent</code> is a system agent responsible for managing guild-level operations, agent lifecycle management, and guild state coordination.</p>"},{"location":"agents/core/guild_manager_agent.html#purpose","title":"Purpose","text":"<p>This agent acts as a central coordinator for a Rustic AI guild, providing administrative functionality for managing agents, monitoring guild health, and handling system-level operations.</p>"},{"location":"agents/core/guild_manager_agent.html#when-to-use","title":"When to Use","text":"<p>The <code>GuildManagerAgent</code> is automatically added to every guild by default and should not typically be manually added. It's used internally by the guild system to:</p> <ul> <li>Manage agent lifecycle (creation, deletion)</li> <li>Maintain guild-level state</li> <li>Respond to system events</li> <li>Monitor guild health</li> <li>Provide guild introspection capabilities</li> </ul>"},{"location":"agents/core/guild_manager_agent.html#configuration","title":"Configuration","text":"<p>The <code>GuildManagerAgent</code> is configured through the <code>GuildManagerAgentProps</code> class, which has these properties:</p> <pre><code>class GuildManagerAgentProps(BaseAgentProps):\n    guild_id: str  # ID of the guild this agent manages\n    enable_agent_management: bool = True  # Whether agent lifecycle management is enabled\n    auto_restart_agents: bool = False  # Whether to auto-restart failed agents\n    health_check_interval: Optional[int] = None  # Seconds between health checks\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/core/guild_manager_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/core/guild_manager_agent.html#useragentcreationrequest","title":"UserAgentCreationRequest","text":"<p>A request to create a new user agent:</p> <pre><code>class UserAgentCreationRequest(BaseModel):\n    user_id: str  # ID of the user to create an agent for\n    default_target: Optional[str] = None  # Default target agent for user messages\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#guildstaterequest","title":"GuildStateRequest","text":"<p>A request for the current state of the guild:</p> <pre><code>class GuildStateRequest(BaseModel):\n    include_agents: bool = True  # Whether to include agent information\n    include_topics: bool = True  # Whether to include topic information\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#agentlifecyclerequest","title":"AgentLifecycleRequest","text":"<p>A request to manage agent lifecycle:</p> <pre><code>class AgentLifecycleRequest(BaseModel):\n    operation: AgentLifecycleOperation  # Operation to perform (CREATE, DELETE, RESTART)\n    agent_spec: Optional[AgentSpec] = None  # Agent specification for creation\n    agent_id: Optional[str] = None  # Agent ID for operations on existing agents\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/core/guild_manager_agent.html#useragentcreationresponse","title":"UserAgentCreationResponse","text":"<p>Response to a user agent creation request:</p> <pre><code>class UserAgentCreationResponse(BaseModel):\n    status: ResponseStatus  # Status of the operation\n    user_id: str  # ID of the user\n    agent_id: Optional[str] = None  # ID of the created agent\n    message: Optional[str] = None  # Additional information\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#guildstateresponse","title":"GuildStateResponse","text":"<p>Response with guild state information:</p> <pre><code>class GuildStateResponse(BaseModel):\n    guild_id: str  # ID of the guild\n    agents: Optional[List[AgentInfo]] = None  # Information about guild agents\n    topics: Optional[List[str]] = None  # Topics in the guild\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#agentlifecycleresponse","title":"AgentLifecycleResponse","text":"<p>Response to an agent lifecycle request:</p> <pre><code>class AgentLifecycleResponse(BaseModel):\n    operation: AgentLifecycleOperation  # The operation that was performed\n    status: ResponseStatus  # Status of the operation\n    agent_id: Optional[str] = None  # ID of the affected agent\n    message: Optional[str] = None  # Additional information\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#behavior","title":"Behavior","text":""},{"location":"agents/core/guild_manager_agent.html#agent-management","title":"Agent Management","text":"<ol> <li>The agent receives agent lifecycle requests (create, delete, restart)</li> <li>It validates the request against guild policies</li> <li>It performs the requested operation</li> <li>It returns a response indicating success or failure</li> </ol>"},{"location":"agents/core/guild_manager_agent.html#user-agent-creation","title":"User Agent Creation","text":"<ol> <li>The agent receives a request to create a user proxy agent</li> <li>It generates a unique ID for the new agent</li> <li>It creates and launches a UserProxyAgent with the specified parameters</li> <li>It returns the ID of the created agent</li> </ol>"},{"location":"agents/core/guild_manager_agent.html#guild-state-reporting","title":"Guild State Reporting","text":"<ol> <li>The agent receives a guild state request</li> <li>It collects information about the guild's agents and topics</li> <li>It returns the compiled information in a structured format</li> </ol>"},{"location":"agents/core/guild_manager_agent.html#health-monitoring","title":"Health Monitoring","text":"<ol> <li>Periodically (if configured), the agent performs health checks on all agents</li> <li>Agents that fail health checks may be restarted (if auto_restart is enabled)</li> <li>Health status is published to the guild</li> </ol>"},{"location":"agents/core/guild_manager_agent.html#sample-usage","title":"Sample Usage","text":"<p>Since the <code>GuildManagerAgent</code> is automatically included in guilds, you typically interact with it through messages:</p> <pre><code>from rustic_ai.core.agents.system.models import UserAgentCreationRequest\n\n# Create a request to create a user proxy agent\nrequest = UserAgentCreationRequest(\n    user_id=\"user-123\",\n    default_target=\"llm_agent\"\n)\n\n# Send to the guild manager agent\nclient.publish(\n    \"default_topic\", \n    request, \n    recipient=GuildTopics.GUILD_MANAGER\n)\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#customizing-the-guild-manager","title":"Customizing the Guild Manager","text":"<p>If you need to customize the GuildManagerAgent, you can replace the default instance when creating a guild:</p> <pre><code>from rustic_ai.core.guild.builders import AgentBuilder, GuildBuilder\nfrom rustic_ai.core.agents.system.guild_manager_agent import GuildManagerAgent, GuildManagerAgentProps\n\n# Create a custom guild manager specification\ncustom_manager_spec = (\n    AgentBuilder(GuildManagerAgent)\n    .set_id(GuildTopics.GUILD_MANAGER)\n    .set_name(\"Custom Guild Manager\")\n    .set_description(\"Guild manager with custom configuration\")\n    .set_properties(\n        GuildManagerAgentProps(\n            guild_id=\"my_guild\",\n            enable_agent_management=True,\n            auto_restart_agents=True,\n            health_check_interval=60  # Check health every minute\n        )\n    )\n    .build_spec()\n)\n\n# Create a guild with the custom manager\nguild = (\n    GuildBuilder(\"my_guild\", \"My Guild\", \"A guild with custom manager\")\n    .set_guild_manager_spec(custom_manager_spec)\n    .launch(org_id=\"myawesomeorgid\")\n)\n</code></pre>"},{"location":"agents/core/guild_manager_agent.html#security-considerations","title":"Security Considerations","text":"<p>The <code>GuildManagerAgent</code> has privileged access to guild operations. In production environments:</p> <ol> <li>Ensure that access to the guild manager is properly authenticated</li> <li>Restrict which agents can send lifecycle management requests</li> <li>Consider disabling agent management if not needed</li> <li>Monitor guild manager activity for security events</li> </ol>"},{"location":"agents/core/guild_manager_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>The GuildManagerAgent is essential for guild operation and should not be removed</li> <li>Direct agent manipulation outside the guild manager may cause inconsistencies</li> <li>For production systems, consider how agent lifecycles intersect with your application's security model</li> <li>The default GuildManagerAgent does not persist agent configurations across restarts </li> </ul>"},{"location":"agents/core/probe_agent.html","title":"ProbeAgent","text":"<p>The <code>ProbeAgent</code> is a specialized utility agent used for testing and debugging agent interactions within a Rustic AI guild. It captures messages, allows sending test messages, and provides inspection capabilities.</p>"},{"location":"agents/core/probe_agent.html#purpose","title":"Purpose","text":"<p>This agent serves as a powerful testing tool that can: - Record all messages it receives - Send messages to other agents - Inspect message flow within a guild - Simulate interactions for integration testing - Aid in debugging complex multi-agent systems</p>"},{"location":"agents/core/probe_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>ProbeAgent</code> when you need to:</p> <ul> <li>Write tests for agent interactions</li> <li>Debug message flow in a guild</li> <li>Monitor communication between agents</li> <li>Simulate external inputs to the guild</li> <li>Validate agent responses</li> </ul>"},{"location":"agents/core/probe_agent.html#properties","title":"Properties","text":"<p>The <code>ProbeAgent</code> does not require any special configuration properties.</p>"},{"location":"agents/core/probe_agent.html#capabilities","title":"Capabilities","text":"<p>The <code>ProbeAgent</code> provides several key capabilities:</p>"},{"location":"agents/core/probe_agent.html#1-message-capturing","title":"1. Message Capturing","text":"<p>All messages sent to the probe agent are stored and can be retrieved for inspection:</p> <pre><code># Get all messages received by the probe\nmessages = probe_agent.get_messages()\n\n# Get messages of a specific format\nchat_messages = probe_agent.get_messages_of_format(SimpleChatMessage)\n</code></pre>"},{"location":"agents/core/probe_agent.html#2-message-publishing","title":"2. Message Publishing","text":"<p>The probe can send messages to other agents:</p> <pre><code># Publish a message to a topic\nprobe_agent.publish(\"default_topic\", some_message)\n\n# Publish a dictionary as a message with a specific format\nprobe_agent.publish_dict(\n    \"default_topic\",\n    {\"content\": \"Hello, world!\"},\n    format=SimpleChatMessage\n)\n</code></pre>"},{"location":"agents/core/probe_agent.html#3-message-clearing","title":"3. Message Clearing","text":"<p>The message history can be cleared:</p> <pre><code># Clear all captured messages\nprobe_agent.clear_messages()\n</code></pre>"},{"location":"agents/core/probe_agent.html#sample-usage-in-tests","title":"Sample Usage in Tests","text":"<pre><code>import pytest\nimport time\n\nfrom rustic_ai.core.guild.builders import GuildBuilder, AgentBuilder\nfrom rustic_ai.core.agents.testutils.probe_agent import ProbeAgent\nfrom rustic_ai.core.agents.llm.simple_llm_agent import SimpleLLMAgent, SimpleChatMessage\n\n@pytest.fixture\ndef test_guild():\n    # Create a guild for testing with a probe agent\n    guild = GuildBuilder(\"test_guild\", \"Test Guild\", \"Guild for testing\").launch(add_probe=True)\n\n    # Add test agent\n    agent_spec = AgentBuilder(SimpleLLMAgent).set_name(\"ChatAgent\").build_spec()\n    guild.launch_agent(agent_spec)\n\n    # Get the probe agent for testing\n    probe_agent = guild.get_agent_of_type(ProbeAgent)\n\n    # Return guild and probe for test use\n    try:\n        yield guild, probe_agent\n    finally:\n        # Clean up\n        guild.shutdown()\n\ndef test_chat_agent_response(test_guild):\n    guild, probe_agent = test_guild\n\n    # Send a test message through the probe\n    probe_agent.publish_dict(\n        guild.DEFAULT_TOPIC,\n        {\"content\": \"Hello, how are you?\"},\n        format=SimpleChatMessage\n    )\n\n    # Wait for processing\n    time.sleep(0.01)\n\n    # Get all messages captured by the probe\n    messages = probe_agent.get_messages()\n\n    # Verify a response was received\n    assert len(messages) &gt;= 1\n\n    # Check the response content\n    response = messages[0]\n    assert \"I'm doing well\" in response.payload[\"content\"]\n</code></pre>"},{"location":"agents/core/probe_agent.html#probe-agent-variants","title":"Probe Agent Variants","text":""},{"location":"agents/core/probe_agent.html#essentialprobeagent","title":"EssentialProbeAgent","text":"<p>The <code>EssentialProbeAgent</code> is a variant that automatically subscribes to the essential topics in the guild, making it useful for monitoring system-level messages.</p>"},{"location":"agents/core/probe_agent.html#integration-with-guild-builder","title":"Integration with Guild Builder","text":"<p>The <code>GuildBuilder</code> class provides a convenient method to add a probe agent when launching a guild:</p> <pre><code># Create a guild with a probe agent\nguild = GuildBuilder(\"my_guild\", \"My Guild\", \"Description\").launch(add_probe=True)\n\n# Access the probe agent\nprobe_agent = guild.get_agent_of_type(ProbeAgent)\n</code></pre>"},{"location":"agents/core/probe_agent.html#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use in Test Fixtures: Create a fixture that sets up a guild with a probe agent and tears it down after tests.</p> </li> <li> <p>Wait for Asynchronous Processing: Use <code>time.sleep()</code> or better asynchronous waiting patterns to allow time for messages to be processed.</p> </li> <li> <p>Clear Messages Between Tests: Use <code>probe_agent.clear_messages()</code> between test cases to ensure clean testing state.</p> </li> <li> <p>Test Message Patterns: Don't just test for response existence, but verify the correct content and message patterns.</p> </li> <li> <p>Use for Debugging: During development, add a probe agent to inspect message flow and diagnose issues.</p> </li> </ol>"},{"location":"agents/core/probe_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>The probe agent stores messages in memory, so be cautious with large message volumes</li> <li>Message history isn't persisted beyond the lifetime of the guild</li> <li>Not intended for production use, only for testing and debugging </li> </ul>"},{"location":"agents/core/simple_llm_agent.html","title":"SimpleLLMAgent","text":"<p>The <code>SimpleLLMAgent</code> is a basic implementation of a Large Language Model agent within the Rustic AI framework. It provides an easy-to-use interface for conversational interactions with language models.</p>"},{"location":"agents/core/simple_llm_agent.html#purpose","title":"Purpose","text":"<p>This agent serves as a straightforward way to interact with language models in a conversational manner. It maintains a chat history and handles the formatting of messages for LLM interactions via a dependency injection pattern.</p>"},{"location":"agents/core/simple_llm_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>SimpleLLMAgent</code> when your application needs:</p> <ul> <li>A simple conversational interface with a language model</li> <li>Basic chat memory functionality</li> <li>A minimal implementation that can be easily extended</li> <li>A reference implementation for creating custom LLM agents</li> </ul>"},{"location":"agents/core/simple_llm_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>SimpleLLMAgent</code> requires:</p> <ul> <li>llm: An LLM dependency that implements the LLM interface</li> </ul>"},{"location":"agents/core/simple_llm_agent.html#configuration","title":"Configuration","text":"<p>The <code>SimpleLLMAgent</code> is configured through the <code>SimpleLLMAgentConf</code> class, which allows setting:</p> <pre><code>class SimpleLLMAgentConf(BaseAgentProps):\n    chat_memory: int = 10  # Number of messages to keep in memory\n    system_messages: List[str] = [\"You are a helpful assistant.\"]  # System instructions\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/core/simple_llm_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/core/simple_llm_agent.html#simplechatmessage","title":"SimpleChatMessage","text":"<p>A simple chat message from a user.</p> <pre><code>class SimpleChatMessage(BaseModel):\n    content: str  # The user's message\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/core/simple_llm_agent.html#simplechatresponse","title":"SimpleChatResponse","text":"<p>The agent's response to a chat message.</p> <pre><code>class SimpleChatResponse(BaseModel):\n    content: str  # The LLM's response\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#chatcompletionerror","title":"ChatCompletionError","text":"<p>Sent when an error occurs during LLM processing:</p> <pre><code>class ChatCompletionError(BaseModel):\n    status_code: ResponseCodes\n    message: str\n    model: str\n    request_messages: List[Any]\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a chat message</li> <li>It formats the message into a prompt, including:<ul> <li>System messages (from configuration)</li> <li>Chat history (up to the configured limit)</li> <li>The new user message</li> </ul> </li> <li>The formatted prompt is sent to the LLM dependency</li> <li>The response from the LLM is captured and returned</li> <li>Both the user message and the LLM response are added to the chat history</li> </ol>"},{"location":"agents/core/simple_llm_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.core.agents.llm.simple_llm_agent import SimpleLLMAgent, SimpleLLMAgentConf\n\n# Create an LLM dependency\nllm_dependency = DependencySpec(\n    class_name=\"rustic_ai.litellm.agent_ext.llm.LiteLLMResolver\",\n    properties={\n        \"model\": \"gpt-4\",\n    },\n)\n\n# Create the agent spec\nsimple_llm_agent_spec = (\n    AgentBuilder(SimpleLLMAgent)\n    .set_id(\"chat_agent\")\n    .set_name(\"Chat Agent\")\n    .set_description(\"Simple conversational agent using an LLM\")\n    .set_properties(\n        SimpleLLMAgentConf(\n            chat_memory=15,  # Remember 15 messages\n            system_messages=[\n                \"You are a helpful assistant in the Rustic AI framework.\",\n                \"You provide concise and accurate information.\"\n            ]\n        )\n    )\n    .build_spec()\n)\n\n# Add dependency to guild when launching\nguild_builder.add_dependency(\"llm\", llm_dependency)\nguild_builder.add_agent_spec(simple_llm_agent_spec)\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.agents.llm.simple_llm_agent import SimpleChatMessage\n\n# Create a chat message\nmessage = SimpleChatMessage(\n    content=\"What is a multi-agent system?\"\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", message)\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#example-response","title":"Example Response","text":"<p>The agent responds with a <code>SimpleChatResponse</code>:</p> <pre><code>SimpleChatResponse(\n    content=\"A multi-agent system (MAS) is a computerized system composed of multiple interacting intelligent agents within an environment. Multi-agent systems can solve problems that are difficult or impossible for an individual agent to solve. In Rustic AI, these agents can communicate, coordinate, and collaborate to accomplish complex tasks.\"\n)\n</code></pre>"},{"location":"agents/core/simple_llm_agent.html#extending-the-agent","title":"Extending the Agent","text":"<p>The <code>SimpleLLMAgent</code> is designed to be a minimal implementation that can be extended for more specialized use cases. You can extend it to add:</p> <ul> <li>Custom message preprocessing</li> <li>Additional message types</li> <li>More sophisticated memory management</li> <li>Integration with other agent capabilities</li> </ul>"},{"location":"agents/core/simple_llm_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Provides only basic conversational capabilities</li> <li>Memory is stored in-memory and not persisted</li> <li>Does not implement advanced features like tool calling</li> <li>Relies on the underlying LLM dependency for most functionality </li> </ul>"},{"location":"agents/core/user_proxy_agent.html","title":"UserProxyAgent","text":"<p>The <code>UserProxyAgent</code> serves as an interface between human users and a Rustic AI guild, handling the translation of user inputs into agent messages and formatting agent responses for user consumption.</p>"},{"location":"agents/core/user_proxy_agent.html#purpose","title":"Purpose","text":"<p>This agent acts as a bridge between external users and the guild's internal messaging system. It provides a consistent interface for users to interact with the guild, handles various input/output formats, and maintains user-specific state.</p>"},{"location":"agents/core/user_proxy_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>UserProxyAgent</code> when you need to:</p> <ul> <li>Create a user-facing interface to a Rustic AI guild</li> <li>Manage user sessions and conversations</li> <li>Format content for display to users</li> <li>Route user requests to appropriate specialized agents</li> <li>Build applications with direct user interaction</li> </ul>"},{"location":"agents/core/user_proxy_agent.html#configuration","title":"Configuration","text":"<p>The <code>UserProxyAgent</code> is configured through the <code>UserProxyAgentProps</code> class, which allows setting:</p> <pre><code>class UserProxyAgentProps(BaseAgentProps):\n    default_target: Optional[str] = None  # Default agent to send messages to\n    include_message_history: bool = True  # Whether to include message history\n    max_history_messages: int = 10  # Maximum number of messages in history\n    user_id: Optional[str] = None  # ID of the user this agent represents\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/core/user_proxy_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/core/user_proxy_agent.html#usermessage","title":"UserMessage","text":"<p>A message from a user to the system:</p> <pre><code>class UserMessage(BaseModel):\n    content: str  # The user's message text\n    target: Optional[str] = None  # Optional target agent ID\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#userchatrequest","title":"UserChatRequest","text":"<p>A chat message with optional content parts (text, images, etc.):</p> <pre><code>class UserChatRequest(BaseModel):\n    content: Optional[List[ContentPart]] = None  # Content parts\n    target: Optional[str] = None  # Optional target agent ID\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/core/user_proxy_agent.html#userchatresponse","title":"UserChatResponse","text":"<p>A formatted response for display to the user:</p> <pre><code>class UserChatResponse(BaseModel):\n    content: Union[str, List[ContentPart]]  # Response content\n    format: Optional[TextFormat] = TextFormat.MARKDOWN  # Text format\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#systemalert","title":"SystemAlert","text":"<p>A system message or alert for the user:</p> <pre><code>class SystemAlert(BaseModel):\n    title: str  # Alert title\n    content: str  # Alert content\n    level: AlertLevel = AlertLevel.INFO  # Alert importance level\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a message from the user interface</li> <li>It processes the message based on type:<ul> <li>Basic user messages are converted to appropriate formats</li> <li>Chat requests are formatted with content parts</li> <li>Messages are routed to the specified target or default target</li> </ul> </li> <li>The agent maintains a conversation history for context</li> <li>Responses from other agents are formatted for user consumption</li> <li>System alerts and status updates are sent to the user interface</li> </ol>"},{"location":"agents/core/user_proxy_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.agents.utils.user_proxy_agent import UserProxyAgent, UserProxyAgentProps\n\n# Create the agent spec with configuration\nuser_proxy_spec = (\n    AgentBuilder(UserProxyAgent)\n    .set_id(\"user_proxy\")\n    .set_name(\"User Interface\")\n    .set_description(\"Interface between user and the system\")\n    .set_properties(\n        UserProxyAgentProps(\n            default_target=\"llm_agent\",  # Default target is the LLM agent\n            max_history_messages=15,  # Remember 15 messages of history\n            user_id=\"user-123\"  # Associate with specific user\n        )\n    )\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(user_proxy_spec)\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#integration-with-user-interfaces","title":"Integration with User Interfaces","text":"<p>The <code>UserProxyAgent</code> is typically integrated with:</p> <ol> <li>Web interfaces - Through WebSocket connections or REST APIs</li> <li>Chat interfaces - For conversational applications</li> <li>Command-line interfaces - For developer tools and scripts</li> <li>Mobile apps - Via appropriate API endpoints</li> </ol>"},{"location":"agents/core/user_proxy_agent.html#example-web-integration","title":"Example Web Integration","text":"<pre><code># In a web server route handler\n@app.route(\"/chat\", methods=[\"POST\"])\ndef handle_chat():\n    user_id = get_user_id_from_session()\n    message_content = request.json.get(\"message\")\n\n    # Get the user's proxy agent ID (or create one if it doesn't exist)\n    user_proxy_id = get_or_create_user_proxy(user_id)\n\n    # Send message to the user's proxy agent\n    guild.publish_message(\n        UserMessage(content=message_content),\n        recipient=user_proxy_id\n    )\n\n    # In a real implementation, would use WebSockets or\n    # some other mechanism to stream back the response\n    return {\"status\": \"message_sent\"}\n</code></pre>"},{"location":"agents/core/user_proxy_agent.html#guild-refresh-capabilities","title":"Guild Refresh Capabilities","text":"<p>The <code>UserProxyAgent</code> implements the <code>GuildRefreshMixin</code>, which allows it to:</p> <ol> <li>Request a refresh of the guild state</li> <li>Update its knowledge of available agents</li> <li>Discover new capabilities as agents are added or removed</li> <li>Adapt routing based on the current guild configuration</li> </ol>"},{"location":"agents/core/user_proxy_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Each user typically needs their own <code>UserProxyAgent</code> instance</li> <li>For multi-user applications, agent IDs should incorporate user identifiers</li> <li>The agent maintains state in memory by default, so consider persistence for production</li> <li>Consider security implications when exposing guild functionality to users</li> <li>Message history is kept in memory, so be mindful of memory usage with many users </li> </ul>"},{"location":"agents/core/vector_agent.html","title":"VectorAgent","text":"<p>The <code>VectorAgent</code> provides document indexing and vector search capabilities within a Rustic AI guild, enabling semantic retrieval of information from text documents.</p>"},{"location":"agents/core/vector_agent.html#purpose","title":"Purpose","text":"<p>This agent serves as a bridge between your application and vector databases. It handles document processing, indexing, and vector similarity search, making it a core component for knowledge retrieval systems.</p>"},{"location":"agents/core/vector_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>VectorAgent</code> when your application needs to:</p> <ul> <li>Store and retrieve documents based on semantic similarity</li> <li>Create a knowledge base for LLM context augmentation</li> <li>Implement retrieval-augmented generation (RAG) patterns</li> <li>Build search functionality based on meaning rather than keywords</li> <li>Process and index documents from various sources</li> </ul>"},{"location":"agents/core/vector_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>VectorAgent</code> requires:</p> <ul> <li>vectorstore: A vector database implementation for storing embeddings</li> <li>textsplitter: A text splitting implementation for breaking documents into chunks</li> <li>embeddings: An embeddings provider for converting text to vectors</li> </ul>"},{"location":"agents/core/vector_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/core/vector_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/core/vector_agent.html#ingestdocuments","title":"IngestDocuments","text":"<p>A request to index documents for later retrieval:</p> <pre><code>class IngestDocuments(BaseModel):\n    links: List[MediaLink]  # List of documents to ingest\n    namespace: Optional[str] = None  # Optional namespace for organizing documents\n    metadata: Optional[Dict[str, Any]] = None  # Additional metadata for all documents\n    chunk_metadata: Optional[Dict[str, Any]] = None  # Metadata for individual chunks\n</code></pre>"},{"location":"agents/core/vector_agent.html#vectorsearchquery","title":"VectorSearchQuery","text":"<p>A request to search for documents by similarity:</p> <pre><code>class VectorSearchQuery(BaseModel):\n    query: str  # The search query text\n    namespace: Optional[str] = None  # Namespace to search within\n    limit: int = 5  # Maximum number of results to return\n    filter: Optional[Dict[str, Any]] = None  # Filter criteria for search\n</code></pre>"},{"location":"agents/core/vector_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/core/vector_agent.html#vectorsearchresults","title":"VectorSearchResults","text":"<p>The results of a vector search:</p> <pre><code>class VectorSearchResults(BaseModel):\n    query: str  # The original query\n    results: List[Document]  # The matching documents\n    namespace: Optional[str] = None  # The namespace that was searched\n</code></pre> <p>Each <code>Document</code> includes: - content: The text content - metadata: Document metadata - score: Similarity score to the query</p>"},{"location":"agents/core/vector_agent.html#ingestcompleted","title":"IngestCompleted","text":"<p>Sent when document ingestion is completed:</p> <pre><code>class IngestCompleted(BaseModel):\n    namespace: Optional[str] = None  # The namespace documents were added to\n    count: int  # Number of documents ingested\n    chunk_count: int  # Number of chunks created from documents\n</code></pre>"},{"location":"agents/core/vector_agent.html#behavior","title":"Behavior","text":""},{"location":"agents/core/vector_agent.html#document-ingestion","title":"Document Ingestion","text":"<ol> <li>The agent receives an <code>IngestDocuments</code> message with document links</li> <li>For each document:<ul> <li>The content is loaded from the file or URL</li> <li>The text is split into chunks using the text splitter dependency</li> <li>Each chunk is converted to embeddings using the embeddings dependency</li> <li>The embeddings are stored in the vector store with associated metadata</li> </ul> </li> <li>The agent emits an <code>IngestCompleted</code> message with statistics</li> </ol>"},{"location":"agents/core/vector_agent.html#vector-search","title":"Vector Search","text":"<ol> <li>The agent receives a <code>VectorSearchQuery</code> message</li> <li>The query text is converted to embeddings</li> <li>A similarity search is performed in the vector store</li> <li>The most similar documents are returned in a <code>VectorSearchResults</code> message</li> </ol>"},{"location":"agents/core/vector_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.core.agents.indexing.vector_agent import VectorAgent\n\n# Set up dependencies\nvectorstore = DependencySpec(\n    class_name=\"rustic_ai.chroma.agent_ext.vectorstore.ChromaResolver\",\n    properties={}\n)\n\nembeddings = DependencySpec(\n    class_name=\"rustic_ai.langchain.agent_ext.embeddings.openai.OpenAIEmbeddingsResolver\",\n    properties={}\n)\n\ntextsplitter = DependencySpec(\n    class_name=\"rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter.RecursiveSplitterResolver\",\n    properties={\n        \"conf\": {\n            \"chunk_size\": 1000,\n            \"chunk_overlap\": 200\n        }\n    }\n)\n\n# Create the agent spec\nvector_agent_spec = (\n    AgentBuilder(VectorAgent)\n    .set_id(\"vector_agent\")\n    .set_name(\"Vector Agent\")\n    .set_description(\"Agent for document indexing and semantic search\")\n    .build_spec()\n)\n\n# Add dependencies and agent to guild\nguild_builder.add_dependency(\"vectorstore\", vectorstore)\nguild_builder.add_dependency(\"embeddings\", embeddings)\nguild_builder.add_dependency(\"textsplitter\", textsplitter)\nguild_builder.add_agent_spec(vector_agent_spec)\n</code></pre>"},{"location":"agents/core/vector_agent.html#example-document-ingestion","title":"Example Document Ingestion","text":"<pre><code>from rustic_ai.core.agents.commons.media import MediaLink\nfrom rustic_ai.core.agents.indexing.vector_agent import IngestDocuments\n\n# Create document links\ndocuments = [\n    MediaLink(\n        url=\"docs/introduction.md\",\n        name=\"Introduction\",\n        on_filesystem=True,\n        mimetype=\"text/markdown\"\n    ),\n    MediaLink(\n        url=\"docs/api_reference.md\",\n        name=\"API Reference\",\n        on_filesystem=True,\n        mimetype=\"text/markdown\"\n    )\n]\n\n# Create ingestion request\ningest_request = IngestDocuments(\n    links=documents,\n    namespace=\"documentation\",\n    metadata={\"source\": \"official_docs\", \"version\": \"1.0\"}\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", ingest_request)\n</code></pre>"},{"location":"agents/core/vector_agent.html#example-vector-search","title":"Example Vector Search","text":"<pre><code>from rustic_ai.core.agents.indexing.vector_agent import VectorSearchQuery\n\n# Create search query\nsearch_query = VectorSearchQuery(\n    query=\"How do I create a custom agent?\",\n    namespace=\"documentation\",\n    limit=3\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", search_query)\n</code></pre>"},{"location":"agents/core/vector_agent.html#integration-with-rag-pattern","title":"Integration with RAG Pattern","text":"<p>The VectorAgent is commonly used as part of a Retrieval-Augmented Generation (RAG) pattern:</p> <ol> <li>Documents are ingested and indexed using the VectorAgent</li> <li>User queries are sent to a coordinator agent</li> <li>The coordinator agent:<ul> <li>Sends a vector search query to find relevant context</li> <li>Combines the retrieved context with the user query</li> <li>Sends the augmented query to an LLM agent</li> </ul> </li> <li>The LLM agent generates a response using the retrieved context</li> </ol> <p>This pattern significantly improves the quality and factuality of LLM responses for domain-specific applications.</p>"},{"location":"agents/core/vector_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>The quality of vector search depends on the embeddings model used</li> <li>Performance depends on the vector store implementation</li> <li>Document chunking strategies significantly impact search quality</li> <li>Large document collections require more storage and compute resources</li> <li>Consider metadata filtering to improve search efficiency in large collections </li> </ul>"},{"location":"agents/huggingface/index.html","title":"HuggingFace Agents","text":"<p>This section contains documentation for Rustic AI's HuggingFace integration, which provides access to various AI models from the Hugging Face ecosystem.</p>"},{"location":"agents/huggingface/index.html#available-agents","title":"Available Agents","text":"<ul> <li>LLMPhiAgent - Interface to Microsoft's Phi-2 language model</li> <li>RunwaymlStableDiffusionAgent - Image generation using Stable Diffusion</li> <li>Image2ImageAgent - Image-to-image transformation with Pix2Pix</li> <li>SpeechT5TTSAgent - Text-to-speech synthesis</li> <li>SquadAgent - Question answering using the SQuAD model</li> </ul>"},{"location":"agents/huggingface/index.html#overview","title":"Overview","text":"<p>HuggingFace agents enable seamless integration with the HuggingFace ecosystem, allowing you to incorporate state-of-the-art AI models into your Rustic AI applications. These agents cover a wide range of capabilities, from text generation and question answering to image creation and speech synthesis.</p>"},{"location":"agents/huggingface/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Text generation using language models</li> <li>Image generation and manipulation</li> <li>Speech synthesis from text</li> <li>Question answering from context</li> <li>Multi-modal AI applications</li> <li>Local model inference (where supported)</li> </ul>"},{"location":"agents/huggingface/index.html#getting-started","title":"Getting Started","text":"<p>To use HuggingFace agents, you'll need:</p> <ol> <li>The appropriate HuggingFace libraries installed in your environment</li> <li>Sufficient hardware resources for models running locally</li> <li>A HuggingFace API key for remote inference (when applicable). This could be exposed as an environment variable <code>HF_TOKEN</code> or handled through the huggingface-cli</li> <li>Proper configuration of the respective agent in your guild</li> </ol> <p>Refer to the individual agent documentation for detailed implementation instructions. </p>"},{"location":"agents/huggingface/image2image_agent.html","title":"Image2ImageAgent","text":"<p>The <code>Image2ImageAgent</code> provides image-to-image transformation capabilities within a Rustic AI guild using the Pix2Pix model, enabling conditional image generation and editing.</p>"},{"location":"agents/huggingface/image2image_agent.html#purpose","title":"Purpose","text":"<p>This agent allows transformation of source images based on text instructions, performing tasks like style transfer, image modification, or feature addition. It uses the Pix2Pix model, which specializes in conditional image-to-image translation.</p>"},{"location":"agents/huggingface/image2image_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>Image2ImageAgent</code> when your application needs to:</p> <ul> <li>Transform existing images based on text instructions</li> <li>Edit images in a controlled manner</li> <li>Apply specific modifications to visual content</li> <li>Generate variations of existing images</li> <li>Implement controlled image manipulation based on natural language</li> </ul>"},{"location":"agents/huggingface/image2image_agent.html#configuration","title":"Configuration","text":"<p>The <code>Image2ImageAgent</code> is configured through the <code>Pix2PixProps</code> class, which allows setting:</p> <pre><code>class Pix2PixProps(PyTorchAgentProps):\n    model_id: str = \"timbrooks/instruct-pix2pix\"  # The model ID to load from Hugging Face\n</code></pre> <p>The agent inherits from the <code>PyTorchAgentProps</code> base class, which provides:</p> <pre><code>class PyTorchAgentProps(BaseAgentProps):\n    torch_device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Device to run the model on\n</code></pre>"},{"location":"agents/huggingface/image2image_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>Image2ImageAgent</code> requires:</p> <ul> <li>filesystem (Guild-level dependency): A file system implementation for storing transformed images</li> </ul>"},{"location":"agents/huggingface/image2image_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/huggingface/image2image_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/huggingface/image2image_agent.html#imageeditrequest","title":"ImageEditRequest","text":"<p>A request to transform an image:</p> <pre><code>class ImageEditRequest(BaseModel):\n    source_image: MediaLink  # The source image to transform\n    instruction: str  # Text instruction describing the desired transformation\n    num_inference_steps: int = 20  # Number of inference steps (higher = better quality)\n    image_guidance_scale: float = 1.5  # How closely to follow the source image\n    guidance_scale: float = 7.5  # How closely to follow the instruction\n    strength: float = 0.8  # Amount of noise added (higher = more transformation)\n    image_format: str = \"png\"  # Output format for the image\n    width: Optional[int] = None  # Optional width to resize to\n    height: Optional[int] = None  # Optional height to resize to\n</code></pre>"},{"location":"agents/huggingface/image2image_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/huggingface/image2image_agent.html#imageeditresponse","title":"ImageEditResponse","text":"<p>Sent when image transformation is completed:</p> <pre><code>class ImageEditResponse(BaseModel):\n    files: List[MediaLink]  # List of transformed image files\n    errors: List[str]  # Any errors that occurred during processing\n    request: str  # The original request (JSON string)\n</code></pre> <p>Each <code>MediaLink</code> contains: - url: Path to the generated image file - name: Filename (UUID-based) - mimetype: Content type (image/png) - on_filesystem: Always True for generated images - metadata: Contains information about the transformation</p>"},{"location":"agents/huggingface/image2image_agent.html#errormessage","title":"ErrorMessage","text":"<p>Sent when image transformation fails:</p> <pre><code>class ErrorMessage(BaseModel):\n    agent_type: str\n    error_type: str  # \"ImageTransformationError\"\n    error_message: str\n</code></pre>"},{"location":"agents/huggingface/image2image_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives an <code>ImageEditRequest</code> with a source image and instruction</li> <li>The source image is loaded and preprocessed</li> <li>The image is transformed according to the instruction using the Pix2Pix model</li> <li>The transformed image is saved to a file with a generated UUID filename</li> <li>A <code>MediaLink</code> is created for the transformed image</li> <li>An <code>ImageEditResponse</code> containing the image link is sent</li> <li>If any errors occur, an <code>ErrorMessage</code> is sent</li> </ol>"},{"location":"agents/huggingface/image2image_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.huggingface.agents.diffusion.pix2pix import Image2ImageAgent, Pix2PixProps\n\n# Define a file system dependency\nfilesystem = DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.FileSystemResolver\",\n    properties={\n        \"path_base\": \"/tmp\",\n        \"protocol\": \"file\",\n        \"storage_options\": {\n            \"auto_mkdir\": True,\n        },\n    },\n)\n\n# Create the agent spec\npix2pix_agent_spec = (\n    AgentBuilder(Image2ImageAgent)\n    .set_id(\"image_editor\")\n    .set_name(\"Image Editor\")\n    .set_description(\"Transforms images based on text instructions using Pix2Pix\")\n    .set_properties(\n        Pix2PixProps(\n            model_id=\"timbrooks/instruct-pix2pix\",  # Default model\n            torch_device=\"cuda:0\"  # Specify GPU device if needed\n        )\n    )\n    .build_spec()\n)\n\n# Add dependency to guild when launching\nguild_builder.add_dependency(\"filesystem\", filesystem)\nguild_builder.add_agent_spec(pix2pix_agent_spec)\n</code></pre>"},{"location":"agents/huggingface/image2image_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.agents.commons.media import MediaLink\nfrom rustic_ai.huggingface.agents.models import ImageEditRequest\n\n# Create an image edit request\nedit_request = ImageEditRequest(\n    source_image=MediaLink(\n        url=\"/path/to/source/image.jpg\",\n        name=\"source_image.jpg\",\n        on_filesystem=True,\n        mimetype=\"image/jpeg\"\n    ),\n    instruction=\"Make it look like a winter scene with snow\",\n    guidance_scale=9.0,  # Higher guidance for more faithful adherence to instruction\n    strength=0.7  # Slightly lower strength to preserve more of the original\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", edit_request)\n</code></pre>"},{"location":"agents/huggingface/image2image_agent.html#technical-details","title":"Technical Details","text":"<p>The agent uses: - Hugging Face's <code>diffusers</code> library with the <code>StableDiffusionInstructPix2PixPipeline</code> - Tim Brooks' Instruct-Pix2Pix model - PyTorch for tensor operations - PIL for image manipulation - Automatic hardware detection to use GPU when available</p>"},{"location":"agents/huggingface/image2image_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires significant VRAM to run efficiently (at least 8GB recommended)</li> <li>Performance is much better with a GPU</li> <li>Quality of transformations depends heavily on the clarity of instructions</li> <li>Works best with certain types of transformations (e.g., style changes, weather effects)</li> <li>First-time initialization may take longer as models are downloaded</li> <li>Larger images require more memory and processing time</li> <li>The <code>strength</code> parameter controls how much of the original image is preserved versus changed</li> <li>The <code>image_guidance_scale</code> controls how closely the output adheres to the input image structure </li> </ul>"},{"location":"agents/huggingface/llm_phi_agent.html","title":"LLMPhiAgent","text":"<p>The <code>LLMPhiAgent</code> provides access to Microsoft's Phi-2 language model within a Rustic AI guild, enabling text generation capabilities using a locally-run model.</p>"},{"location":"agents/huggingface/llm_phi_agent.html#purpose","title":"Purpose","text":"<p>This agent serves as a language model interface using Microsoft's Phi-2, a compact yet powerful LLM capable of various text generation tasks. It runs the model locally using Hugging Face's Transformers library.</p>"},{"location":"agents/huggingface/llm_phi_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>LLMPhiAgent</code> when your application needs to:</p> <ul> <li>Generate text using a locally-run language model</li> <li>Have lower latency than cloud-based LLMs</li> <li>Work in environments with limited or no internet access</li> <li>Use a lightweight language model with good performance</li> <li>Avoid sending sensitive data to external API services</li> </ul>"},{"location":"agents/huggingface/llm_phi_agent.html#configuration","title":"Configuration","text":"<p>The <code>LLMPhiAgent</code> is configured through the <code>PhiAgentProps</code> class, which allows setting:</p> <pre><code>class PhiAgentProps(PyTorchAgentProps):\n    model_id: str = \"microsoft/phi-2\"  # The model ID to load from Hugging Face\n</code></pre> <p>The agent inherits from the <code>PyTorchAgentProps</code> base class, which provides:</p> <pre><code>class PyTorchAgentProps(BaseAgentProps):\n    torch_device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Device to run the model on\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/huggingface/llm_phi_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/huggingface/llm_phi_agent.html#generationpromptrequest","title":"GenerationPromptRequest","text":"<p>A request for text generation:</p> <pre><code>class GenerationPromptRequest(BaseModel):\n    generation_prompt: str  # The prompt text to complete\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/huggingface/llm_phi_agent.html#generationpromptresponse","title":"GenerationPromptResponse","text":"<p>The response with the generated text:</p> <pre><code>class GenerationPromptResponse(BaseModel):\n    generation_prompt: str  # The original prompt\n    generated_response: str  # The generated text\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a <code>GenerationPromptRequest</code> containing a text prompt</li> <li>It tokenizes the prompt using the Phi-2 tokenizer</li> <li>The tokens are processed through the Phi-2 model</li> <li>The generated text is decoded from the output tokens</li> <li>The agent returns a <code>GenerationPromptResponse</code> containing both the original prompt and the generated text</li> </ol>"},{"location":"agents/huggingface/llm_phi_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.huggingface.agents.llm.phi_agent import LLMPhiAgent, PhiAgentProps\n\n# Create the agent spec\nphi_agent_spec = (\n    AgentBuilder(LLMPhiAgent)\n    .set_id(\"phi_agent\")\n    .set_name(\"Phi-2 LLM\")\n    .set_description(\"Text generation using Microsoft's Phi-2 model\")\n    .set_properties(\n        PhiAgentProps(\n            model_id=\"microsoft/phi-2\",  # Default is microsoft/phi-2\n            torch_device=\"cuda:0\"  # Specify GPU device if needed\n        )\n    )\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(phi_agent_spec)\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.agents.commons.message_formats import GenerationPromptRequest\n\n# Create a generation request\nrequest = GenerationPromptRequest(\n    generation_prompt=\"The benefits of multi-agent systems include\"\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", request)\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#example-response","title":"Example Response","text":"<p>The agent responds with a <code>GenerationPromptResponse</code>:</p> <pre><code>GenerationPromptResponse(\n    generation_prompt=\"The benefits of multi-agent systems include\",\n    generated_response=\"The benefits of multi-agent systems include improved problem-solving capabilities, enhanced system robustness, distributed computing efficiency, and the ability to solve complex tasks that single agents cannot handle effectively. Multi-agent systems can also adapt to changing environments and scale more effectively than monolithic systems.\"\n)\n</code></pre>"},{"location":"agents/huggingface/llm_phi_agent.html#technical-details","title":"Technical Details","text":"<p>The agent leverages: - Hugging Face's <code>transformers</code> library for model loading and inference - Microsoft's Phi-2 model, a 2.7B parameter language model - PyTorch for the underlying computation - Automatic hardware detection to use GPU when available</p>"},{"location":"agents/huggingface/llm_phi_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires significant RAM/VRAM to load the model (at least 8GB recommended)</li> <li>Performance depends on the hardware available (GPU highly recommended)</li> <li>The model has a context length limitation of approximately 2,048 tokens</li> <li>First-time initialization may take longer as models are downloaded</li> <li>While Phi-2 is smaller than models like GPT-4, it still provides good performance on many tasks</li> <li>Consider using the <code>torch_device</code> property to control which GPU device the model uses in multi-GPU systems </li> </ul>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html","title":"RunwaymlStableDiffusionAgent","text":"<p>The <code>RunwaymlStableDiffusionAgent</code> is an image generation agent that creates images from text prompts using Stability AI's Stable Diffusion model.</p>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#purpose","title":"Purpose","text":"<p>This agent provides text-to-image generation capabilities within a Rustic AI guild, enabling the creation of images from natural language descriptions. It uses Stable Diffusion 3.5, a powerful diffusion model capable of generating high-quality images.</p>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>RunwaymlStableDiffusionAgent</code> when your application needs to:</p> <ul> <li>Generate images from text descriptions</li> <li>Create visual content based on textual prompts</li> <li>Produce illustrations or artwork programmatically</li> <li>Visualize concepts or ideas described in text</li> <li>Add image generation capabilities to your AI system</li> </ul>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#configuration","title":"Configuration","text":"<p>The <code>RunwaymlStableDiffusionAgent</code> is configured through the <code>RunwaymlStableDiffusionProps</code> class, which allows setting:</p> <pre><code>class RunwaymlStableDiffusionProps(PyTorchAgentProps):\n    model_id: str = \"stabilityai/stable-diffusion-3.5-medium\"  # The model ID to load from Hugging Face\n</code></pre> <p>The agent inherits from the <code>PyTorchAgentProps</code> base class, which provides:</p> <pre><code>class PyTorchAgentProps(BaseAgentProps):\n    torch_device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Device to run the model on\n</code></pre>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>RunwaymlStableDiffusionAgent</code> requires:</p> <ul> <li>filesystem (Guild-level dependency): A file system implementation for storing generated images</li> </ul>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#imagegenerationrequest","title":"ImageGenerationRequest","text":"<p>A request to generate images:</p> <pre><code>class ImageGenerationRequest(BaseModel):\n    generation_prompt: str  # The text prompt describing the desired image\n    num_images: int = 1  # Number of images to generate\n    guidance_scale: float = 7.5  # How closely to follow the prompt (higher = more faithful)\n    num_inference_steps: int = 50  # Number of denoising steps (higher = better quality, slower)\n    height: int = 1024  # Height of the generated image\n    width: int = 1024  # Width of the generated image\n    image_format: str = \"png\"  # Output format for the image\n</code></pre>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#imagegenerationresponse","title":"ImageGenerationResponse","text":"<p>Sent when image generation is completed:</p> <pre><code>class ImageGenerationResponse(BaseModel):\n    files: List[MediaLink]  # List of generated image files\n    errors: List[str]  # Any errors that occurred during generation\n    request: str  # The original request (JSON string)\n</code></pre> <p>Each <code>MediaLink</code> contains: - url: Path to the generated image file - name: Filename (UUID-based) - mimetype: Content type (image/png) - on_filesystem: Always True for generated images</p>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#errormessage","title":"ErrorMessage","text":"<p>Sent when image generation fails:</p> <pre><code>class ErrorMessage(BaseModel):\n    agent_type: str\n    error_type: str  # \"ImageGenerationError\"\n    error_message: str\n</code></pre>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives an <code>ImageGenerationRequest</code> with a text prompt</li> <li>The prompt is processed through the Stable Diffusion pipeline</li> <li>The specified number of images are generated with the requested parameters</li> <li>The images are saved to files with generated UUID filenames</li> <li>A <code>MediaLink</code> is created for each generated image</li> <li>An <code>ImageGenerationResponse</code> containing all the image links is sent</li> <li>If any errors occur, an <code>ErrorMessage</code> is sent</li> </ol>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.huggingface.agents.diffusion.stable_diffusion_agent import (\n    RunwaymlStableDiffusionAgent,\n    RunwaymlStableDiffusionProps\n)\n\n# Define a file system dependency\nfilesystem = DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.FileSystemResolver\",\n    properties={\n        \"path_base\": \"/tmp\",\n        \"protocol\": \"file\",\n        \"storage_options\": {\n            \"auto_mkdir\": True,\n        },\n    },\n)\n\n# Create the agent spec\nsd_agent_spec = (\n    AgentBuilder(RunwaymlStableDiffusionAgent)\n    .set_id(\"image_generator\")\n    .set_name(\"Image Generator\")\n    .set_description(\"Generates images from text using Stable Diffusion\")\n    .set_properties(\n        RunwaymlStableDiffusionProps(\n            model_id=\"stabilityai/stable-diffusion-3.5-medium\",  # Default model\n            torch_device=\"cuda:0\"  # Specify GPU device if needed\n        )\n    )\n    .build_spec()\n)\n\n# Add dependency to guild when launching\nguild_builder.add_dependency(\"filesystem\", filesystem)\nguild_builder.add_agent_spec(sd_agent_spec)\n</code></pre>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.huggingface.agents.models import ImageGenerationRequest\n\n# Create an image generation request\nimage_request = ImageGenerationRequest(\n    generation_prompt=\"A serene forest lake at sunset with mountains in the background\",\n    num_images=2,  # Generate 2 variations\n    guidance_scale=8.0,  # Slightly higher guidance for more prompt adherence\n    num_inference_steps=30,  # Fewer steps for faster generation\n    height=768,\n    width=768\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", image_request)\n</code></pre>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#technical-details","title":"Technical Details","text":"<p>The agent uses: - Hugging Face's <code>diffusers</code> library with the <code>StableDiffusion3Pipeline</code> - Stability AI's Stable Diffusion 3.5 model - PyTorch for tensor operations - Automatic hardware detection to use GPU when available</p>"},{"location":"agents/huggingface/runwayml_stable_diffusion_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires significant VRAM to run efficiently (at least 8GB recommended)</li> <li>Performance is much better with a GPU</li> <li>Generation time depends on the number of inference steps and image size</li> <li>First-time initialization may take longer as models are downloaded</li> <li>Large image sizes (&gt;1024x1024) may require more memory</li> <li>Model is run locally, so consider hardware requirements when deploying</li> <li>Consider using a custom <code>model_id</code> for different versions of Stable Diffusion </li> </ul>"},{"location":"agents/huggingface/speecht5_tts_agent.html","title":"SpeechT5TTSAgent","text":"<p>The <code>SpeechT5TTSAgent</code> is a text-to-speech synthesis agent that converts text into spoken audio using Microsoft's SpeechT5 model via Hugging Face.</p>"},{"location":"agents/huggingface/speecht5_tts_agent.html#purpose","title":"Purpose","text":"<p>This agent provides text-to-speech (TTS) capabilities within a Rustic AI guild, enabling conversion of text content into natural-sounding speech. It uses the Microsoft SpeechT5 model, which produces high-quality speech synthesis.</p>"},{"location":"agents/huggingface/speecht5_tts_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>SpeechT5TTSAgent</code> when your application needs to:</p> <ul> <li>Convert text to spoken audio</li> <li>Generate voice responses for users</li> <li>Create audio content from textual data</li> <li>Add voice capabilities to your AI system</li> <li>Make information more accessible through audio formats</li> </ul>"},{"location":"agents/huggingface/speecht5_tts_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>SpeechT5TTSAgent</code> requires:</p> <ul> <li>filesystem (Guild-level dependency): A file system implementation for storing generated audio files</li> </ul>"},{"location":"agents/huggingface/speecht5_tts_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/huggingface/speecht5_tts_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/huggingface/speecht5_tts_agent.html#generationpromptrequest","title":"GenerationPromptRequest","text":"<p>A request to convert text to speech:</p> <pre><code>class GenerationPromptRequest(BaseModel):\n    generation_prompt: str  # The text to convert to speech\n</code></pre>"},{"location":"agents/huggingface/speecht5_tts_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/huggingface/speecht5_tts_agent.html#medialink","title":"MediaLink","text":"<p>When synthesis is successful, a <code>MediaLink</code> message is emitted with the audio content:</p> <pre><code>class MediaLink(BaseModel):\n    url: str  # Path to the generated audio file\n    name: str  # Filename\n    metadata: Dict  # Metadata including sampling rate\n    on_filesystem: bool  # Always True for generated audio\n    mimetype: str  # Content type (audio/wav)\n</code></pre>"},{"location":"agents/huggingface/speecht5_tts_agent.html#errormessage","title":"ErrorMessage","text":"<p>Sent when speech synthesis fails:</p> <pre><code>class ErrorMessage(BaseModel):\n    agent_type: str\n    error_type: str  # \"SpeechGenerationError\" or \"FileWriteError\"\n    error_message: str\n</code></pre>"},{"location":"agents/huggingface/speecht5_tts_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a <code>GenerationPromptRequest</code> with text content</li> <li>It processes the text through the SpeechT5 TTS pipeline</li> <li>The synthesized speech is saved to a WAV file with a generated UUID filename</li> <li>A <code>MediaLink</code> message is emitted with a reference to the generated audio file</li> <li>If any errors occur during synthesis or file writing, an <code>ErrorMessage</code> is sent</li> </ol>"},{"location":"agents/huggingface/speecht5_tts_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.huggingface.agents.text_to_speech.speecht5_tts_agent import SpeechT5TTSAgent\n\n# Define a file system dependency\nfilesystem = DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.FileSystemResolver\",\n    properties={\n        \"path_base\": \"/tmp\",\n        \"protocol\": \"file\",\n        \"storage_options\": {\n            \"auto_mkdir\": True,\n        },\n    },\n)\n\n# Create the agent spec\ntts_agent_spec = (\n    AgentBuilder(SpeechT5TTSAgent)\n    .set_id(\"tts_agent\")\n    .set_name(\"Text-to-Speech\")\n    .set_description(\"Converts text to spoken audio using SpeechT5\")\n    .build_spec()\n)\n\n# Add dependency to guild when launching\nguild_builder.add_dependency(\"filesystem\", filesystem)\nguild_builder.add_agent_spec(tts_agent_spec)\n</code></pre>"},{"location":"agents/huggingface/speecht5_tts_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.agents.commons.message_formats import GenerationPromptRequest\n\n# Create a text-to-speech request\ntts_request = GenerationPromptRequest(\n    generation_prompt=\"Welcome to Rustic AI, a powerful multi-agent framework.\"\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", tts_request)\n</code></pre>"},{"location":"agents/huggingface/speecht5_tts_agent.html#technical-details","title":"Technical Details","text":"<p>The agent uses: - The Hugging Face <code>transformers</code> library with the <code>text-to-speech</code> pipeline - Microsoft's SpeechT5 model (<code>microsoft/speecht5_tts</code>) - Speaker embeddings from the CMU Arctic dataset for voice characteristics - SoundFile for writing WAV audio files</p>"},{"location":"agents/huggingface/speecht5_tts_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>The agent uses a fixed speaker embedding, resulting in consistent voice characteristics</li> <li>Only produces WAV format audio files</li> <li>Requires a significant amount of memory for the SpeechT5 model</li> <li>First-time initialization may take longer as models are downloaded</li> <li>Currently only supports English text input </li> </ul>"},{"location":"agents/huggingface/squad_agent.html","title":"SquadAgent","text":"<p>The <code>SquadAgent</code> is a question-answering agent that uses a model trained on the Stanford Question Answering Dataset (SQuAD) to extract answers from provided context.</p>"},{"location":"agents/huggingface/squad_agent.html#purpose","title":"Purpose","text":"<p>This agent provides extractive question-answering capabilities within a Rustic AI guild. Given a context passage and a question, it can locate and extract the relevant answer from the context, enabling precise information retrieval.</p>"},{"location":"agents/huggingface/squad_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>SquadAgent</code> when your application needs to:</p> <ul> <li>Extract specific information from longer text passages</li> <li>Answer factual questions based on provided context</li> <li>Implement extractive question-answering functionality</li> <li>Retrieve precise answers rather than generated responses</li> <li>Process documents and extract key information</li> </ul>"},{"location":"agents/huggingface/squad_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/huggingface/squad_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/huggingface/squad_agent.html#questionwithcontext","title":"QuestionWithContext","text":"<p>A request containing a question and its context:</p> <pre><code>class QuestionWithContext(BaseModel):\n    context: str  # The text passage containing the answer\n    question: str  # The question to answer\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/huggingface/squad_agent.html#squadanswer","title":"SquadAnswer","text":"<p>The answer extracted from the context:</p> <pre><code>class SquadAnswer(BaseModel):\n    text: str  # The extracted answer text\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#errormessage","title":"ErrorMessage","text":"<p>Sent when question answering fails:</p> <pre><code>class ErrorMessage(BaseModel):\n    agent_type: str\n    error_type: str  # \"InferenceError\"\n    error_message: str\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a <code>QuestionWithContext</code> message with a context passage and a question</li> <li>It formats the input for the SQuAD model (deepset/roberta-base-squad2)</li> <li>The request is sent to the Hugging Face Inference API</li> <li>The model extracts the most relevant answer span from the context</li> <li>The agent returns a <code>SquadAnswer</code> with the extracted text</li> <li>If any errors occur, an <code>ErrorMessage</code> is sent</li> </ol>"},{"location":"agents/huggingface/squad_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.huggingface.agents.nlp.squad_agent import SquadAgent\n\n# Create the agent spec\nsquad_agent_spec = (\n    AgentBuilder(SquadAgent)\n    .set_id(\"qa_agent\")\n    .set_name(\"Question Answering\")\n    .set_description(\"Extracts answers from context using SQuAD\")\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(squad_agent_spec)\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.huggingface.agents.nlp.squad_agent import QuestionWithContext\n\n# Create a question-answering request\nqa_request = QuestionWithContext(\n    context=\"The Taj Mahal, found in the Indian state of Uttar Pradesh, is one of the Seven Wonders of the Modern World. It was built in the 17th century by Mughal emperor Shah Jahan as a mausoleum for his third wife, Mumtaz Mahal. The Taj Mahal is a fine example of Mughal architecture, which is a blend of Islamic, Persian, Turkish and Indian architectural styles.\",\n    question=\"Who was Mumtaz Mahal?\"\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", qa_request)\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#example-response","title":"Example Response","text":"<p>The agent responds with a <code>SquadAnswer</code>:</p> <pre><code>SquadAnswer(\n    text=\"his third wife\"\n)\n</code></pre>"},{"location":"agents/huggingface/squad_agent.html#technical-details","title":"Technical Details","text":"<p>The agent leverages: - Hugging Face's Inference API - deepset/roberta-base-squad2 model, a RoBERTa model fine-tuned on SQuAD 2.0 - Inherits from <code>HuggingfaceInferenceMixin</code> to handle API communication</p>"},{"location":"agents/huggingface/squad_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires a Hugging Face API key set as the <code>HUGGINGFACE_API_KEY</code> environment variable</li> <li>Only performs extractive QA (extracts spans from the context, doesn't generate new text)</li> <li>Performance depends on the relevance of the provided context</li> <li>Questions must be answerable from the given context</li> <li>The model works best with factual, specific questions</li> <li>Context length is limited; very long contexts may need to be split</li> <li>Performance may vary based on context complexity and question type</li> <li>The agent operates in REMOTE mode, relying on the Hugging Face API rather than local inference </li> </ul>"},{"location":"agents/litellm/index.html","title":"LiteLLM Agents","text":"<p>This section contains documentation for Rustic AI's LiteLLM integration, which provides a unified interface to various large language models through the LiteLLM library.</p>"},{"location":"agents/litellm/index.html#available-agents","title":"Available Agents","text":"<ul> <li>LiteLLMAgent - Interface to various LLMs through the LiteLLM library</li> </ul>"},{"location":"agents/litellm/index.html#overview","title":"Overview","text":"<p>LiteLLM agents enable seamless integration with multiple language model providers through a single, consistent interface. The LiteLLM library abstracts away the differences between various LLM APIs (like OpenAI, Anthropic, Cohere, etc.), allowing you to switch between models with minimal code changes.</p>"},{"location":"agents/litellm/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Natural language processing and generation</li> <li>Conversational AI systems</li> <li>Content creation and summarization</li> <li>Language translation and reformatting</li> <li>Knowledge extraction and question answering</li> <li>Multi-provider LLM implementation with easy fallbacks</li> </ul>"},{"location":"agents/litellm/index.html#getting-started","title":"Getting Started","text":"<p>To use LiteLLM agents, you'll need:</p> <ol> <li>API keys for your preferred LLM providers</li> <li>LiteLLM library installed in your environment</li> <li>Proper configuration of the LiteLLM agent in your guild</li> </ol> <p>Refer to the LiteLLMAgent documentation for detailed implementation instructions. </p>"},{"location":"agents/litellm/litellm_agent.html","title":"LiteLLMAgent","text":"<p>The <code>LiteLLMAgent</code> provides a unified interface to various Large Language Models (LLMs) through integration with the LiteLLM library, enabling consistent interaction with different LLM providers.</p>"},{"location":"agents/litellm/litellm_agent.html#purpose","title":"Purpose","text":"<p>This agent acts as a gateway to language models from providers like OpenAI, Anthropic, Google, and others. It provides a consistent message format and response handling, regardless of the underlying LLM being used.</p>"},{"location":"agents/litellm/litellm_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>LiteLLMAgent</code> when your application needs to:</p> <ul> <li>Interact with various LLMs through a unified interface</li> <li>Switch between different LLM providers without changing application code</li> <li>Maintain conversation history with LLMs</li> <li>Use system prompts and conversation context</li> <li>Leverage LLM tools and function calling capabilities</li> </ul>"},{"location":"agents/litellm/litellm_agent.html#configuration","title":"Configuration","text":"<p>The <code>LiteLLMAgent</code> is configured through the <code>LiteLLMConf</code> class, which allows setting:</p> <ul> <li>The LLM model to use</li> <li>Default system messages</li> <li>Tools/function definitions</li> <li>Conversation memory size</li> </ul> <p>The agent requires appropriate API keys for the selected model, which must be set as environment variables (e.g., <code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, <code>GEMINI_API_KEY</code>).</p>"},{"location":"agents/litellm/litellm_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/litellm/litellm_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/litellm/litellm_agent.html#chatcompletionrequest","title":"ChatCompletionRequest","text":"<p>A request for the LLM to process.</p> <pre><code>class ChatCompletionRequest(BaseModel):\n    messages: List[Union[SystemMessage, UserMessage, AssistantMessage, ToolMessage, FunctionMessage]]\n    model: Optional[str] = None  # Overrides the default model if specified\n    temperature: Optional[float] = None\n    max_tokens: Optional[int] = None\n    tools: Optional[List[ChatCompletionTool]] = None\n    tool_choice: Optional[Union[str, ToolChoice]] = None\n    mock_response: Optional[str] = None  # Used for testing\n    # Other LLM parameters...\n</code></pre> <p>The message types include: - <code>SystemMessage</code>: Instructions to the model about how to behave - <code>UserMessage</code>: Input from the user - <code>AssistantMessage</code>: Previous responses from the assistant - <code>ToolMessage</code>/<code>FunctionMessage</code>: Tool call results</p>"},{"location":"agents/litellm/litellm_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/litellm/litellm_agent.html#chatcompletionresponse","title":"ChatCompletionResponse","text":"<p>Sent when the LLM has generated a response:</p> <pre><code>class ChatCompletionResponse(BaseModel):\n    id: str\n    object: str\n    created: int\n    model: str\n    choices: List[ChatCompletionResponseChoice]\n    usage: Optional[ChatCompletionUsage] = None\n</code></pre> <p>The <code>choices</code> field contains the generated responses, potentially including tool calls.</p>"},{"location":"agents/litellm/litellm_agent.html#chatcompletionerror","title":"ChatCompletionError","text":"<p>Sent when an error occurs during LLM processing:</p> <pre><code>class ChatCompletionError(BaseModel):\n    status_code: ResponseCodes\n    message: str\n    response: Optional[str] = None\n    model: Optional[str] = None\n    request_messages: Optional[List[Any]] = None\n</code></pre>"},{"location":"agents/litellm/litellm_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a chat completion request with messages</li> <li>It prepends any configured system messages from its initialization</li> <li>If conversation memory is enabled, it includes previous exchanges</li> <li>The request is sent to the LLM provider via LiteLLM</li> <li>The response is formatted and returned in a standardized format</li> <li>The conversation is updated in memory for subsequent requests</li> </ol>"},{"location":"agents/litellm/litellm_agent.html#properties","title":"Properties","text":"<p>The <code>LiteLLMConf</code> class supports the following properties:</p> Property Type Description model str The LLM model to use (e.g., \"gpt-4\", \"claude-3-opus\") messages List[Message] Default messages to prepend to all requests tools List[ChatCompletionTool] Tools/functions the model can call message_memory Optional[int] Number of message exchanges to remember temperature Optional[float] Sampling temperature for generation max_tokens Optional[int] Maximum tokens to generate Additional LLM parameters Various Any parameter supported by the LLM provider"},{"location":"agents/litellm/litellm_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.llm.models import SystemMessage\nfrom rustic_ai.litellm.agent import LiteLLMAgent, LiteLLMConf\nfrom rustic_ai.core.guild.agent_ext.depends.llm.models import Models\n\n# Create the agent spec\nllm_agent_spec = (\n    AgentBuilder(LiteLLMAgent)\n    .set_id(\"llm_agent\")\n    .set_name(\"Language Model\")\n    .set_description(\"Interacts with various LLMs via LiteLLM\")\n    .set_properties(\n        LiteLLMConf(\n            model=Models.gpt_4o,  # Use GPT-4o model\n            messages=[\n                SystemMessage(content=\"You are a helpful assistant in the Rustic AI framework.\"),\n            ],\n            message_memory=10,  # Remember 10 message exchanges\n            temperature=0.7,\n        )\n    )\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(llm_agent_spec)\n</code></pre>"},{"location":"agents/litellm/litellm_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.guild.agent_ext.depends.llm.models import (\n    ChatCompletionRequest,\n    UserMessage\n)\n\n# Create a chat completion request\nrequest = ChatCompletionRequest(\n    messages=[\n        UserMessage(content=\"What can Rustic AI be used for?\")\n    ]\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", request)\n</code></pre>"},{"location":"agents/litellm/litellm_agent.html#example-response","title":"Example Response","text":"<p>The agent responds with a <code>ChatCompletionResponse</code> containing the LLM's response:</p> <pre><code>ChatCompletionResponse(\n    id=\"response-12345\",\n    object=\"chat.completion\",\n    created=1685960528,\n    model=\"gpt-4o\",\n    choices=[\n        ChatCompletionResponseChoice(\n            index=0,\n            message=AssistantMessage(\n                content=\"Rustic AI is a multi-agent framework that can be used to build...\"\n            ),\n            finish_reason=\"stop\"\n        )\n    ],\n    usage=ChatCompletionUsage(\n        prompt_tokens=25,\n        completion_tokens=114,\n        total_tokens=139\n    )\n)\n</code></pre>"},{"location":"agents/litellm/litellm_agent.html#testing-with-mock-responses","title":"Testing with Mock Responses","text":"<p>For testing purposes, the <code>ChatCompletionRequest</code> accepts a <code>mock_response</code> parameter that bypasses the actual LLM call:</p> <pre><code>request = ChatCompletionRequest(\n    messages=[UserMessage(content=\"Test question\")],\n    mock_response=\"This is a mocked response for testing.\"\n)\n</code></pre>"},{"location":"agents/litellm/litellm_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires appropriate API keys for the chosen model provider</li> <li>Cost considerations apply based on the model and token usage</li> <li>Different models have different capabilities (e.g., context length, tool calling)</li> <li>Rate limits apply based on your subscription with the LLM provider </li> </ul>"},{"location":"agents/marvin/index.html","title":"Marvin Agents","text":"<p>This section contains documentation for Rustic AI's Marvin integration, which provides classification and structured data extraction capabilities through the Prefect Marvin library.</p>"},{"location":"agents/marvin/index.html#available-agents","title":"Available Agents","text":"<ul> <li>MarvinAgent - Classification and structured data extraction</li> </ul>"},{"location":"agents/marvin/index.html#overview","title":"Overview","text":"<p>Marvin agents enable advanced text classification and structured data extraction within your Rustic AI applications. Using Prefect's Marvin library, these agents can categorize text into predefined classes and extract structured information from unstructured text based on specified schemas.</p>"},{"location":"agents/marvin/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Text classification and categorization</li> <li>Structured data extraction from text</li> <li>Intent recognition in natural language</li> <li>Information parsing and normalization</li> <li>Converting free-form text to structured formats</li> <li>Entity and attribute extraction</li> </ul>"},{"location":"agents/marvin/index.html#getting-started","title":"Getting Started","text":"<p>To use Marvin agents, you'll need:</p> <ol> <li>Marvin library installed in your environment</li> <li>Proper configuration of the Marvin agent in your guild</li> <li>Well-defined categories for classification or schemas for extraction</li> </ol> <p>Refer to the MarvinAgent documentation for detailed implementation instructions. </p>"},{"location":"agents/marvin/marvin_agent.html","title":"MarvinAgent","text":"<p>The <code>MarvinAgent</code> is a specialized agent that provides text classification and data extraction capabilities using Prefect's Marvin library, enabling structured information retrieval from unstructured text.</p>"},{"location":"agents/marvin/marvin_agent.html#purpose","title":"Purpose","text":"<p>This agent serves as a bridge to Marvin's AI-powered classification and extraction capabilities. It can categorize text into predefined categories and extract structured data based on specified schemas, turning unstructured text into structured information.</p>"},{"location":"agents/marvin/marvin_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>MarvinAgent</code> when your application needs to:</p> <ul> <li>Classify text into predefined categories</li> <li>Extract structured information from unstructured text</li> <li>Convert natural language to structured data</li> <li>Implement intent recognition in conversational systems</li> <li>Parse complex text into standardized formats</li> <li>Extract entities, attributes, or key information from text</li> </ul>"},{"location":"agents/marvin/marvin_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/marvin/marvin_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/marvin/marvin_agent.html#classifyrequest","title":"ClassifyRequest","text":"<p>A request to classify text into one of several categories:</p> <pre><code>class ClassifyRequest(BaseModel):\n    source_text: str  # The text to classify\n    categories: List[str]  # List of possible categories\n    instructions: Optional[str] = None  # Optional additional instructions\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#extractrequest","title":"ExtractRequest","text":"<p>A request to extract structured data from text:</p> <pre><code>class ExtractRequest(BaseModel):\n    source_text: str  # The text to extract data from\n    extraction_spec: ExtractionSpec  # Specification for extraction\n</code></pre> <p>Where <code>ExtractionSpec</code> defines: <pre><code>class ExtractionSpec(BaseModel):\n    extraction_class: Type  # Pydantic model defining the data structure to extract\n    extraction_instructions: Optional[str] = None  # Optional instructions\n</code></pre></p>"},{"location":"agents/marvin/marvin_agent.html#classifyandextractrequest","title":"ClassifyAndExtractRequest","text":"<p>A request to both classify text and extract relevant data based on the classification:</p> <pre><code>class ClassifyAndExtractRequest(BaseModel):\n    source_text: str  # The text to process\n    categories: List[str]  # Possible categories for classification\n    classification_instructions: Optional[str] = None  # Instructions for classification\n    category_to_extraction_class: Dict[str, Type]  # Mapping categories to extraction models\n    category_to_extraction_instructions: Dict[str, str] = {}  # Instructions for each category\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/marvin/marvin_agent.html#classifyresponse","title":"ClassifyResponse","text":"<p>Response to a classification request:</p> <pre><code>class ClassifyResponse(BaseModel):\n    source_text: str  # The original text\n    category: str  # The identified category\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#extractresponse","title":"ExtractResponse","text":"<p>Response to an extraction request:</p> <pre><code>class ExtractResponse(BaseModel):\n    source_text: str  # The original text\n    extracted_data: Any  # The extracted structured data\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#classifyandextractresponse","title":"ClassifyAndExtractResponse","text":"<p>Response to a combined classify and extract request:</p> <pre><code>class ClassifyAndExtractResponse(BaseModel):\n    source_text: str  # The original text\n    category: str  # The identified category\n    extracted_data: Any  # The extracted data\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#behavior","title":"Behavior","text":""},{"location":"agents/marvin/marvin_agent.html#classification","title":"Classification","text":"<ol> <li>The agent receives a <code>ClassifyRequest</code> with text and possible categories</li> <li>It calls Marvin's classification function to identify the most appropriate category</li> <li>The agent returns a <code>ClassifyResponse</code> with the identified category</li> </ol>"},{"location":"agents/marvin/marvin_agent.html#extraction","title":"Extraction","text":"<ol> <li>The agent receives an <code>ExtractRequest</code> with text and an extraction specification</li> <li>It calls Marvin's extraction function to parse the text into the specified structure</li> <li>The agent returns an <code>ExtractResponse</code> with the extracted data</li> </ol>"},{"location":"agents/marvin/marvin_agent.html#combined-classification-and-extraction","title":"Combined Classification and Extraction","text":"<ol> <li>The agent receives a <code>ClassifyAndExtractRequest</code> with text, categories, and extraction specifications</li> <li>It first classifies the text into one of the provided categories</li> <li>Based on the classification, it selects the appropriate extraction model</li> <li>It extracts structured data using the selected model</li> <li>The agent returns a <code>ClassifyAndExtractResponse</code> with both the category and extracted data</li> </ol>"},{"location":"agents/marvin/marvin_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.marvin.classifier_agent import MarvinAgent\n\n# Create the agent spec\nmarvin_agent_spec = (\n    AgentBuilder(MarvinAgent)\n    .set_id(\"classifier_extractor\")\n    .set_name(\"Text Analyzer\")\n    .set_description(\"Classifies text and extracts structured data\")\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(marvin_agent_spec)\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#example-classification-request","title":"Example Classification Request","text":"<pre><code>from rustic_ai.core.agents.commons import ClassifyRequest\n\n# Define some categories\ncategories = [\"complaint\", \"inquiry\", \"feedback\", \"support_request\"]\n\n# Create a classification request\nclassify_request = ClassifyRequest(\n    source_text=\"I've been trying to access my account for two days but keep getting an error message. Can someone help me?\",\n    categories=categories,\n    instructions=\"Classify customer service messages\"\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", classify_request)\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#example-extraction-request","title":"Example Extraction Request","text":"<pre><code>from pydantic import BaseModel\nfrom rustic_ai.core.agents.commons import ExtractRequest, ExtractionSpec\n\n# Define an extraction model\nclass CustomerIssue(BaseModel):\n    problem_type: str\n    duration: str\n    urgency_level: str\n    requires_account_access: bool\n\n# Create an extraction request\nextract_request = ExtractRequest(\n    source_text=\"I've been trying to access my account for two days but keep getting an error message. Can someone help me?\",\n    extraction_spec=ExtractionSpec(\n        extraction_class=CustomerIssue,\n        extraction_instructions=\"Extract details about customer service issues\"\n    )\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", extract_request)\n</code></pre>"},{"location":"agents/marvin/marvin_agent.html#technical-details","title":"Technical Details","text":"<p>The agent uses: - Prefect's Marvin library for classification and extraction - Asynchronous processing for classification requests - Synchronous processing for combined classification and extraction</p>"},{"location":"agents/marvin/marvin_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires the Marvin library, which in turn uses LLMs for its functionality</li> <li>Quality of classification and extraction depends on the clarity of instructions</li> <li>Classification works best with well-defined, distinct categories</li> <li>Extraction is more reliable with clearly structured data in the source text</li> <li>More complex extraction schemas may require more detailed instructions</li> <li>For best results, provide clear examples in extraction instructions</li> <li>Marvin may use API calls to external LLMs, which could have rate limits or costs</li> <li>Classification and extraction quality depend on the underlying LLM used by Marvin </li> </ul>"},{"location":"agents/playwright/index.html","title":"Playwright Agents","text":"<p>This section contains documentation for Rustic AI's Playwright integration, which provides web automation and scraping capabilities to your agent system.</p>"},{"location":"agents/playwright/index.html#available-agents","title":"Available Agents","text":"<ul> <li>PlaywrightScraperAgent - Automated web scraping and interaction using Playwright</li> </ul>"},{"location":"agents/playwright/index.html#overview","title":"Overview","text":"<p>Playwright agents enable web automation within your Rustic AI applications. These agents can navigate websites, extract content, interact with web elements, and capture screenshots or other data from web pages. They leverage the Microsoft Playwright library, which provides cross-browser automation capabilities.</p>"},{"location":"agents/playwright/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Web scraping and content extraction</li> <li>Automated testing of web applications</li> <li>Form submission and data entry</li> <li>Monitoring website changes</li> <li>Generating screenshots or PDFs of web content</li> <li>Interacting with dynamic web applications</li> </ul>"},{"location":"agents/playwright/index.html#getting-started","title":"Getting Started","text":"<p>To use Playwright agents, you'll need:</p> <ol> <li>Playwright installed in your environment</li> <li>Proper configuration of the Playwright agent in your guild</li> <li>Clear instructions on the web interactions to perform</li> </ol> <p>Refer to the PlaywrightScraperAgent documentation for detailed implementation instructions. </p>"},{"location":"agents/playwright/playwright_scraper_agent.html","title":"PlaywrightScraperAgent","text":"<p>The <code>PlaywrightScraperAgent</code> is a web scraping agent that uses the Playwright framework to automate browser interactions and extract content from web pages.</p>"},{"location":"agents/playwright/playwright_scraper_agent.html#purpose","title":"Purpose","text":"<p>This agent provides automated web scraping capabilities within a Rustic AI guild, enabling retrieval of web content for further processing. It's designed to handle requests for scraping multiple URLs and returns the scraped content in the requested format.</p>"},{"location":"agents/playwright/playwright_scraper_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>PlaywrightScraperAgent</code> when your application needs to:</p> <ul> <li>Extract content from web pages</li> <li>Store web content for later analysis</li> <li>Convert HTML content to more processable formats like Markdown</li> <li>Get web content for LLM processing or other AI tasks</li> </ul>"},{"location":"agents/playwright/playwright_scraper_agent.html#dependencies","title":"Dependencies","text":"<p>The <code>PlaywrightScraperAgent</code> requires:</p> <ul> <li>filesystem (Guild-level dependency): A file system implementation for storing scraped content</li> </ul>"},{"location":"agents/playwright/playwright_scraper_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/playwright/playwright_scraper_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/playwright/playwright_scraper_agent.html#webscrapingrequest","title":"WebScrapingRequest","text":"<p>A request to scrape web pages.</p> <pre><code>class WebScrapingRequest(BaseModel):\n    id: str  # ID of the request\n    links: List[MediaLink]  # URLs to scrape\n    output_format: ScrapingOutputFormat = ScrapingOutputFormat.TEXT_HTML  # Output format\n    transformer_options: JsonDict = {}  # Options for transforming the content\n</code></pre> <p>The <code>ScrapingOutputFormat</code> enum supports: - <code>TEXT_HTML</code>: Returns the content as HTML - <code>MARKDOWN</code>: Converts the HTML to Markdown before returning</p>"},{"location":"agents/playwright/playwright_scraper_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/playwright/playwright_scraper_agent.html#medialink","title":"MediaLink","text":"<p>For each URL successfully scraped, a <code>MediaLink</code> message is emitted with the scraped content:</p> <pre><code>class MediaLink(BaseModel):\n    url: str  # Path to the scraped file\n    name: str  # Filename\n    metadata: Dict  # Metadata including original URL, title, etc.\n    on_filesystem: bool  # Always True for scraped content\n    mimetype: str  # Content type\n    encoding: str  # Always \"utf-8\"\n</code></pre>"},{"location":"agents/playwright/playwright_scraper_agent.html#webscrapingcompleted","title":"WebScrapingCompleted","text":"<p>Sent when all requested URLs have been processed:</p> <pre><code>class WebScrapingCompleted(BaseModel):\n    id: str  # ID of the original request\n    links: List[MediaLink]  # List of all successfully scraped URLs\n</code></pre>"},{"location":"agents/playwright/playwright_scraper_agent.html#errormessage","title":"ErrorMessage","text":"<p>Sent when scraping fails for a specific URL:</p> <pre><code>class ErrorMessage(BaseModel):\n    agent_type: str\n    error_type: str\n    error_message: str\n</code></pre>"},{"location":"agents/playwright/playwright_scraper_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent launches a headless Chrome browser using Playwright</li> <li>For each URL in the request:<ul> <li>Navigates to the URL</li> <li>Checks for successful HTTP status (200)</li> <li>Extracts the page content</li> <li>Transforms the content (to Markdown if requested)</li> <li>Stores the content to the filesystem</li> <li>Emits a MediaLink message for the stored content</li> </ul> </li> <li>After processing all URLs, it emits a WebScrapingCompleted message</li> </ol> <p>The scraped content is saved in the <code>scraped_data/</code> directory with filenames based on a hash of the content.</p>"},{"location":"agents/playwright/playwright_scraper_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.playwright.agent import PlaywrightScraperAgent\n\n# Define a file system dependency\nfilesystem = DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.FileSystemResolver\",\n    properties={\n        \"path_base\": \"/tmp\",\n        \"protocol\": \"file\",\n        \"storage_options\": {\n            \"auto_mkdir\": True,\n        },\n    },\n)\n\n# Create the agent spec\nplaywright_agent_spec = (\n    AgentBuilder(PlaywrightScraperAgent)\n    .set_id(\"web_scraper\")\n    .set_name(\"Web Scraper\")\n    .set_description(\"Scrapes web content using Playwright\")\n    .build_spec()\n)\n\n# Add dependency to guild when launching\nguild_builder.add_dependency(\"filesystem\", filesystem)\nguild_builder.add_agent_spec(playwright_agent_spec)\n</code></pre>"},{"location":"agents/playwright/playwright_scraper_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.core.agents.commons.media import MediaLink\nfrom rustic_ai.playwright.agent import WebScrapingRequest, ScrapingOutputFormat\n\n# Create a request to scrape two URLs and convert to Markdown\nrequest = WebScrapingRequest(\n    links=[\n        MediaLink(url=\"https://example.com\"),\n        MediaLink(url=\"https://rustic.ai/docs\"),\n    ],\n    output_format=ScrapingOutputFormat.MARKDOWN\n)\n\n# Send to the agent via messaging system\nclient.publish(\"default_topic\", request)\n</code></pre>"},{"location":"agents/playwright/playwright_scraper_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>The agent requires a working installation of Playwright and a browser</li> <li>For security, it's recommended to run with appropriate sandboxing</li> <li>Consider rate limiting and respecting robots.txt for production use</li> <li>Large pages may consume significant memory </li> </ul>"},{"location":"agents/serpapi/index.html","title":"SerpAPI Agents","text":"<p>This section contains documentation for Rustic AI's SerpAPI integration, which provides search engine capabilities to your agent system.</p>"},{"location":"agents/serpapi/index.html#available-agents","title":"Available Agents","text":"<ul> <li>SERPAgent - Retrieve search engine results via the SerpAPI service</li> </ul>"},{"location":"agents/serpapi/index.html#overview","title":"Overview","text":"<p>SerpAPI agents allow you to incorporate search engine functionality into your Rustic AI applications, enabling agents to retrieve real-time information from the web. These agents act as bridges to the SerpAPI service, which provides structured search results from various search engines.</p>"},{"location":"agents/serpapi/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Information retrieval from the web</li> <li>Research automation</li> <li>Data gathering for analysis</li> <li>Fact-checking and verification</li> <li>Trend monitoring and competitive analysis</li> </ul>"},{"location":"agents/serpapi/index.html#getting-started","title":"Getting Started","text":"<p>To use SerpAPI agents, you'll need:</p> <ol> <li>A SerpAPI API key (available from serpapi.com)</li> <li>Proper configuration of the SerpAPI agent in your guild</li> </ol> <p>Refer to the SERPAgent documentation for detailed implementation instructions. </p>"},{"location":"agents/serpapi/serp_agent.html","title":"SERPAgent","text":"<p>The <code>SERPAgent</code> provides search engine capabilities to a Rustic AI guild by integrating with the SerpAPI service, which offers access to search results from various search engines.</p>"},{"location":"agents/serpapi/serp_agent.html#purpose","title":"Purpose","text":"<p>This agent allows access to structured search engine results, enabling information retrieval capabilities within a guild. It acts as a bridge between your application and search engines like Google, Bing, DuckDuckGo, and others.</p>"},{"location":"agents/serpapi/serp_agent.html#when-to-use","title":"When to Use","text":"<p>Use the <code>SERPAgent</code> when your application needs to:</p> <ul> <li>Retrieve information from search engines</li> <li>Get structured search results for a query</li> <li>Access multiple search engines through a unified interface</li> <li>Gather web information without directly scraping websites</li> </ul>"},{"location":"agents/serpapi/serp_agent.html#configuration","title":"Configuration","text":"<p>The <code>SERPAgent</code> requires an API key from SerpAPI. This should be set as an environment variable:</p> <pre><code>SERP_API_KEY=your_api_key_here\n</code></pre>"},{"location":"agents/serpapi/serp_agent.html#message-types","title":"Message Types","text":""},{"location":"agents/serpapi/serp_agent.html#input-messages","title":"Input Messages","text":""},{"location":"agents/serpapi/serp_agent.html#serpquery","title":"SERPQuery","text":"<p>A request to search for information.</p> <pre><code>class SERPQuery(BaseModel):\n    engine: str  # Search engine to use (google, bing, etc.)\n    query: str  # The search query\n    id: str = \"\"  # Optional ID for tracking\n    num: Optional[int] = 12  # Number of results to return\n    start: Optional[int] = 0  # Starting position for pagination\n</code></pre> <p>Supported search engines include: - google - bing - baidu - yahoo - duckduckgo - ebay - yandex - home_depot - google_scholar - youtube - walmart - google_maps - google_patents</p>"},{"location":"agents/serpapi/serp_agent.html#output-messages","title":"Output Messages","text":""},{"location":"agents/serpapi/serp_agent.html#serpresults","title":"SERPResults","text":"<p>Sent when a search is successfully completed:</p> <pre><code>class SERPResults(BaseModel):\n    engine: str  # The engine used for search\n    query: str  # The query that was searched\n    count: int  # Number of results returned\n    id: str = \"\"  # ID from the original request\n    results: List[MediaLink]  # The search results\n    total_results: Optional[int] = None  # Total number of results available\n</code></pre> <p>Each result is a <code>MediaLink</code> with metadata containing: - title: The title of the search result - favicon: The favicon URL of the result website - search_position: The position in search results - snippet: A text snippet from the result - date: Publication date if available - query_id: ID of the original query</p>"},{"location":"agents/serpapi/serp_agent.html#searcherror","title":"SearchError","text":"<p>Sent when a search fails:</p> <pre><code>class SearchError(BaseModel):\n    id: str = \"\"  # ID from the original request\n    response: JsonDict  # Error details from SerpAPI\n</code></pre>"},{"location":"agents/serpapi/serp_agent.html#behavior","title":"Behavior","text":"<ol> <li>The agent receives a search query with a specified search engine</li> <li>It formats the query appropriately for the chosen search engine</li> <li>The query is sent to SerpAPI</li> <li>Results are transformed into a structured format with rich metadata</li> <li>The agent returns the results as a <code>SERPResults</code> message with <code>MediaLink</code> objects for each result</li> </ol>"},{"location":"agents/serpapi/serp_agent.html#sample-usage","title":"Sample Usage","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.serpapi.agent import SERPAgent\n\n# Create the agent spec\nserp_agent_spec = (\n    AgentBuilder(SERPAgent)\n    .set_id(\"search_agent\")\n    .set_name(\"Search Agent\")\n    .set_description(\"Provides search engine results using SerpAPI\")\n    .build_spec()\n)\n\n# Add to guild\nguild_builder.add_agent_spec(serp_agent_spec)\n</code></pre>"},{"location":"agents/serpapi/serp_agent.html#example-request","title":"Example Request","text":"<pre><code>from rustic_ai.serpapi.agent import SERPQuery\n\n# Create a search request\nsearch_request = SERPQuery(\n    engine=\"google\",\n    query=\"rustic ai multi-agent systems\",\n    num=5  # Request 5 results\n)\n\n# Send to the agent\nclient.publish(\"default_topic\", search_request)\n</code></pre>"},{"location":"agents/serpapi/serp_agent.html#example-response","title":"Example Response","text":"<p>The agent responds with a <code>SERPResults</code> message containing search results:</p> <pre><code>SERPResults(\n    engine=\"google\",\n    query=\"rustic ai multi-agent systems\",\n    count=5,\n    results=[\n        MediaLink(\n            url=\"https://example.com/result1\",\n            name=\"result1.html\",\n            metadata={\n                \"title\": \"Rustic AI: A Framework for Multi-Agent Systems\",\n                \"snippet\": \"Rustic AI is a powerful framework for building...\",\n                \"search_position\": 1,\n                # Other metadata...\n            },\n            mimetype=\"text/html\",\n            encoding=\"utf-8\"\n        ),\n        # More results...\n    ],\n    total_results=14700\n)\n</code></pre>"},{"location":"agents/serpapi/serp_agent.html#notes-and-limitations","title":"Notes and Limitations","text":"<ul> <li>Requires a SerpAPI key with sufficient quota</li> <li>Search engines have different parameters and return slightly different result structures</li> <li>Rate limits apply based on your SerpAPI subscription level</li> <li>Search results reflect what's available through SerpAPI's service, which may have slight delays compared to direct searches </li> </ul>"},{"location":"api/index.html","title":"Rustic AI API Reference","text":"<p>Welcome to the API reference documentation for Rustic AI. This section provides detailed information about the public API interfaces available for interacting with the Rustic AI framework.</p>"},{"location":"api/index.html#overview","title":"Overview","text":"<p>The Rustic AI API allows you to:</p> <ul> <li>Create and manage guilds and agents programmatically</li> <li>Interact with existing agent systems</li> <li>Build integrations with external services</li> <li>Monitor and control Rustic AI deployments</li> </ul> <p>NOTE: We are working on writing the documentation for this project. (Contributions Welcome)</p>"},{"location":"core/index.html","title":"Rustic AI Core","text":"<p>Rustic AI Core provides the foundational interfaces and components necessary for building human-centered, multi-agent applications. It includes abstractions for agents, guilds, messaging, execution engines, and dependency management.</p>"},{"location":"core/index.html#sections","title":"Sections","text":"<ul> <li>Architecture</li> <li>Agents</li> <li>Guilds</li> <li>Messaging<ul> <li>Socket Messaging Backend</li> </ul> </li> <li>Execution<ul> <li>Multiprocess Execution</li> </ul> </li> <li>Dependencies</li> <li>State Management </li> </ul>"},{"location":"core/agents.html","title":"Agents","text":"<p>Agents are the fundamental, autonomous, and message-driven entities in Rustic AI. They encapsulate specific logic, maintain their own state, communicate with other agents via asynchronous messages, and collaborate within a Guild to achieve complex tasks. Agents can represent automated processes (bots) or act as proxies for human users.</p> <p>Prerequisites: Familiarity with Guilds, Messaging, State Management, and Dependencies is recommended.</p>"},{"location":"core/agents.html#table-of-contents","title":"Table of Contents","text":"<ul> <li>Core Concepts</li> <li>Defining an Agent Class</li> <li>Agent Specification (AgentSpec)</li> <li>The AgentMetaclass and its Magic</li> <li>Message Handling</li> <li>Agent Fixtures and Modifiers</li> <li>Dependency Injection in Handlers</li> <li>Agent State Management</li> <li>Error Handling Strategies</li> <li>Testing Agents in Isolation</li> <li>Agent Mixins: Behind-the-Scenes Support</li> <li>Advanced Topics</li> </ul>"},{"location":"core/agents.html#core-concepts","title":"Core Concepts","text":"<ul> <li>Encapsulation: Agents bundle their own logic, configuration, and state.</li> <li>Message-Driven: Agents react to incoming messages, process them, and can send new messages.</li> <li>Stateful: Agents can maintain internal state across message interactions. See State Management.</li> <li>Collaborative: Agents operate within Guilds, allowing for coordinated multi-agent workflows.</li> <li>Configurable: Agent behavior is defined by their Python class and configured via an <code>AgentSpec</code>.</li> </ul>"},{"location":"core/agents.html#agent-types-and-modes","title":"Agent Types and Modes","text":"<p>Rustic AI provides two enumerations that define fundamental characteristics of agents:</p>"},{"location":"core/agents.html#agenttype","title":"AgentType","text":"<p><code>AgentType</code> specifies the nature of the agent:</p> <pre><code>from rustic_ai.core.guild import AgentType\n\n# Usage:\nclass MyAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec, agent_type=AgentType.BOT)  # Default is BOT\n</code></pre> Value Description <code>AgentType.BOT</code> A fully automated agent that operates without human intervention (default) <code>AgentType.HUMAN</code> Represents a human user or requires human participation"},{"location":"core/agents.html#agentmode","title":"AgentMode","text":"<p><code>AgentMode</code> defines how the agent is executed by the execution engine:</p> <pre><code>from rustic_ai.core.guild import AgentMode\n\n# Usage:\nclass MyAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec, agent_mode=AgentMode.LOCAL)  # Default is LOCAL\n</code></pre> Value Description <code>AgentMode.LOCAL</code> Runs in the same process as the Guild (default) <code>AgentMode.REMOTE</code> Runs in a separate process (potentially distributed) <p>These values are used by the execution engine to determine how to instantiate and run the agent, especially in distributed or multi-process environments.</p>"},{"location":"core/agents.html#defining-an-agent-class","title":"Defining an Agent Class","text":"<p>To create a custom agent, you define a Python class that inherits from <code>rustic_ai.core.guild.Agent</code>. This base class, along with the powerful <code>AgentMetaclass</code>, provides the core machinery for message handling, dependency injection, and lifecycle management.</p>"},{"location":"core/agents.html#agent-properties-baseagentprops","title":"Agent Properties (<code>BaseAgentProps</code>)","text":"<p>Each agent can have its own set of configurable properties. These are defined in a Pydantic model that inherits from <code>rustic_ai.core.guild.dsl.BaseAgentProps</code>.</p> <p><pre><code>from rustic_ai.core.guild import Agent, agent  # agent provides the @agent.processor decorator\nfrom rustic_ai.core.guild.dsl import BaseAgentProps, AgentSpec\n\n# 1. Define messages models\nclass GreetRequest(BaseModel):\n    name: Optional[str]\n\nclass GreetResponse(BaseModel):\n    greeting: str\n    count: int\n\n# 1. Define Properties Model (Optional but Recommended)\nclass MyGreeterAgentProps(BaseAgentProps):\n    greeting_prefix: str = \"Hello\"\n    default_name: str = \"World\"\n\n# 2. Define the Agent Class\nclass GreeterAgent(Agent[MyGreeterAgentProps]): # Generic type specifies the props model\n    def __init__(self, agent_spec: AgentSpec[MyGreeterAgentProps]):\n        super().__init__(agent_spec)\n        # Access configured properties:\n        self.greeting_prefix = self.get_spec().props.greeting_prefix\n        self.default_name = self.get_spec().props.default_name\n        self.greet_count = 0\n\n    @agent.processor(clz=GreetRequest) # Handles raw string payloads\n    def handle_name(self, ctx: agent.ProcessContext[GreetRequest]):\n        name_to_greet = ctx.payload.name if ctx.payload.name else self.default_name\n        response = f\"{self.greeting_prefix}, {name_to_greet}!\"\n        self.greet_count += 1\n\n        # Update agent's own state (illustrative, actual state updates are more structured)\n        # self._state[\"greet_count\"] = self.greet_count \n\n        ctx.send_dict(GreetResponse(greeting = response, count=count))\n\n# To use this agent, you'd create an AgentSpec for it, often via AgentBuilder.\n# from rustic_ai.core.guild.builders import AgentBuilder\n# greeter_spec = AgentBuilder(GreeterAgent) \\\\\n#     .set_name(\"MyGreeter\") \\\\\n#     .set_description(\"A friendly greeter agent.\") \\\\\n#     .set_properties(MyGreeterAgentProps(greeting_prefix=\"Greetings\")) \\\\\n#     .build_spec()\n</code></pre> - The agent class is generic: <code>Agent[MyAgentPropsType]</code>. This tells the system about the expected structure of its <code>properties</code>. - The <code>__init__</code> method must call <code>super().__init__(agent_spec)</code>. - The <code>agent_spec</code> (an instance of <code>AgentSpec[MyAgentPropsType]</code>) provides access to configured properties via <code>self.get_spec().props</code>.</p>"},{"location":"core/agents.html#agent-specification-agentspec","title":"Agent Specification (<code>AgentSpec</code>)","text":"<p>As introduced in Guilds, an <code>AgentSpec</code> is a data structure (typically created via <code>AgentBuilder</code> or loaded from YAML/JSON) that defines an agent's configuration. Key fields relevant from an agent's perspective:</p> <ul> <li><code>id</code> (str): Unique identifier.</li> <li><code>name</code> (str): Human-readable name.</li> <li><code>description</code> (str): Purpose of the agent.</li> <li><code>class_name</code> (str): The fully qualified Python class name of the agent (e.g., <code>\"my_project.agents.GreeterAgent\"</code>).</li> <li><code>properties</code> (Pydantic Model | Dict): An instance of the agent's properties model (e.g., <code>MyGreeterAgentProps</code>) or a dictionary that can be validated into it. This is how you customize an agent instance.</li> <li><code>additional_topics</code> (List[str]): Specific message topics the agent subscribes to, beyond the default guild topic.</li> <li><code>listen_to_default_topic</code> (bool): If <code>True</code> (default), the agent listens to messages on the guild's default topic.</li> <li><code>dependency_map</code> (Dict[str, DependencySpec]): Agent-specific dependencies. These can override or supplement guild-level dependencies.</li> <li><code>act_only_when_tagged</code> (bool): If <code>True</code>, the agent will only process messages where its <code>AgentTag</code> (ID or name) is explicitly included in the message's <code>recipient_list</code>. This is useful for targeted communication in busy topics.</li> <li><code>predicates</code> (Dict[str, SimpleRuntimePredicate]): A dictionary mapping method names (of <code>@processor</code> decorated methods) to <code>SimpleRuntimePredicate</code> objects. A predicate contains a JSONata expression that is evaluated against the incoming message, agent state, and guild state. The handler method is only invoked if the predicate evaluates to true.<pre><code>// Example predicate in AgentSpec (conceptual)\n\"predicates\": {\n    \"handle_urgent_task\": {\n        \"expression\": \"message.priority &gt; 7 and agent_state.is_available\"\n    }\n}\n</code></pre> </li> </ul>"},{"location":"core/agents.html#the-agentmetaclass-and-its-magic","title":"The <code>AgentMetaclass</code> and its Magic","text":"<p>The <code>Agent</code> base class uses <code>AgentMetaclass</code>. This metaclass works behind the scenes during agent class definition to automate several setup tasks:</p> <ul> <li>Handler Registration: It inspects the agent class for methods decorated with <code>@agent.processor(...)</code> and registers them as message handlers.</li> <li>Fixture Registration: It finds methods decorated with <code>@AgentFixtures.*</code> and registers them as lifecycle hooks or message modifiers.</li> <li>Properties Type Inference: It determines the agent's specific properties type (e.g., <code>MyGreeterAgentProps</code>) from the generic type hint (<code>Agent[MyGreeterAgentProps]</code>).</li> <li>Dependency Analysis: It can analyze <code>@processor</code> methods for <code>depends_on</code> arguments to understand their dependencies.</li> <li>Mixin Injection: It automatically includes default mixins (e.g., <code>StateRefresherMixin</code>, <code>HealthMixin</code>, <code>TelemetryMixin</code>) that provide common cross-cutting concerns.</li> </ul> <p>This automation reduces boilerplate and allows developers to focus on the agent's core logic.</p>"},{"location":"core/agents.html#message-handling","title":"Message Handling","text":"<p>Agents are fundamentally message-driven. The process of an agent receiving and handling a message involves several steps, orchestrated by the <code>AgentMetaclass</code> and the <code>Agent</code> base class.</p>"},{"location":"core/agents.html#the-agentprocessor-decorator","title":"The <code>@agent.processor</code> Decorator","text":"<p>Methods that handle incoming messages are decorated with <code>@agent.processor</code>.</p> <pre><code>from pydantic import BaseModel\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent import ProcessContext\nfrom rustic_ai.core.messaging.core import JsonDict # For raw JSON\n\nclass MyData(BaseModel):\n    value: str\n    count: int\n\nclass MyOtherAgent(Agent[BaseAgentProps]):\n    # Handles messages where payload is MyData\n    @agent.processor(clz=MyData)\n    def handle_my_data(self, ctx: ProcessContext[MyData]):\n        data_object = ctx.payload # data_object is an instance of MyData\n        # ... process data_object ...\n        ctx.send(AnotherMessage(...))\n\n    # Handles messages where payload is a raw JSON dictionary\n    @agent.processor(clz=JsonDict)\n    def handle_any_json(self, ctx: ProcessContext[JsonDict]):\n        raw_payload = ctx.payload # raw_payload is a dict\n        # ... process raw_payload ...\n        ctx.send_dict({\"status\": \"processed raw json\"})\n\n    # Handles messages of MyData type only on \"essential\" topics,\n    # and also injects a 'db_connection' dependency.\n    @agent.processor(clz=MyData, handle_essential=True, depends_on=[\"db_connection\"])\n    def handle_essential_data(self, ctx: ProcessContext[MyData], db_connection: Any):\n        # This handler will run for MyData messages on system/status topics\n        # even if the agent doesn't explicitly subscribe to them.\n        # db_connection is resolved and injected.\n        pass\n</code></pre> <ul> <li><code>clz</code>: Specifies the expected Pydantic model for the message payload. If the incoming message's <code>format</code> matches the qualified name of this model, the payload is automatically parsed and validated into an instance of this model. Use <code>JsonDict</code> to receive the payload as a raw dictionary without parsing.</li> <li><code>handle_essential</code> (bool, default <code>False</code>): If <code>True</code>, this handler can process messages on essential guild topics (like status or system topics), even if the agent isn't explicitly subscribed to them or if the message isn't directly addressed to it.</li> <li><code>depends_on</code> (List[str | AgentDependency], optional): A list of dependency keys. These dependencies are resolved at runtime and injected as arguments into the handler method. See Dependency Injection in Handlers.</li> <li><code>predicate</code> (Callable[[Agent, Message], bool], optional, less common): An older style of predicate, a callable that takes the agent instance and the raw message and returns <code>True</code> if the handler should run. Prefer <code>AgentSpec.predicates</code> for declarative JSONata-based predicates.</li> </ul>"},{"location":"core/agents.html#asynchronous-handlers","title":"Asynchronous Handlers","text":"<pre><code>from aiohttp import ClientSession\n\nclass AsyncAgent(Agent[BaseAgentProps]):\n    @agent.processor(clz=SearchQuery)\n    async def search_web(self, ctx: ProcessContext[SearchQuery]):\n        query = ctx.payload.query\n\n        # Perform asynchronous operations\n        async with ClientSession() as session:\n            async with session.get(f\"https://api.example.com/search?q={query}\") as response:\n                result = await response.json()\n\n        # Process results and respond\n        ctx.send(SearchResult(results=result[\"items\"]))\n</code></pre> <p>When an async handler is invoked: 1. The framework detects it's an async function via <code>inspect.iscoroutinefunction()</code> 2. The <code>ProcessorHelper.run_coroutine()</code> method handles scheduling:    - If in an already running event loop, it creates a new task    - Otherwise, it calls <code>asyncio.run()</code> to run the coroutine to completion</p> <p>This allows your agent to perform non-blocking I/O operations like network requests or database queries without blocking the entire agent/guild.</p>"},{"location":"core/agents.html#incoming-message-flow","title":"Incoming Message Flow","text":"<ol> <li>Delivery: A message is delivered to the agent's internal <code>_on_message(self, message: Message)</code> method by the messaging system.</li> <li>Handler Discovery:     *   The <code>Agent</code> base class, using handler maps prepared by <code>AgentMetaclass</code>, identifies applicable <code>@processor</code> methods.     *   This matching considers:         *   The <code>format</code> string in the <code>Message</code> against the <code>clz</code> argument of <code>@processor</code>.         *   If <code>agent_spec.act_only_when_tagged</code> is <code>True</code>, the message must explicitly tag the agent.         *   The <code>handle_essential</code> flag of the processor if the message is on an essential topic.</li> <li>Processing Each Applicable Handler: For each matched handler method:     *   Runtime Predicate Check: If a predicate is defined for this handler in <code>agent_spec.predicates</code>, it's evaluated. If it returns <code>False</code>, the handler is skipped.     *   Dependency Resolution: Dependencies specified in <code>@processor(depends_on=[...])</code> are resolved.     *   <code>ProcessContext</code> Creation: A <code>ProcessContext</code> instance (<code>ctx</code>) is created, providing access to the message, payload, agent state, and sending capabilities.     *   <code>before_process</code> Fixtures: Any methods decorated with <code>@AgentFixtures.before_process</code> are executed.     *   Handler Invocation: The handler method is called with <code>self</code> (the agent instance), <code>ctx</code> (the <code>ProcessContext</code>), and any resolved dependencies as arguments.     *   <code>after_process</code> Fixtures: Any methods decorated with <code>@AgentFixtures.after_process</code> are executed.     *   Error Handling: If the handler raises an unhandled exception, it's caught, wrapped in an <code>ErrorMessage</code>, and sent out (triggering <code>on_send_error</code> fixtures). The exception might also be bubbled to the execution engine.</li> </ol>"},{"location":"core/agents.html#the-processcontext-ctx","title":"The <code>ProcessContext</code> (<code>ctx</code>)","text":"<p>The <code>ProcessContext</code> is passed as the second argument (after <code>self</code>) to every message handler and provides essential tools for message processing:</p> <ul> <li><code>ctx.payload</code> -&gt; <code>MDT</code> (MessageDataType):     *   If the <code>@processor</code> specified a Pydantic model (e.g., <code>clz=MyData</code>), <code>ctx.payload</code> is an instance of that model, automatically parsed and validated from the message's payload.     *   If <code>clz=JsonDict</code>, <code>ctx.payload</code> is the raw dictionary payload.</li> <li><code>ctx.message</code> -&gt; <code>Message</code>: The full incoming <code>Message</code> object, including headers, sender/recipient info, topic, <code>routing_slip</code>, etc.</li> <li><code>ctx.agent</code> -&gt; <code>Agent</code>: The instance of the agent processing the message.</li> <li><code>ctx.method_name</code> -&gt; <code>str</code>: The name of the handler method currently being executed.</li> <li><code>ctx.update_context(updates: JsonDict)</code>: Updates a temporary, per-message-processing-flow, session-like state. This context is passed along if messages are sent via <code>ctx.send()</code> and the routing rules dictate context propagation.</li> <li><code>ctx.get_context() -&gt; JsonDict</code>: Retrieves the current per-message-flow context.</li> <li><code>ctx.add_routing_step(routing_entry: RoutingRule)</code>: Adds a new <code>RoutingRule</code> to the <code>RoutingSlip</code> of the original incoming message. This can dynamically alter the message's future path if it's part of a multi-step workflow.</li> <li>Sending Methods:     *   <code>ctx.send(payload: BaseModel, new_thread: bool = False, forwarding: bool = False) -&gt; List[GemstoneID]</code>:         Sends a new message with a Pydantic <code>BaseModel</code> as its payload.         -   <code>new_thread</code>: If <code>True</code>, starts a new message thread ID.         -   <code>forwarding</code>: If <code>True</code>, indicates the message is being forwarded, which can affect routing rule application (e.g., <code>mark_forwarded</code>).     *   <code>ctx.send_dict(payload: JsonDict, format: str = MessageConstants.RAW_JSON_FORMAT, new_thread: bool = False, forwarding: bool = False) -&gt; List[GemstoneID]</code>:         Sends a new message with a raw dictionary as its payload. The <code>format</code> string should indicate the type of the payload.     *   <code>ctx.send_error(payload: BaseModel) -&gt; List[GemstoneID]</code>:         Sends a new message marked as an error, typically using an <code>ErrorMessage</code> or a custom error model.<p>When <code>ctx.send*</code> is called:   1.  Registered <code>@AgentFixtures.on_send</code> (or <code>@AgentFixtures.on_send_error</code> for <code>send_error</code>) fixtures are executed.   2.  The routing logic (detailed in Guilds and Messaging) determines the next step(s) based on the incoming message's <code>RoutingSlip</code> or guild-level routes.   3.  For each routing step, a new <code>Message</code> is constructed.   4.  Registered <code>@AgentFixtures.outgoing_message_modifier</code> fixtures can alter the new message before it's published.   5.  The message is published via the agent's messaging client.   6.  IDs of the sent messages are returned.</p> </li> </ul>"},{"location":"core/agents.html#end-to-end-handler-example","title":"End-to-End Handler Example","text":"<pre><code>from pydantic import BaseModel\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent import ProcessContext\nfrom rustic_ai.core.guild.dsl import BaseAgentProps\n\nclass UserQuery(BaseModel):\n    text: str\n    user_id: str\n\nclass QueryResponse(BaseModel):\n    answer: str\n    source: str\n\nclass MyQnAAgent(Agent[BaseAgentProps]):\n    @agent.processor(clz=UserQuery)\n    def handle_query(self, ctx: ProcessContext[UserQuery]):\n        query_text = ctx.payload.text # Accessing typed payload\n        user = ctx.payload.user_id\n\n        # Illustrative: update per-message context\n        ctx.update_context({\"current_user_id\": user, \"query_received_at\": \"timestamp\"})\n\n        print(f\"Agent {self.name} received query: '{query_text}' from {user}\")\n        print(f\"Original message ID: {ctx.message.id}, Topic: {ctx.message.topic_published_to}\")\n\n        # Simulate processing\n        answer = f\"Answer to '{query_text}'\"\n\n        response_payload = QueryResponse(answer=answer, source=self.name)\n\n        # Send the response\n        # Routing will be determined by incoming message's slip or guild routes\n        sent_ids = ctx.send(response_payload) \n        print(f\"Sent response message(s) with IDs: {sent_ids}\")\n</code></pre>"},{"location":"core/agents.html#agent-fixtures-and-modifiers-agentfixtures","title":"Agent Fixtures and Modifiers (<code>@AgentFixtures</code>)","text":"<p>Fixtures allow you to inject logic at various points in an agent's message processing lifecycle or when messages are sent. They are methods in your agent class decorated with specific decorators from <code>rustic_ai.core.guild.agent.AgentFixtures</code>.</p> <ul> <li><code>@AgentFixtures.before_process</code>:     -   Signature: <code>def my_fixture(self, ctx: ProcessContext[MDT])</code>     -   Called before each message handler (<code>@processor</code>) method is executed for a message that the handler matches. <code>MDT</code> is the type the handler expects.</li> <li><code>@AgentFixtures.after_process</code>:     -   Signature: <code>def my_fixture(self, ctx: ProcessContext[MDT])</code>     -   Called after each message handler method completes (normally or with an exception that was handled by the system).</li> <li><code>@AgentFixtures.on_send</code>:     -   Signature: <code>def my_fixture(self, ctx: ProcessContext[Any])</code>     -   Called when <code>ctx.send()</code> or <code>ctx.send_dict()</code> is invoked (but not <code>ctx.send_error()</code>), before the routing logic determines the final outgoing message(s). The <code>ctx</code> here is the context of the handler that initiated the send.</li> <li><code>@AgentFixtures.on_send_error</code>:     -   Signature: <code>def my_fixture(self, ctx: ProcessContext[Any])</code>     -   Called when <code>ctx.send_error()</code> is invoked, before the routing logic.</li> <li><code>@AgentFixtures.outgoing_message_modifier</code>:     -   Signature: <code>def my_fixture(self, ctx: ProcessContext[Any], message_to_be_sent: Message)</code>     -   Called for each message that is about to be published via the agent's client (resulting from <code>ctx.send*</code> calls). Allows direct modification of the <code>message_to_be_sent</code> object (e.g., adding custom headers) before it goes out.</li> </ul> <pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent import AgentFixtures, ProcessContext, Message\nfrom rustic_ai.core.guild.dsl import BaseAgentProps\nfrom pydantic import BaseModel\n\nclass LoggableEvent(BaseModel):\n    event_data: str\n\nclass FixtureDemoAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec):\n        super().__init__(agent_spec)\n        self.processed_count = 0\n        self.sent_count = 0\n\n    @agent.processor(LoggableEvent)\n    def log_event(self, ctx: ProcessContext[LoggableEvent]):\n        print(f\"HANDLER: Processing event: {ctx.payload.event_data}\")\n        ctx.send(LoggableEvent(event_data=\"Response to \" + ctx.payload.event_data))\n\n    @AgentFixtures.before_process\n    def count_incoming(self, ctx: ProcessContext[LoggableEvent]):\n        self.processed_count +=1\n        print(f\"BEFORE_PROCESS: Message #{self.processed_count} for {ctx.method_name}. Payload: {ctx.payload}\")\n\n    @AgentFixtures.after_process\n    def confirm_processed(self, ctx: ProcessContext[LoggableEvent]):\n        print(f\"AFTER_PROCESS: Finished processing for {ctx.method_name}.\")\n\n    @AgentFixtures.on_send\n    def count_outgoing(self, ctx: ProcessContext[LoggableEvent]): # Context of the calling handler\n        self.sent_count += 1\n        print(f\"ON_SEND: Agent {self.name} is sending message #{self.sent_count} (initiated by {ctx.method_name}).\")\n\n    @AgentFixtures.outgoing_message_modifier\n    def add_custom_header(self, ctx: ProcessContext[LoggableEvent], message_to_be_sent: Message):\n        print(f\"OUTGOING_MODIFIER: Modifying message ID {message_to_be_sent.id}\")\n        if message_to_be_sent.payload: # Ensure payload exists\n             message_to_be_sent.payload[\"modified_by\"] = self.name # Example modification\n</code></pre>"},{"location":"core/agents.html#dependency-injection-in-handlers","title":"Dependency Injection in Handlers","text":"<p>Message handlers can declare dependencies that are automatically resolved and injected by the framework when the handler is called. This is done using the <code>depends_on</code> argument of the <code>@agent.processor</code> decorator.</p> <pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent import ProcessContext\nfrom rustic_ai.core.guild.dsl import BaseAgentProps, AgentSpec, DependencySpec\n# Assume MyDatabaseService and MyApiClient are defined elsewhere\n\n# Example Dependency Resolvers (simplified, see dependencies.md for full structure)\nclass MyDatabaseResolver: # Implements rustic_ai.core.guild.agent_ext.depends.DependencyResolver\n    def __init__(self, connection_string: str): \n        super().__init__()\n        self.conn_str = connection_string\n    def resolve(self, guild_id, agent_id=None): return f\"DBConnection({self.conn_str})\" # Returns actual service\n\nclass MyApiClientResolver:\n    def __init__(self, api_key: str): \n        super().__init__()\n        self.api_key = api_key\n    def resolve(self, guild_id, agent_id=None): return f\"ApiClient(key={self.api_key})\"\n\nclass OrderRequest(BaseModel):\n    item_id: str\n    quantity: int\n\nclass OrderProcessorAgent(Agent[BaseAgentProps]):\n    @agent.processor(clz=OrderRequest, depends_on=[\"db\", \"api_client\"])\n    def process_order(self, ctx: ProcessContext[OrderRequest], db: str, api_client: str):\n        # 'db' will be an instance of MyDatabaseService (or whatever the resolver returns)\n        # 'api_client' will be an instance of MyApiClient\n        print(f\"Processing order for item {ctx.payload.item_id} using DB: {db} and API: {api_client}\")\n        # ... use db and api_client ...\n        ctx.send_dict({\"status\": \"order processed\"})\n\n# In AgentSpec for OrderProcessorAgent:\n# \"dependency_map\": {\n#   \"db\": { \n#       \"class_name\": \"my_project.resolvers.MyDatabaseResolver\", \n#       \"properties\": {\"connection_string\": \"prod_db_uri\"} \n#   },\n#   \"api_client\": { \n#       \"class_name\": \"my_project.resolvers.MyApiClientResolver\", \n#       \"properties\": {\"api_key\": \"secret_key\"}\n#   }\n# }\n# Or these could be defined at the Guild level and inherited/overridden.\n</code></pre> <ul> <li>The <code>depends_on</code> list contains string keys.</li> <li>These keys must match entries in the agent's own <code>dependency_map</code> or the <code>dependency_map</code> of its Guild.</li> <li>The corresponding <code>DependencySpec</code> defines a resolver class and its configuration.</li> <li>The resolver's <code>resolve()</code> method is called to provide the dependency instance.</li> <li>The names of the parameters in the handler method must match the keys in <code>depends_on</code>.</li> </ul> <p>Refer to the Dependencies documentation for a full explanation of dependency resolvers.</p>"},{"location":"core/agents.html#agent-state-management","title":"Agent State Management","text":"<p>Agents are often stateful. Rustic AI provides mechanisms for managing agent state persistently.</p> <ul> <li>Internal State Access: Within an agent, <code>self._state</code> holds a dictionary representing the agent's current state. <code>self._guild_state</code> holds the guild's state. Direct modification of these is generally discouraged for persistence.</li> <li><code>StateRefresherMixin</code>: This default mixin, added by <code>AgentMetaclass</code>, handles messages like <code>StateFetchResponse</code> and <code>StateUpdateResponse</code> to keep <code>self._state</code> and <code>self._guild_state</code> synchronized with the authoritative <code>StateManager</code>.</li> <li>Requesting State Changes: To persist state changes, an agent typically sends a <code>StateUpdateRequest</code> message (often to a system topic like <code>GuildTopics.GUILD_STATUS_TOPIC</code>). The <code>StateManager</code> (via a system agent like <code>GuildManagerAgent</code> or a dedicated state agent) processes this request.</li> <li><code>ProcessContext</code> and State: While <code>ctx.update_context()</code> modifies a per-message-flow temporary context, it does not directly persist to the agent's long-term state.</li> </ul> <pre><code># Conceptual example of an agent requesting a state update\n# (Actual implementation details may vary based on system setup)\nfrom rustic_ai.core.state.models import StateOwner, StateUpdateRequest\n\n# Inside a handler:\n# new_state_values = {\"last_processed_id\": ctx.message.id, \"item_count\": self.item_count + 1}\n# update_request = StateUpdateRequest(\n#     state_owner=StateOwner.AGENT,\n#     guild_id=self.guild_id,\n#     agent_id=self.id,\n#     update_format=\"MERGE_DICT\", # or \"REPLACE_DICT\", \"JMESPATH_UPDATE\"\n#     state_update=new_state_values \n# )\n# # Send this request, typically to a system topic\n# ctx.send_dict(payload=update_request.model_dump(), format=StateUpdateRequest.get_qualified_class_name(), ...)\n</code></pre> <p>For detailed information, see the State Management documentation.</p>"},{"location":"core/agents.html#error-handling-strategies","title":"Error Handling Strategies","text":"<p>Robust agents need to handle errors gracefully.</p> <ol> <li> <p>Standard Exceptions in Handlers:     *   If a <code>@processor</code> method raises an unhandled Python exception:         1.  The system catches the exception.         2.  It wraps the error details into an <code>ErrorMessage</code> (or similar).         3.  <code>ctx.send_error()</code> is implicitly called with this <code>ErrorMessage</code>.         4.  This triggers any <code>@AgentFixtures.on_send_error</code> hooks.         5.  The <code>ErrorMessage</code> is then published, often to a designated error topic or back to the sender based on routing.         6.  The original exception might also be logged and potentially bubbled up to the <code>ExecutionEngine</code>, which could have policies for restarting the agent.</p> </li> <li> <p>Custom Typed Errors (<code>AgentError</code>):     *   For business logic errors or expected fault conditions, it's good practice to define custom exception classes inheriting from <code>rustic_ai.core.guild.AgentError</code> (or a more specific base error if available).     *   Raise these custom errors from your handlers.     *   Other agents can then have <code>@processor</code> methods specifically for these custom error types, allowing for targeted error handling workflows.</p> </li> </ol> <pre><code># Create your own error class to support domain-specific error handling\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent import ProcessContext\nfrom pydantic import BaseModel\n\n# Define a custom error class based on exception or a framework base\nclass AgentError(Exception):\n    \"\"\"Base class for agent-specific exceptions\"\"\"\n    pass\n\nclass InsufficientStockError(AgentError):\n    item_id: str\n    requested_qty: int\n    available_qty: int\n\n    def __init__(self, item_id: str, requested_qty: int, available_qty: int, message: str = \"Insufficient stock\"):\n        super().__init__(message)\n        self.item_id = item_id\n        self.requested_qty = requested_qty\n        self.available_qty = available_qty\n\nclass OrderRequest(BaseModel):\n    item_id: str\n    quantity: int\n\nclass StockCheckerAgent(Agent[BaseAgentProps]):\n    @agent.processor(OrderRequest)\n    def check_stock(self, ctx: ProcessContext[OrderRequest]):\n        # ... logic to check stock ...\n        available = 5 # simplified\n        if ctx.payload.quantity &gt; available:\n            raise InsufficientStockError(\n                item_id=ctx.payload.item_id, \n                requested_qty=ctx.payload.quantity, \n                available_qty=available\n            )\n        # ... proceed with order ...\n        ctx.send_dict({\"status\": \"stock_ok\"})\n\nclass ErrorHandlerAgent(Agent[BaseAgentProps]):\n    @agent.processor(InsufficientStockError) # Handles the specific typed error\n    def handle_stock_error(self, ctx: ProcessContext[InsufficientStockError]):\n        error_data = ctx.payload # error_data is an InsufficientStockError instance\n        print(f\"Stock error: Item {error_data.item_id}, wanted {error_data.requested_qty}, have {error_data.available_qty}\")\n        # ... notify user, log, etc. ...\n</code></pre>"},{"location":"core/agents.html#testing-agents-in-isolation","title":"Testing Agents in Isolation","text":"<p>Rustic AI promotes robust unit and integration testing of agents. The framework provides utilities, most notably <code>wrap_agent_for_testing</code> from <code>rustic_ai.testing.helpers</code>, to simplify the setup and execution of agent tests.</p> <p>The <code>wrap_agent_for_testing</code> helper typically handles: -   Agent Instantiation: Taking an agent instance (usually created via <code>AgentBuilder(...).build()</code>). -   Dependency Setup: Allowing you to provide <code>DependencySpec</code>s for the agent's dependencies, enabling the use of mock resolvers or test-specific configurations. -   Message ID Generation: Often takes a <code>generator</code> (e.g., a <code>GemstoneGenerator</code> instance) for creating unique message IDs during the test. -   Outgoing Message Capture: It returns the configured agent instance and a <code>results</code> list, which automatically collects all messages sent by the agent under test.</p>"},{"location":"core/agents.html#unit-testing-with-wrap_agent_for_testing","title":"Unit Testing with <code>wrap_agent_for_testing</code>","text":"<p>Here's how you typically test an agent:</p> <pre><code>import pytest\nimport asyncio # For testing async handlers\nfrom pydantic import BaseModel # For defining message payloads\nfrom typing import Any, Callable # For type hinting mock callables\n\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps, DependencySpec\nfrom rustic_ai.core.guild.agent import ProcessContext # For type hinting if needed\nfrom rustic_ai.core.messaging.core.message import Message, AgentTag, MessageConstants\nfrom rustic_ai.core.utils.basic_class_utils import get_qualified_class_name\nfrom rustic_ai.core.utils.priority import Priority\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator, GemstoneID # For ID generation in tests\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing # The real helper for testing agents\n</code></pre>"},{"location":"core/agents.html#example-test-setup","title":"Example Test Setup","text":"<pre><code># Agent under test \nclass GreeterAgentProps(BaseAgentProps):\n    greeting: str = \"Hello\"\n\nclass GreetingResponse(BaseModel):\n    message: str\n\nclass GreeterAgent(Agent[GreeterAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[GreeterAgentProps]):\n        super().__init__(agent_spec)\n\n    @agent.processor(clz=str)\n    def greet(self, ctx: ProcessContext[str]):\n        name = ctx.payload or \"World\"\n        ctx.send(GreetingResponse(message=f\"{self.get_spec().props.greeting}, {name}!\"))\n\n# Test fixture\n@pytest.fixture\ndef greeter_test_setup():\n    # Create agent instance\n    agent_instance = AgentBuilder(GreeterAgent)\\\n        .set_name(\"TestGreeter\")\\\n        .set_properties(GreeterAgentProps(greeting=\"Greetings\"))\\\n        .build()\n\n    # Set up for testing\n    id_generator = GemstoneGenerator(machine_id=1)\n    test_agent, results = wrap_agent_for_testing(agent_instance, id_generator)\n\n    return test_agent, results, id_generator\n\n# Actual test\ndef test_greeter(greeter_test_setup):\n    agent, results, id_generator = greeter_test_setup\n\n    # Create test message\n    msg = Message(\n        id_obj=id_generator.get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Tester\"),\n        payload=\"Friend\",\n        format=\"str\"  # Matches @agent.processor(clz=str)\n    )\n\n    # Deliver message\n    agent._on_message(msg)\n\n         # Verify response\n     assert len(results) == 1\n     response = GreetingResponse.model_validate(results[0].payload)\n     assert response.message == \"Greetings, Friend!\"\n</code></pre>"},{"location":"core/agents.html#key-aspects-of-testing-with-wrap_agent_for_testing","title":"Key Aspects of Testing with <code>wrap_agent_for_testing</code>","text":"<ul> <li>Agent Instantiation: Pass an instance of your agent (usually from <code>AgentBuilder(...).build()</code>) to <code>wrap_agent_for_testing</code>.</li> <li>Dependency Management:<ul> <li>Provide a <code>dependencies</code> dictionary to <code>wrap_agent_for_testing</code>. The keys are dependency names (as used in <code>@agent.processor(depends_on=[...])</code>) and values are <code>DependencySpec</code> objects.</li> <li>Your <code>DependencySpec</code> in the test should point to a mock resolver or a real resolver configured for a test environment. The mock resolver's <code>resolve()</code> method should return the mock object/function your agent expects.</li> </ul> </li> <li>Simulating Input: Craft <code>Message</code> objects with appropriate <code>payload</code>, <code>format</code>, <code>sender</code>, <code>id_obj</code> (using the provided <code>id_generator</code>), etc., to correctly trigger your target handler.</li> <li>Invoking Handler: Call <code>agent_instance._on_message(input_message)</code> to simulate message arrival. The <code>AgentMetaclass</code> and base <code>Agent</code> logic will then find and invoke the correct <code>@processor</code>.</li> <li>Capturing &amp; Asserting Output: The <code>results</code> list returned by <code>wrap_agent_for_testing</code> collects all <code>Message</code> objects sent by the agent. Assert their <code>payload</code>, <code>format</code>, <code>recipient_list</code>, <code>in_response_to</code> field, etc.</li> </ul>"},{"location":"core/agents.html#mocking-external-calls-with-unittestmockpatch","title":"Mocking External Calls with <code>unittest.mock.patch</code>","text":"<p>If an agent makes direct external calls that are not managed via the <code>dependency_map</code> (e.g., using a globally imported library or a method on an unmanaged object), you can use Python's standard <code>unittest.mock.patch</code>:</p> <pre><code>from unittest.mock import patch\n\n# Inside your test function or class:\n# @patch('my_agent_module.some_external_library.some_function')\n# def test_agent_with_patched_call(mock_some_function, my_agent_test_setup):\n#     agent_uut, captured_messages, id_generator = my_agent_test_setup\n#     mock_some_function.return_value = \"mocked_external_data\"\n#     \n#     # ... create input message and call agent_uut._on_message(...) ...\n#     \n#     mock_some_function.assert_called_once_with(...)\n#     # ... assert on captured_messages ...\n</code></pre>"},{"location":"core/agents.html#testing-asynchronous-handlers","title":"Testing Asynchronous Handlers","text":"<p>If your agent's <code>@processor</code> methods are <code>async def</code>: -   The test function itself might need to be <code>async</code> (e.g., using <code>pytest-asyncio</code> and decorating the test with <code>@pytest.mark.asyncio</code>). -   The <code>Agent</code>'s <code>_on_message</code> method and the <code>@agent.processor</code> decorator handle the execution of the async handler correctly. -   If your assertions depend on the completion of asynchronous tasks that the handler might have initiated (e.g., messages sent after an <code>await</code> within the handler, or background tasks), you may need to use <code>await asyncio.sleep()</code> in your test to allow these operations time to complete before making assertions on the <code>captured_messages</code> list or other side effects. The Playwright agent tests demonstrate this pattern by looping with <code>await asyncio.sleep()</code> while checking the <code>results</code> list.</p> <pre><code># Conceptual snippet for testing an async handler\n# @pytest.mark.asyncio\n# async def test_async_agent_handler(my_async_agent_test_setup):\n#     agent_uut, captured_messages, id_generator = my_async_agent_test_setup\n#     # ... prepare incoming_message ...\n#     agent_uut._on_message(incoming_message) # This will schedule the async handler\n\n#     # Allow time for async operations within the handler to complete\n#     await asyncio.sleep(0.1) \n\n#     # ... assertions on captured_messages ...\n</code></pre>"},{"location":"core/agents.html#general-testing-guidelines","title":"General Testing Guidelines:","text":"<ul> <li>Focus: Test the specific logic within your agent's handlers and fixtures.</li> <li>Isolation: Use dependency injection (via <code>wrap_agent_for_testing</code> and <code>DependencySpec</code>) and standard mocking techniques (like <code>unittest.mock.patch</code>) to isolate your agent from external systems for unit tests.</li> <li>Variety: Test with different valid and invalid input message payloads and formats to ensure robustness.</li> <li>Error Conditions: Simulate errors from dependencies (e.g., make mock services raise exceptions or return error indicators) and verify your agent's error handling logic.</li> <li>State Changes: If your agent is stateful, assert that its internal state is updated correctly after message processing. For persistent state, you might need more integrated tests involving a test <code>StateManager</code>.</li> <li>Agent-to-Agent Interactions: For testing how multiple agents interact within a workflow, consider setting up a minimal test <code>Guild</code> (e.g., using <code>GuildBuilder().launch(add_probe=True)</code> or by manually adding a <code>ProbeAgent</code>) to capture messages on relevant topics or observe interactions.</li> </ul>"},{"location":"core/agents.html#agent-mixins-behind-the-scenes-support","title":"Agent Mixins: Behind-the-Scenes Support","text":"<p>When you define an agent class, the <code>AgentMetaclass</code> automatically incorporates several default \"mixin\" classes into its structure. These mixins operate largely behind the scenes, providing your agent with essential cross-cutting functionalities without requiring explicit code in your agent logic.</p> <p>The primary default mixins include:</p> <ul> <li><code>StateRefresherMixin</code>: This is crucial for stateful agents. It listens for system messages (like <code>StateFetchResponse</code> and <code>StateUpdateResponse</code>) from the <code>StateManager</code> and ensures that the agent's local cached copies of its own state (<code>self._state</code>) and the guild's state (<code>self._guild_state</code>) are kept synchronized with the authoritative state. This allows you to access reasonably up-to-date state within your agent without manually fetching it on every message.<p>This mixin provides helpful methods for state management that you can safely use in your handlers:   <pre><code># Get state from the state manager\nself.request_state(ctx)  # Request agent's own state \nself.request_guild_state(ctx)  # Request guild state\n\n# Update state persistently\nself.update_state(\n    ctx,\n    update_format=StateUpdateFormat.MERGE_DICT,  # or REPLACE_DICT, JMESPATH_UPDATE\n    update={\"counter\": self.counter}  # New state values\n)\n\nself.update_guild_state(\n    ctx,\n    update_format=StateUpdateFormat.MERGE_DICT,\n    update={\"last_active_agent\": self.id}\n)\n</code></pre></p> </li> </ul> <ul> <li><code>HealthMixin</code>: This mixin provides a basic health check capability. It defines a handler for a system \"ping\" message (<code>Heartbeat</code>), allowing the execution environment or guild management services to verify that the agent is alive and responsive. The default implementation responds with <code>HeartbeatResponse</code> and status \"OK\".</li> </ul> <ul> <li><code>TelemetryMixin</code>: This mixin integrates the agent with the broader observability infrastructure. It helps in propagating tracing contexts across messages and emitting standard metrics, which are invaluable for monitoring and debugging distributed multi-agent interactions. It automatically adds tracing information to outgoing messages and captures spans for message processing.</li> </ul> <p>Interaction and Customization:</p> <p>For most agent development, you don't need to interact directly with these mixins or even be explicitly aware of their detailed implementation. They are designed to provide foundational capabilities transparently.</p> <p>However, if you are an advanced user looking to deeply customize these core behaviors (e.g., changing how state is refreshed or implementing a very custom health check), you would then need to understand the specific mixin's interface and potentially override its methods or provide alternative implementations. For such advanced scenarios, referring to the source code of these mixins (typically found in <code>rustic_ai.core.guild.agent_ext.mixins.*</code>) would be necessary.</p>"},{"location":"core/agents.html#advanced-topics","title":"Advanced Topics","text":"<p>In this section, we cover more advanced topics related to agent development and usage.</p>"},{"location":"core/agents.html#custom-mixins","title":"Custom Mixins","text":"<p>You can create your own mixins and let the AgentMetaclass auto-inject them. To do this:</p> <ol> <li>Define your mixin class with functionality you want to add to agents</li> <li>Add your mixin to the <code>DEFAULT_MIXINS</code> list in a custom metaclass extending <code>AgentMetaclass</code></li> <li>Use your custom metaclass when defining agent classes</li> </ol>"},{"location":"core/agents.html#dynamic-agent-deployment","title":"Dynamic Agent Deployment","text":"<p>The <code>GuildManagerAgent</code> provides capabilities for dynamic agent deployment:</p> <ul> <li>Hot-reloading agents with updated implementation or configuration</li> <li>Blue-green deployment strategies for zero-downtime updates</li> <li>Dynamic scaling by adding/removing agent instances</li> </ul>"},{"location":"core/agents.html#performance-considerations","title":"Performance Considerations","text":"<p>For high-performance agent systems:</p> <ul> <li>Message priority control using the <code>Priority</code> enum</li> <li>Message batching for reducing overhead</li> <li>Efficient state management strategies for agents with large state</li> <li>Gemstone ID sharding for distributed systems</li> </ul> <p>The <code>@agent.processor</code> decorator also supports asynchronous functions with <code>async def</code>. The framework will automatically detect and properly schedule these handlers:</p> <pre><code>from aiohttp import ClientSession\n\nclass AsyncAgent(Agent[BaseAgentProps]):\n    @agent.processor(clz=SearchQuery)\n    async def search_web(self, ctx: ProcessContext[SearchQuery]):\n        query = ctx.payload.query\n\n        # Perform asynchronous operations\n        async with ClientSession() as session:\n            async with session.get(f\"https://api.example.com/search?q={query}\") as response:\n                result = await response.json()\n\n        # Process results and respond\n        ctx.send(SearchResult(results=result[\"items\"]))\n</code></pre> <p>When an async handler is invoked: 1. The framework detects it's an async function via <code>inspect.iscoroutinefunction()</code> 2. The <code>ProcessorHelper.run_coroutine()</code> method handles scheduling:    - If in an already running event loop, it creates a new task    - Otherwise, it calls <code>asyncio.run()</code> to run the coroutine to completion</p> <p>This allows your agent to perform non-blocking I/O operations like network requests or database queries without blocking the entire agent/guild.</p>"},{"location":"core/agents.html#asynchronous-handlers_1","title":"Asynchronous Handlers","text":"<p>The <code>@agent.processor</code> decorator also supports asynchronous functions with <code>async def</code>. The framework will automatically detect and properly schedule these handlers:</p> <pre><code>from aiohttp import ClientSession\n\nclass AsyncAgent(Agent[BaseAgentProps]):\n    @agent.processor(clz=SearchQuery)\n    async def search_web(self, ctx: ProcessContext[SearchQuery]):\n        query = ctx.payload.query\n\n        # Perform asynchronous operations\n        async with ClientSession() as session:\n            async with session.get(f\"https://api.example.com/search?q={query}\") as response:\n                result = await response.json()\n\n        # Process results and respond\n        ctx.send(SearchResult(results=result[\"items\"]))\n</code></pre> <p>When an async handler is invoked: 1. The framework detects it's an async function via <code>inspect.iscoroutinefunction()</code> 2. The <code>ProcessorHelper.run_coroutine()</code> method handles scheduling:    - If in an already running event loop, it creates a new task    - Otherwise, it calls <code>asyncio.run()</code> to run the coroutine to completion</p> <p>This allows your agent to perform non-blocking I/O operations like network requests or database queries without blocking the entire agent/guild.</p> <ul> <li><code>clz</code>: Specifies the expected Pydantic model for the message payload. If the incoming message's <code>format</code> matches the qualified name of this model, the payload is automatically parsed and validated into an instance of this model. Use <code>JsonDict</code> to receive the payload as a raw dictionary without parsing.</li> </ul>"},{"location":"core/architecture.html","title":"Architecture Overview","text":"<p>Rustic AI Core is engineered to be a scalable, human-centred, multi-agent platform. Its design follows a hexagonal (ports-and-adapters) philosophy that cleanly separates domain logic from infrastructure, making the system easy to extend, test, and deploy in a variety of environments \u2013 from a single-process Jupyter notebook to a distributed cluster.</p>"},{"location":"core/architecture.html#core-layers","title":"Core Layers","text":"<ol> <li>Domain Layer \u2013 The pure business logic of agents, guilds, and messages.</li> <li>Application Layer \u2013 Coordination logic such as execution engines, dependency resolution, and routing.</li> <li>Infrastructure Layer \u2013 Concrete implementations for messaging brokers, persistence stores, and execution back-ends.</li> </ol> <pre><code>flowchart LR\n    subgraph Domain\n        Agents\n        Guilds\n        Messages\n    end\n    subgraph Application\n        ExecutionEngines\n        DependencyResolver\n        Router\n        StateManager\n    end\n    subgraph Infrastructure\n        MessagingBroker[[Messaging Broker]]\n        Database[[Database / KV-Store]]\n        Scheduler[[Thread / Process Pool]]\n    end\n    Agents -- publish / subscribe --&gt; Router\n    Router -- uses --&gt; MessagingBroker\n    ExecutionEngines -- persists --&gt; StateManager\n    StateManager -- stores --&gt; Database\n    ExecutionEngines -- schedules --&gt; Scheduler\n</code></pre>"},{"location":"core/architecture.html#component-breakdown","title":"Component Breakdown","text":"Component Responsibility Extensibility Points Agent Encapsulates autonomous behaviour and state. Custom handler methods, fixtures, and properties. Guild Logical collection of agents; bootstraps dependencies, execution and routing. Custom <code>GuildSpec</code>, shared dependencies, routing rules. Messaging Topic-based, asynchronous bus that agents use to exchange <code>Message</code> objects. Custom message formats, brokers, routing strategies. Execution Engine Orchestrates when and where each agent runs (sync, multithreaded, distributed). Implement the <code>BaseExecutionEngine</code> interface. State Manager Persists agent/guild state and message history. Pluggable back-ends (in-memory, SQLite, Redis, etc.). Dependency Injection Lazily resolves resources requested in <code>dependency_map</code>. Custom <code>DependencyResolver</code> classes."},{"location":"core/architecture.html#data-flow-walk-through","title":"Data-Flow Walk-Through","text":"<p>Below is a typical request / response interaction highlighting how the layers collaborate.</p> <pre><code>sequenceDiagram\n    participant User\n    participant AgentA\n    participant Broker as \"Messaging Broker\"\n    participant AgentB\n\n    User-&gt;&gt;AgentA: External stimulus / UI event\n    AgentA-&gt;&gt;AgentA: Business logic &amp; state mutation\n    AgentA-&gt;&gt;Broker: ctx.send(Request)\n    Broker-&gt;&gt;AgentB: deliver(Request)\n    AgentB-&gt;&gt;AgentB: Handle request\n    AgentB-&gt;&gt;Broker: ctx.send(Response)\n    Broker-&gt;&gt;AgentA: deliver(Response)\n    AgentA-&gt;&gt;User: Emit result / side effect\n</code></pre>"},{"location":"core/architecture.html#execution-models","title":"Execution Models","text":"<p>Rustic AI ships with two built-in engines and allows you to plug in your own:</p> <ol> <li><code>SyncExecutionEngine</code> \u2013 Runs everything in a single thread; perfect for tutorials and unit tests.</li> <li><code>MultithreadedExecutionEngine</code> \u2013 Allocates a thread per agent or a thread-pool; good for IO-bound workloads.</li> <li>Custom \u2013 Implement <code>BaseExecutionEngine</code> to target async runtimes, process pools, or Kubernetes Jobs.</li> </ol>"},{"location":"core/architecture.html#choosing-an-engine","title":"Choosing an Engine","text":"Scenario Recommended Engine Quick prototyping / notebooks <code>SyncExecutionEngine</code> CPU-light IO-bound ops (API calls, DB) <code>MultithreadedExecutionEngine</code> CPU-heavy or distributed workloads Custom engine (Ray, Celery, Kubernetes)"},{"location":"core/architecture.html#error-handling-observability","title":"Error Handling &amp; Observability","text":"<ul> <li>Structured Errors \u2013 All exceptions propagate through a typed <code>AgentError</code> hierarchy allowing rich error routing.</li> <li>Tracing \u2013 Built-in OpenTelemetry hooks emit spans for message processing and dependency resolution.</li> <li>Metrics \u2013 Prometheus counters/latencies for message throughput, handler latency, and error rates.</li> <li>Logging \u2013 JSON structured logs with correlation IDs (guild, agent, message).</li> </ul>"},{"location":"core/architecture.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Sandboxing \u2013 Agents running untrusted code can be isolated via OS containers or process sandboxes.</li> <li>Authentication \u2013 Messages carry signed headers (<code>MessageAuth</code>) to verify sender identity.</li> <li>Authorization \u2013 Guild-level policies can reject or transform messages based on ACLs.</li> <li>Encryption \u2013 End-to-end optional encryption of payloads at transport or application layer.</li> </ul>"},{"location":"core/architecture.html#extending-rustic-ai-core","title":"Extending Rustic AI Core","text":"<ol> <li>New Agent Types \u2013 Subclass <code>Agent</code> and register via <code>AgentBuilder</code>.</li> <li>Custom Message Broker \u2013 Implement the <code>BrokerClient</code> interface (e.g., Kafka, MQTT, NATS).</li> <li>Alternative Persistence \u2013 Provide a <code>StateBackend</code> driver.</li> <li>Domain-Specific DSLs \u2013 Use the metaclass hooks to generate agent code from higher-level specs.</li> </ol> <p>Continue reading the dedicated pages on Agents, Messaging, Execution, and State Management for deep-dives into each component. </p>"},{"location":"core/dependencies.html","title":"Dependencies","text":"<p>Rustic AI Core provides a flexible dependency management system for agents and guilds. This enables modular, testable, and extensible agent design.</p>"},{"location":"core/dependencies.html#purpose","title":"Purpose","text":"<ul> <li>Allow agents and guilds to declare required dependencies</li> <li>Support runtime resolution and injection of dependencies</li> <li>Enable sharing of resources and services</li> </ul>"},{"location":"core/dependencies.html#core-components","title":"Core Components","text":""},{"location":"core/dependencies.html#dependencyspec","title":"DependencySpec","text":"<p>A Pydantic model that defines a dependency with: - <code>class_name</code>: The fully qualified name of a <code>DependencyResolver</code> class (string) - <code>properties</code>: Configuration parameters passed to the resolver's constructor (JSON dictionary)</p>"},{"location":"core/dependencies.html#dependencyresolver","title":"DependencyResolver","text":"<p>An abstract base class that all resolvers must implement: - Defines an abstract <code>resolve(guild_id, agent_id)</code> method that creates/returns the actual dependency - Provides built-in caching via <code>get_or_resolve()</code> (controlled by <code>memoize_resolution</code> flag) - Enables hierarchical dependency resolution through <code>inject()</code></p>"},{"location":"core/dependencies.html#declaring-dependencies","title":"Declaring Dependencies","text":"<p>Agents and guilds declare dependencies using the <code>dependency_map</code> in their specs. Dependencies can be defined at the agent or guild level.</p>"},{"location":"core/dependencies.html#in-guild-specifications","title":"In Guild Specifications","text":"<pre><code>from rustic_ai.core.guild.dsl import DependencySpec\n\n# Using GuildBuilder\nguild_builder = (\n    GuildBuilder(\"my_guild\", \"My Guild\", \"Guild with dependencies\")\n    .set_dependency_map({\n        \"database\": DependencySpec(\n            class_name=\"my_package.resolvers.DatabaseResolver\", \n            properties={\"connection_string\": \"postgresql://user:pass@host/db\"}\n        )\n    })\n    .add_dependency_resolver(\n        \"api_client\", \n        DependencySpec(\n            class_name=\"my_package.resolvers.ApiClientResolver\",\n            properties={\"api_key\": \"my-api-key\"}\n        )\n    )\n)\n</code></pre>"},{"location":"core/dependencies.html#in-agent-specifications","title":"In Agent Specifications","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\n# Agent-specific dependencies\nagent_spec = (\n    AgentBuilder(MyAgent)\n    .set_name(\"AgentWithDeps\")\n    .set_description(\"Agent with dependencies\")\n    .set_dependency_map({\n        \"logger\": DependencySpec(\n            class_name=\"my_package.resolvers.LoggerResolver\",\n            properties={\"log_level\": \"DEBUG\"}\n        )\n    })\n    .build_spec()\n)\n</code></pre>"},{"location":"core/dependencies.html#dependency-resolution","title":"Dependency Resolution","text":"<ul> <li>Dependencies are resolved at runtime by the execution engine or agent wrapper</li> <li>Dependency resolvers instantiate and inject the required resources</li> <li>Guild-level dependencies are available to all agents within the guild</li> <li>Agent-level dependencies can override guild-level dependencies with the same key</li> </ul>"},{"location":"core/dependencies.html#resolver-lifecycle","title":"Resolver Lifecycle","text":"<ol> <li>Lookup \u2013 At agent boot, the DI system reads the <code>dependency_map</code> and locates the specified resolver class</li> <li>Instantiate \u2013 The resolver is instantiated with the provided properties from the DependencySpec</li> <li>Resolve \u2013 Resolver's <code>resolve()</code> method is called to create or retrieve the concrete resource</li> <li>Cache \u2013 Results are cached based on guild_id and agent_id for efficient reuse</li> <li>Shared Access \u2013 Guild-level dependencies are shared by all agents requesting them</li> </ol> <pre><code>class MyDatabaseResolver(DependencyResolver):\n    def __init__(self, url: str):\n        super().__init__()  # Important!\n        self._url = url\n        self._engine = None\n\n    def resolve(self, guild_id: str, agent_id: str = None):\n        if not self._engine:\n            self._engine = create_database_engine(self._url)\n        return self._engine\n</code></pre>"},{"location":"core/dependencies.html#caching-and-memoization","title":"Caching and Memoization","text":"<p>By default, dependency resolvers cache their resolved dependencies: - The cache is a two-level dictionary keyed by <code>guild_id</code> and <code>agent_id</code> - Guild-level dependencies use the special <code>GUILD_GLOBAL</code> constant as the agent_id - The <code>memoize_resolution</code> class attribute can be set to <code>False</code> to disable caching</p>"},{"location":"core/dependencies.html#overriding-dependencies-in-tests","title":"Overriding Dependencies in Tests","text":"<p>Testing often requires replacing real services with fakes:</p> <pre><code>from rustic_ai.core.guild.dsl import DependencySpec\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\n\n# Create mock dependencies for testing\nmock_deps = {\n    \"database\": DependencySpec(\n        class_name=\"tests.mocks.MockDatabaseResolver\",\n        properties={\"connection_string\": \"mock://in-memory\"}\n    )\n}\n\n# Wrap agent for testing with mock dependencies\ntest_agent, results = wrap_agent_for_testing(\n    my_agent,\n    gemstone_generator,\n    dependencies=mock_deps\n)\n</code></pre>"},{"location":"core/dependencies.html#dependency-scopes","title":"Dependency Scopes","text":"Scope Visibility Example Agent Only injected into a single agent Personal API keys Guild Shared by all agents in a guild Persistent DB connection pool Global Application-wide singletons Metrics exporter"},{"location":"core/dependencies.html#injecting-dependencies-into-handlers","title":"Injecting Dependencies into Handlers","text":"<p>Dependencies are injected into message handler methods using the <code>depends_on</code> parameter:</p> <pre><code>from rustic_ai.core.guild import Agent, agent\n\nclass MyAgent(Agent):\n    @agent.processor(clz=MyMessageType, depends_on=[\"database\", \"api_client\"])\n    def handle_message(self, ctx, database, api_client):\n        # database and api_client are automatically injected\n        result = database.query(...)\n        api_client.send(result)\n</code></pre>"},{"location":"core/dependencies.html#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Custom Resolvers: Implement custom logic for dependency instantiation</li> <li>Dependency Hierarchies: Resolvers can inject other dependencies using the <code>inject()</code> method</li> <li>Testing: Inject mock dependencies for testing agents in isolation</li> </ul> <p>See the Agents and Guilds sections for how dependencies are used in practice, and Dependency Injection for a detailed guide. </p>"},{"location":"core/embedded_messaging_backend.html","title":"Embedded Messaging Backend","text":"<p>The Embedded Messaging Backend provides a fast, embedded messaging solution for testing distributed agents without requiring external dependencies. It's designed to work with any execution engine and uses only Python standard library components with asyncio for high performance.</p>"},{"location":"core/embedded_messaging_backend.html#overview","title":"Overview","text":"<p>The embedded messaging backend consists of two main components:</p> <ol> <li>EmbeddedServer: A TCP socket-based server that stores messages and provides real-time messaging</li> <li>EmbeddedMessagingBackend: A messaging backend that communicates with the server via socket connections</li> </ol>"},{"location":"core/embedded_messaging_backend.html#key-features","title":"Key Features","text":""},{"location":"core/embedded_messaging_backend.html#core-messaging-features","title":"Core Messaging Features","text":"<ul> <li>Message Storage: Store and retrieve messages by topic</li> <li>Real-time Subscriptions: Subscribe to topics with true push delivery via asyncio</li> <li>Message TTL: Automatic expiration of messages after a specified time</li> <li>Cross-Process Communication: Multiple processes can share the same server</li> <li>Back-pressure Handling: Per-connection message queues with overflow protection</li> <li>Thread Safety: Designed for multi-threaded and multi-process environments</li> </ul>"},{"location":"core/embedded_messaging_backend.html#performance-features","title":"Performance Features","text":"<ul> <li>Socket-Based: Direct TCP socket communication for minimal latency</li> <li>Asyncio Integration: Non-blocking operations with event loop efficiency</li> <li>Connection Pooling: Efficient connection management</li> <li>Binary Protocol: Fast text-based wire protocol with base64 encoding</li> </ul>"},{"location":"core/embedded_messaging_backend.html#testing-features","title":"Testing Features","text":"<ul> <li>No External Dependencies: Uses only Python standard library</li> <li>Fixed Port Configuration: Predictable ports for testing scenarios</li> <li>Easy Cleanup: Proper resource management and cleanup</li> <li>Thread-safe: Safe for use across multiple threads</li> <li>Process-safe: Safe for use across multiple processes</li> </ul>"},{"location":"core/embedded_messaging_backend.html#basic-usage","title":"Basic Usage","text":""},{"location":"core/embedded_messaging_backend.html#simple-setup","title":"Simple Setup","text":"<pre><code>from rustic_ai.core.messaging.backend.embedded_backend import (\n    EmbeddedMessagingBackend,\n    EmbeddedServer\n)\n\n# Auto-start server (simplest approach)\nbackend = EmbeddedMessagingBackend()\n\n# Or use external server\nport = 31134\nbackend = EmbeddedMessagingBackend(port=port, auto_start_server=False)\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#with-messagingconfig","title":"With MessagingConfig","text":"<pre><code>from rustic_ai.core.messaging.core.messaging_config import MessagingConfig\nfrom rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\n\n# Create config\nconfig_dict = create_embedded_messaging_config()\nmessaging_config = MessagingConfig(**config_dict)\n\n# Use with Guild\nguild = Guild(\n    guild_id=\"test_guild\",\n    execution_engine=SyncExecutionEngine(),\n    messaging_config=messaging_config\n)\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#advanced-usage","title":"Advanced Usage","text":""},{"location":"core/embedded_messaging_backend.html#distributed-testing","title":"Distributed Testing","text":"<pre><code># Start a shared server for multiple processes\nimport asyncio\nimport threading\n\ndef start_server(port=31134):\n    def run_server():\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        server = EmbeddedServer(port=port)\n        loop.run_until_complete(server.start())\n        try:\n            loop.run_forever()\n        finally:\n            loop.run_until_complete(server.stop())\n            loop.close()\n\n    thread = threading.Thread(target=run_server, daemon=True)\n    thread.start()\n    return port\n\n# In process 1\nport = start_server(31134)\nbackend1 = EmbeddedMessagingBackend(port=port, auto_start_server=False)\n\n# In process 2  \nbackend2 = EmbeddedMessagingBackend(port=port, auto_start_server=False)\n\n# Both backends share the same message store\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#real-time-subscriptions","title":"Real-time Subscriptions","text":"<pre><code>def message_handler(message):\n    print(f\"Received: {message.payload}\")\n\n# Subscribe to topic\nbackend.subscribe(\"notifications\", message_handler)\n\n# Messages stored to this topic will trigger the handler\nbackend.store_message(\"namespace\", \"notifications\", message)\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#message-based-coordination","title":"Message-based Coordination","text":"<pre><code>from rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\n\ngenerator = GemstoneGenerator(1)\n\n# Coordination via messages\nstatus_msg = Message(\n    id_obj=generator.get_id(),\n    sender=AgentTag(id=\"coordinator\", name=\"Coordinator\"),\n    topics=\"task_status\",\n    payload={\"task_id\": \"task_1\", \"status\": \"assigned\", \"worker\": \"worker_1\"}\n)\nbackend.store_message(\"coordination\", \"task_status\", status_msg)\n\n# Workers can retrieve coordination messages\nmessages = backend.get_messages_for_topic(\"task_status\")\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#testing-utilities","title":"Testing Utilities","text":""},{"location":"core/embedded_messaging_backend.html#pytest-fixtures","title":"Pytest Fixtures","text":"<pre><code>import pytest\nfrom rustic_ai.testing.messaging.shared_memory import (\n    socket_messaging_server,\n    socket_messaging_config,\n    socket_messaging_backend\n)\n\ndef test_messaging(socket_messaging_backend):\n    backend = socket_messaging_backend\n    # Test your messaging logic\n    backend.store_message(\"test\", \"topic\", message)\n    messages = backend.get_messages_for_topic(\"topic\")\n    assert len(messages) == 1\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#test-helpers","title":"Test Helpers","text":"<pre><code>from rustic_ai.testing.messaging.shared_memory import (\n    SocketMessagingTestHelper,\n    DistributedTestScenario\n)\n\n# Simple helper\nwith SocketMessagingTestHelper() as helper:\n    backend = helper.get_backend()\n    # Test messaging\n\n# Distributed scenario\nwith DistributedTestScenario() as scenario:\n    backend1 = scenario.create_backend(\"agent1\")\n    backend2 = scenario.create_backend(\"agent2\")\n\n    scenario.setup_subscriber(\"agent1\", \"topic\")\n    # Send message from agent2, verify agent1 receives it\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#configuration-options","title":"Configuration Options","text":""},{"location":"core/embedded_messaging_backend.html#server-configuration","title":"Server Configuration","text":"<pre><code>server = EmbeddedServer(\n    port=31134,  # Fixed port (required)\n)\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#backend-configuration","title":"Backend Configuration","text":"<pre><code>backend = EmbeddedMessagingBackend(\n    port=31134,           # Server port\n    auto_start_server=True,  # Auto-start if server not running\n)\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#messagingconfig-integration","title":"MessagingConfig Integration","text":"<pre><code>config = {\n    \"backend_module\": \"rustic_ai.core.messaging.backend.embedded_backend\",\n    \"backend_class\": \"EmbeddedMessagingBackend\",\n    \"backend_config\": {\n        \"port\": 31134,\n        \"auto_start_server\": False\n    }\n}\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#api-reference","title":"API Reference","text":""},{"location":"core/embedded_messaging_backend.html#embeddedserver","title":"EmbeddedServer","text":""},{"location":"core/embedded_messaging_backend.html#methods","title":"Methods","text":"<ul> <li><code>async start()</code>: Start the asyncio server</li> <li><code>async stop()</code>: Stop the server</li> <li><code>get_stats()</code>: Get server statistics</li> </ul>"},{"location":"core/embedded_messaging_backend.html#socket-protocol","title":"Socket Protocol","text":"<p>The server uses a text-based protocol with base64 encoding:</p> <pre><code>COMMAND arg1 arg2 ...\n</code></pre> <p>Supported commands: - <code>PUBLISH topic message_json</code> - <code>SUBSCRIBE topic</code> - <code>UNSUBSCRIBE topic</code> - <code>STORE_MESSAGE namespace topic message_json</code> - <code>GET_MESSAGES topic</code> - <code>GET_MESSAGES_SINCE topic message_id</code> - <code>GET_MESSAGES_BY_ID namespace message_ids_json</code></p>"},{"location":"core/embedded_messaging_backend.html#embeddedmessagingbackend","title":"EmbeddedMessagingBackend","text":""},{"location":"core/embedded_messaging_backend.html#core-methods","title":"Core Methods","text":"<ul> <li><code>store_message(namespace, topic, message)</code>: Store a message</li> <li><code>get_messages_for_topic(topic)</code>: Get all messages for topic</li> <li><code>get_messages_for_topic_since(topic, msg_id)</code>: Get messages since ID</li> <li><code>get_messages_by_id(namespace, msg_ids)</code>: Get messages by ID list</li> <li><code>subscribe(topic, handler)</code>: Subscribe to topic</li> <li><code>unsubscribe(topic)</code>: Unsubscribe from topic</li> <li><code>supports_subscription()</code>: Check if backend supports subscriptions</li> <li><code>load_subscribers(subscribers)</code>: Load subscriber configuration</li> </ul>"},{"location":"core/embedded_messaging_backend.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"core/embedded_messaging_backend.html#scalability","title":"Scalability","text":"<ul> <li>Memory Usage: All data stored in memory, suitable for testing</li> <li>Concurrent Connections: Asyncio handles multiple connections efficiently</li> <li>Message Volume: Designed for test scenarios with good performance</li> <li>Latency: ~0.1-1ms typical latency for local socket communication</li> </ul>"},{"location":"core/embedded_messaging_backend.html#advantages-over-http-based","title":"Advantages over HTTP-based","text":"<ul> <li>Lower Latency: Direct socket communication vs HTTP overhead</li> <li>True Push: Real-time message delivery vs polling</li> <li>Connection Efficiency: Persistent connections vs request/response cycles</li> <li>Back-pressure: Built-in queue management vs connection timeouts</li> </ul>"},{"location":"core/embedded_messaging_backend.html#limitations","title":"Limitations","text":"<ul> <li>Persistence: Data is lost when server stops</li> <li>Single Server: No clustering or replication</li> <li>Local Only: Designed for single-machine testing</li> </ul>"},{"location":"core/embedded_messaging_backend.html#best-practices","title":"Best Practices","text":""},{"location":"core/embedded_messaging_backend.html#for-testing","title":"For Testing","text":"<ol> <li>Use Fixed Ports: Use predictable ports for test reproducibility</li> <li>Use Fixtures: Leverage pytest fixtures for consistent setup</li> <li>Cleanup Resources: Always cleanup backends and servers</li> <li>Isolated Tests: Use separate ports for independent tests</li> <li>Timeout Handling: Set appropriate timeouts for async operations</li> </ol>"},{"location":"core/embedded_messaging_backend.html#for-development","title":"For Development","text":"<ol> <li>Auto-start for Simple Cases: Use auto-start for single-process tests</li> <li>Shared Server for Complex Cases: Use shared server for multi-process tests</li> <li>Message-based Coordination: Use messages for process coordination</li> <li>TTL for Cleanup: Use message TTL to prevent memory leaks</li> </ol>"},{"location":"core/embedded_messaging_backend.html#error-handling","title":"Error Handling","text":"<pre><code>try:\n    backend = SocketMessagingBackend(\n        port=31134,\n        auto_start_server=False\n    )\nexcept ConnectionError:\n    # Handle server connection failure\n    print(\"Could not connect to socket messaging server\")\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#examples","title":"Examples","text":""},{"location":"core/embedded_messaging_backend.html#basic-message-exchange","title":"Basic Message Exchange","text":"<pre><code>from rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\n\n# Setup\nbackend = EmbeddedMessagingBackend()\ngenerator = GemstoneGenerator(1)\n\n# Create message\nmessage = Message(\n    id_obj=generator.get_id(),\n    sender=AgentTag(id=\"sender\", name=\"Sender\"),\n    topics=\"test_topic\",\n    payload={\"data\": \"Hello World\"}\n)\n\n# Store and retrieve\nbackend.store_message(\"test\", \"test_topic\", message)\nmessages = backend.get_messages_for_topic(\"test_topic\")\nprint(f\"Retrieved: {messages[0].payload}\")\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#multi-process-coordination","title":"Multi-Process Coordination","text":"<pre><code>from rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\n\n# Process 1: Coordinator\nbackend = EmbeddedMessagingBackend(port=31134)\ngenerator = GemstoneGenerator(1)\n\n# Assign work via messages\ntask_msg = Message(\n    id_obj=generator.get_id(),\n    sender=AgentTag(id=\"coordinator\", name=\"Coordinator\"),\n    topics=\"task_assignments\",\n    payload={\"task_id\": \"task_1\", \"action\": \"process_data\", \"worker\": \"worker_1\"}\n)\nbackend.store_message(\"coordination\", \"task_assignments\", task_msg)\n\n# Process 2: Worker\nworker_backend = EmbeddedMessagingBackend(port=31134, auto_start_server=False)\n\n# Get work assignments\ntasks = worker_backend.get_messages_for_topic(\"task_assignments\")\nfor task in tasks:\n    if task.payload.get(\"worker\") == \"worker_1\":\n        print(f\"Processing: {task.payload['action']}\")\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#real-time-notifications","title":"Real-time Notifications","text":"<pre><code>notifications = []\n\ndef notification_handler(message):\n    notifications.append(message.payload)\n\n# Subscribe\nbackend.subscribe(\"alerts\", notification_handler)\n\n# Send notification (from another process/thread)\nalert_message = Message(\n    id_obj=generator.get_id(),\n    sender=AgentTag(id=\"system\", name=\"System\"),\n    topics=\"alerts\",\n    payload={\"type\": \"warning\", \"message\": \"High CPU usage\"}\n)\nbackend.store_message(\"system\", \"alerts\", alert_message)\n\n# Handler will be called automatically via socket push\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"core/embedded_messaging_backend.html#common-issues","title":"Common Issues","text":"<ol> <li>Connection Refused: Server not started or wrong port</li> <li>Port Already in Use: Specify different port</li> <li>Messages Not Received: Check subscription setup and connection</li> <li>Memory Growth: Use TTL or periodic cleanup</li> </ol>"},{"location":"core/embedded_messaging_backend.html#debugging","title":"Debugging","text":"<pre><code># Test connection\ntry:\n    backend._test_connection()\n    print(\"Server connection OK\")\nexcept ConnectionError as e:\n    print(f\"Connection error: {e}\")\n\n# Check subscriptions\nprint(f\"Active subscriptions: {list(backend.local_handlers.keys())}\")\n\n# Check message counts\nmessages = backend.get_messages_for_topic(\"test_topic\")\nprint(f\"Messages in topic: {len(messages)}\")\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#migration-from-http-based-backends","title":"Migration from HTTP-based Backends","text":"<p>The socket messaging backend provides improved performance over HTTP-based messaging:</p> <pre><code># Old HTTP-based approach\nbackend.subscribe(\"topic\", handler)  # Long polling\nbackend.store_message(\"ns\", \"topic\", msg)  # HTTP POST\n\n# New socket-based approach (same API, better performance)\nbackend.subscribe(\"topic\", handler)  # Real-time push\nbackend.store_message(\"ns\", \"topic\", msg)  # Socket command\n</code></pre>"},{"location":"core/embedded_messaging_backend.html#comparison-with-other-backends","title":"Comparison with Other Backends","text":"Feature InMemory EmbeddedMessaging Redis Latency ~1\u03bcs ~0.1-1ms ~1-10ms Cross-Process No Yes Yes Real-time Immediate Push delivery Near real-time Dependencies None None Redis Server Persistence None None Full Scalability Single process Multi-process Distributed"},{"location":"core/embedded_messaging_backend.html#conclusion","title":"Conclusion","text":"<p>The Embedded Messaging Backend provides a high-performance, embedded messaging solution for testing distributed agents without external dependencies. It offers significant performance improvements over HTTP-based approaches while maintaining the simplicity and zero-dependency philosophy. The backend is designed to be easy to use, feature-rich, and suitable for a wide range of testing scenarios while maintaining compatibility with the existing Rustic AI messaging architecture. </p>"},{"location":"core/execution.html","title":"Execution","text":"<p>Execution in Rustic AI Core is managed by execution engines, which control how agents are run, scheduled, and coordinated. This enables flexible deployment, from simple synchronous runs to advanced multithreaded, multiprocess, or distributed setups.</p>"},{"location":"core/execution.html#purpose","title":"Purpose","text":"<ul> <li>Manage the lifecycle and scheduling of agents</li> <li>Support different execution models (sync, multithreaded, multiprocess, distributed)</li> <li>Integrate with messaging and state management</li> <li>Provide agent tracking and monitoring capabilities</li> <li>Handle graceful shutdown and resource cleanup</li> </ul>"},{"location":"core/execution.html#execution-engines","title":"Execution Engines","text":"<p>Rustic AI provides four built-in execution engines and supports custom implementations:</p> <ul> <li>SyncExecutionEngine: Runs agents synchronously in the main thread/process.</li> <li>MultiThreadedEngine: Runs agents in separate threads for concurrency.</li> <li>MultiProcessExecutionEngine: Runs agents in separate processes for true parallelism.</li> <li>RayExecutionEngine: Runs agents as distributed Ray actors for scalable, distributed execution.</li> <li>Custom Engines: Extendable for specialized execution models.</li> </ul> Engine Concurrency Model Suitable For Key Features <code>SyncExecutionEngine</code> Single-thread Tutorials, deterministic tests, debugging Simple, predictable execution order <code>MultiThreadedEngine</code> Thread-per-agent IO-bound tasks, WebSocket bots, concurrent processing Thread-safe agent tracking, escapes GIL for IO <code>MultiProcessExecutionEngine</code> Process-per-agent CPU-intensive tasks, true parallelism, process isolation Escapes GIL completely, process isolation, fault tolerance <code>RayExecutionEngine</code> Distributed actors CPU-heavy workloads, distributed systems, scalable deployments Cross-machine execution, fault tolerance Custom User-defined Specialized workloads Implement <code>ExecutionEngine</code> interface"},{"location":"core/execution.html#syncexecutionengine","title":"SyncExecutionEngine","text":"<pre><code>from rustic_ai.core.guild.execution import SyncExecutionEngine\n\n# Default execution - runs agents sequentially in main thread\nengine = SyncExecutionEngine(guild_id=\"my-guild\")\n</code></pre> <p>Key characteristics:</p> <ul> <li>Uses <code>SyncAgentWrapper</code> for direct execution</li> <li>Employs <code>InMemorySyncAgentTracker</code> for agent management</li> <li>Ideal for development, testing, and simple workflows</li> </ul>"},{"location":"core/execution.html#multithreadedengine","title":"MultiThreadedEngine","text":"<pre><code>from rustic_ai.core.guild.execution.multithreaded import MultiThreadedEngine\n\n# Concurrent execution - each agent runs in its own thread\nengine = MultiThreadedEngine(guild_id=\"my-guild\")\n</code></pre> <p>Key characteristics:</p> <ul> <li>Uses <code>MultiThreadedAgentWrapper</code> with separate threads</li> <li>Employs <code>InMemoryMTAgentTracker</code> (thread-safe) for agent management</li> <li>Suitable for IO-bound operations and concurrent processing</li> </ul>"},{"location":"core/execution.html#multiprocessexecutionengine","title":"MultiProcessExecutionEngine","text":"<pre><code>from rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\n\n# True parallel execution - each agent runs in its own process\nengine = MultiProcessExecutionEngine(guild_id=\"my-guild\", max_processes=8)\n</code></pre> <p>Key characteristics:</p> <ul> <li>Uses <code>MultiProcessAgentWrapper</code> with separate processes</li> <li>Employs <code>MultiProcessAgentTracker</code> with shared memory for cross-process tracking</li> <li>Escapes Python GIL completely for true parallelism</li> <li>Provides process isolation for robustness</li> <li>Suitable for CPU-intensive tasks and fault-tolerant systems</li> </ul>"},{"location":"core/execution.html#rayexecutionengine","title":"RayExecutionEngine","text":"<pre><code>from rustic_ai.ray import RayExecutionEngine\nimport ray\n\n# Initialize Ray cluster first\nray.init()\n\n# Distributed execution - agents run as Ray actors\nengine = RayExecutionEngine(guild_id=\"my-guild\")\n</code></pre> <p>Key characteristics:</p> <ul> <li>Uses <code>RayAgentWrapper</code> decorated with <code>@ray.remote</code></li> <li>Agents run as named Ray actors with namespace isolation</li> <li>Supports distributed execution across multiple machines</li> <li>Includes built-in observability and tracing setup</li> </ul>"},{"location":"core/execution.html#agent-wrappers","title":"Agent Wrappers","text":"<p>Agent wrappers encapsulate the logic for initializing, running, and shutting down agents within an execution engine. All wrappers inherit from the base <code>AgentWrapper</code> class.</p>"},{"location":"core/execution.html#common-wrapper-functionality","title":"Common Wrapper Functionality","text":"<ul> <li>Dependency injection: Resolves and injects agent dependencies</li> <li>Messaging client setup: Configures messaging clients and subscriptions</li> <li>State and guild context: Provides access to guild specifications and state</li> <li>Resource management: Handles initialization and cleanup</li> </ul>"},{"location":"core/execution.html#wrapper-types","title":"Wrapper Types","text":"<ul> <li>SyncAgentWrapper: Executes <code>initialize_agent()</code> directly in the current thread</li> <li>MultiThreadedAgentWrapper: Starts a new thread running <code>initialize_agent()</code></li> <li>MultiProcessAgentWrapper: Spawns a new process running the agent with full isolation</li> <li>RayAgentWrapper: Runs as a Ray actor with distributed execution capabilities</li> </ul>"},{"location":"core/execution.html#configuration-and-usage","title":"Configuration and Usage","text":""},{"location":"core/execution.html#default-engine-selection","title":"Default Engine Selection","text":"<p>The default execution engine can be configured via environment variable or guild properties:</p> <pre><code># Via environment variable\nexport RUSTIC_AI_EXECUTION_ENGINE=\"rustic_ai.core.guild.execution.multithreaded.MultiThreadedEngine\"\n\n# Via guild properties\nguild_spec.properties[\"execution_engine\"] = \"rustic_ai.core.guild.execution.sync.SyncExecutionEngine\"\n</code></pre>"},{"location":"core/execution.html#example-running-agents-with-different-engines","title":"Example: Running Agents with Different Engines","text":"<pre><code>from rustic_ai.core.guild import AgentBuilder, Guild\nfrom rustic_ai.core.guild.execution import SyncExecutionEngine\nfrom rustic_ai.core.guild.execution.multithreaded import MultiThreadedEngine\nfrom rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\n\n# Create a guild and agent spec\nguild = Guild(...)\nagent_spec = AgentBuilder(...).set_name(\"Agent1\").set_description(\"...\").build_spec()\n\n# Option 1: Use default execution engine\nguild.launch_agent(agent_spec)\n\n# Option 2: Use specific execution engine\nsync_engine = SyncExecutionEngine(guild_id=guild.id)\nguild.launch_agent(agent_spec, execution_engine=sync_engine)\n\n# Option 3: Use multithreaded engine\nmt_engine = MultiThreadedEngine(guild_id=guild.id)\nguild.launch_agent(agent_spec, execution_engine=mt_engine)\n\n# Option 4: Use multiprocess engine\nmp_engine = MultiProcessExecutionEngine(guild_id=guild.id, max_processes=4)\nguild.launch_agent(agent_spec, execution_engine=mp_engine)\n</code></pre>"},{"location":"core/execution.html#agent-lifecycle-management","title":"Agent Lifecycle Management","text":""},{"location":"core/execution.html#agent-tracking","title":"Agent Tracking","text":"<p>All execution engines provide methods for tracking and managing running agents:</p> <pre><code># Check if agent is running\nis_running = engine.is_agent_running(guild_id, agent_id)\n\n# Get all agents in guild\nagents = engine.get_agents_in_guild(guild_id)\n\n# Find agents by name\nmatching_agents = engine.find_agents_by_name(guild_id, \"MyAgent\")\n\n# Stop specific agent\nengine.stop_agent(guild_id, agent_id)\n\n# Get process/execution info (for multiprocess/Ray engines)\nprocess_info = engine.get_process_info(guild_id, agent_id)\nengine_stats = engine.get_engine_stats()\n</code></pre>"},{"location":"core/execution.html#graceful-shutdown","title":"Graceful Shutdown","text":"<p>All engines respect graceful stop semantics:</p> <ol> <li>Stop Request: Call <code>guild.shutdown()</code> or <code>engine.shutdown()</code></li> <li>Agent Cleanup: Each agent's wrapper handles resource cleanup</li> <li>Messaging Cleanup: Unsubscribe from topics and unregister clients</li> <li>Engine Cleanup: Engine-specific cleanup (thread joining, process termination, Ray actor termination)</li> </ol>"},{"location":"core/execution.html#advanced-topics","title":"Advanced Topics","text":""},{"location":"core/execution.html#extending-execution-engines","title":"Extending Execution Engines","text":"<p>To create a custom execution engine, implement the <code>ExecutionEngine</code> abstract base class:</p> <pre><code>from rustic_ai.core.guild.execution.execution_engine import ExecutionEngine\n\nclass CustomExecutionEngine(ExecutionEngine):\n    def __init__(self, guild_id: str):\n        super().__init__(guild_id=guild_id)\n        # Custom initialization\n\n    def run_agent(self, guild_spec, agent_spec, messaging_config, machine_id, **kwargs):\n        # Custom agent execution logic\n        pass\n\n    def get_agents_in_guild(self, guild_id: str):\n        # Return running agents\n        pass\n\n    # Implement other required methods...\n</code></pre>"},{"location":"core/execution.html#error-handling-and-observability","title":"Error Handling and Observability","text":"<ul> <li>Ray Integration: RayExecutionEngine includes OpenTelemetry tracing setup</li> <li>Logging: All engines provide structured logging for agent lifecycle events</li> <li>Exception Handling: Proper error propagation and cleanup on failures</li> <li>Process Monitoring: MultiProcessExecutionEngine provides process health monitoring</li> </ul>"},{"location":"core/execution.html#performance-considerations","title":"Performance Considerations","text":"Scenario Recommended Engine Reasoning Development/Testing <code>SyncExecutionEngine</code> Predictable, debuggable execution IO-bound applications <code>MultiThreadedEngine</code> Concurrent processing with thread safety CPU-intensive workloads <code>MultiProcessExecutionEngine</code> True parallelism, escapes GIL completely Mixed workloads <code>MultiProcessExecutionEngine</code> Process isolation, fault tolerance Distributed systems <code>RayExecutionEngine</code> Built-in fault tolerance and scaling High-throughput systems <code>MultiProcessExecutionEngine</code> or <code>RayExecutionEngine</code> Maximum parallelism and scaling"},{"location":"core/execution.html#messaging-backend-compatibility","title":"Messaging Backend Compatibility","text":"<p>Different execution engines work best with different messaging backends:</p> Engine Best Messaging Backend Notes <code>SyncExecutionEngine</code> In-Memory Simple, fast for single-process <code>MultiThreadedEngine</code> In-Memory or Redis Thread-safe messaging <code>MultiProcessExecutionEngine</code> Socket Messaging or Redis Cross-process communication <code>RayExecutionEngine</code> Redis Distributed messaging <p>For multiprocess execution, the Socket Messaging Backend is particularly well-suited as it provides: - Cross-process messaging without external dependencies - Real-time socket-based operations for process coordination - Automatic cleanup and resource management</p>"},{"location":"core/execution.html#fault-tolerance-and-recovery","title":"Fault Tolerance and Recovery","text":"<p>The MultiProcessExecutionEngine provides enhanced fault tolerance:</p> <pre><code># Automatic cleanup of dead processes\nengine.cleanup_dead_processes()\n\n# Monitor process health\nprocess_info = engine.get_process_info(guild_id, agent_id)\nif not process_info.get('is_alive'):\n    # Handle dead process\n    engine.stop_agent(guild_id, agent_id)\n    # Optionally restart the agent\n</code></pre> <p>See the Guilds and Agents sections for how execution integrates with agent and guild lifecycles. </p>"},{"location":"core/guilds.html","title":"Guilds","text":"<p>A Guild is a logical grouping of agents in Rustic AI. It acts as a collaborative environment, managing the lifecycle, execution, and coordination of its member agents. Guilds provide a shared context, including common dependencies, message routing infrastructure, and state management facilities.</p>"},{"location":"core/guilds.html#purpose","title":"Purpose","text":"<ul> <li>Organize Agents: Group agents into functional units for specific tasks or workflows.</li> <li>Lifecycle Management: Control the registration, launching, execution, and removal of agents.</li> <li>Coordinated Execution: Define how agents run, leveraging different Execution Engines.</li> <li>Message Orchestration: Define sophisticated Messaging flows between agents using routes.</li> <li>Shared Resources: Provide shared Dependencies and State for member agents.</li> </ul>"},{"location":"core/guilds.html#guild-specification-guildspec","title":"Guild Specification (<code>GuildSpec</code>)","text":"<p>A <code>GuildSpec</code> is a declarative blueprint that defines the structure and behavior of a Guild. It's typically defined in a YAML or JSON file, or constructed programmatically using the <code>GuildBuilder</code>.</p> <p>Key fields in a <code>GuildSpec</code>:</p> <ul> <li><code>id</code> (str): A unique identifier for the Guild. Defaults to a <code>shortuuid</code>.</li> <li><code>name</code> (str): A human-readable name for the Guild (1-64 characters).</li> <li><code>description</code> (str): A detailed description of the Guild's purpose.</li> <li><code>properties</code> (Dict[str, Any]): A dictionary for guild-specific configurations. This often includes:     -   <code>execution_engine</code> (str): The fully qualified class name of the Execution Engine to use (e.g., <code>\"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\"</code>).     -   <code>messaging</code> (Dict): Configuration for the Messaging system, including <code>backend_module</code>, <code>backend_class</code>, and <code>backend_config</code>.     -   <code>client_type</code> (str): The default <code>Client</code> class for agents.     -   <code>client_properties</code> (Dict): Default properties for agent clients.</li> <li><code>agents</code> (List[AgentSpec]): A list of Agent Specifications (<code>AgentSpec</code>) that define the agents belonging to this guild.</li> <li><code>dependency_map</code> (Dict[str, DependencySpec]): A mapping of dependency keys to Dependency Specifications (<code>DependencySpec</code>) available to all agents in the guild. These can be overridden at the agent level.</li> <li><code>routes</code> (RoutingSlip): Defines the message routing rules within the guild. This is a powerful mechanism for orchestrating agent interactions.</li> </ul>"},{"location":"core/guilds.html#example-guildspec-conceptual-json","title":"Example <code>GuildSpec</code> (Conceptual JSON)","text":"<pre><code>{\n    \"id\": \"research-guild-01\",\n    \"name\": \"Research Guild\",\n    \"description\": \"A guild to research topics using multiple agents.\",\n    \"properties\": {\n        \"execution_engine\": \"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\",\n        \"messaging\": {\n            \"backend_module\": \"rustic_ai.core.messaging.backend\",\n            \"backend_class\": \"InMemoryMessagingBackend\",\n            \"backend_config\": {}\n        }\n    },\n    \"agents\": [\n        // ... AgentSpec definitions here ... (see Agents section below)\n    ],\n    \"dependency_map\": {\n        \"database\": {\n            \"class_name\": \"my_package.resolvers.DatabaseResolver\",\n            \"properties\": {\n                \"connection_string\": \"postgresql://user:pass@host/db\"\n            }\n        },\n        \"api_client\": {\n            \"class_name\": \"my_package.resolvers.ApiClientResolver\",\n            \"properties\": {\n                \"api_key\": \"secret-key\",\n                \"base_url\": \"https://api.example.com\"\n            }\n        }\n    },\n    \"routes\": {\n        // ... RoutingSlip definition here ... (see Routes section below)\n    }\n}\n</code></pre>"},{"location":"core/guilds.html#agents-within-a-guild","title":"Agents within a Guild","text":"<p>The <code>agents</code> field in <code>GuildSpec</code> is a list of <code>AgentSpec</code> objects. Each <code>AgentSpec</code> defines an individual agent within the guild. Key <code>AgentSpec</code> fields include:</p> <ul> <li><code>id</code> (str): Unique ID for the agent.</li> <li><code>name</code> (str): Human-readable name.</li> <li><code>description</code> (str): Agent's purpose.</li> <li><code>class_name</code> (str): Fully qualified class name of the agent (e.g., <code>\"rustic_ai.agents.llm.litellm.litellm_agent.LiteLLMAgent\"</code>).</li> <li><code>additional_topics</code> (List[str]): Specific message topics the agent subscribes to.</li> <li><code>properties</code> (Dict[str, Any]): Agent-specific configuration (e.g., LLM model, API keys).</li> <li><code>listen_to_default_topic</code> (bool): Whether the agent listens to the guild's default topic.</li> <li><code>dependency_map</code> (Dict[str, DependencySpec]): Agent-specific dependencies, which can override guild-level ones.</li> </ul> <p>Refer to the Agents documentation for a complete overview of <code>AgentSpec</code>.</p>"},{"location":"core/guilds.html#example-agent-in-a-guild","title":"Example Agent in a Guild:","text":"<pre><code>// Inside GuildSpec.agents list\n{\n    \"id\": \"research_manager\",\n    \"name\": \"Research Manager\",\n    \"description\": \"A manager for the research process\",\n    \"class_name\": \"rustic_ai.agents.laira.research_manager.ResearchManager\",\n    \"properties\": {\n        \"llm_model\": \"gpt-4o\"\n    },\n    \"listen_to_default_topic\": true\n}\n</code></pre>"},{"location":"core/guilds.html#guild-level-dependencies-dependency_map","title":"Guild-Level Dependencies (<code>dependency_map</code>)","text":"<p>The <code>dependency_map</code> in <code>GuildSpec</code> allows you to define dependencies that are available to all agents within the guild. This is useful for sharing resources like database connections, API clients, or configuration objects.</p> <ul> <li>Each key in the map is a name by which agents can request the dependency.</li> <li>The value is a <code>DependencySpec</code> that defines how to resolve and instantiate the dependency.</li> <li>Agent-specific <code>dependency_map</code> entries can override guild-level ones with the same key.</li> </ul> <p>See Dependencies for more details on how dependency injection works.</p>"},{"location":"core/guilds.html#message-routing-routes","title":"Message Routing (<code>routes</code>)","text":"<p>The <code>routes</code> field in <code>GuildSpec</code> defines a <code>RoutingSlip</code>. A RoutingSlip is a list of <code>RoutingRule</code> objects (often called \"steps\") that dictate how messages are processed and forwarded within the guild. This enables complex workflows and orchestrations.</p>"},{"location":"core/guilds.html#routingslip-structure","title":"<code>RoutingSlip</code> Structure:","text":"<p>A <code>RoutingSlip</code> primarily contains a list of <code>steps</code>, where each step is a <code>RoutingRule</code>.</p> <pre><code>// GuildSpec.routes\n\"routes\": {\n    \"steps\": [\n        // ... RoutingRule definitions here ...\n    ]\n}\n</code></pre>"},{"location":"core/guilds.html#routingrule-step-structure","title":"<code>RoutingRule</code> (Step) Structure:","text":"<p>Each <code>RoutingRule</code> defines how a message, upon matching certain criteria, should be transformed and sent to a destination. Key fields include:</p> <ul> <li><code>agent</code> (AgentTag) or <code>agent_type</code> (str):     -   <code>agent</code>: Specifies a particular agent instance by its <code>id</code> or <code>name</code> (e.g., <code>{\"name\": \"echo_agent_1\"}</code>). This rule applies to messages produced by this specific agent.     -   <code>agent_type</code>: Specifies an agent class (e.g., <code>\"rustic_ai.agents.utils.user_proxy_agent.UserProxyAgent\"</code>). This rule applies to messages produced by any agent of this type.</li> <li><code>method_name</code> (str, optional): The name of the method on the source agent that produced the message. If specified, the rule only applies to messages from this method.</li> <li><code>origin_filter</code> (Dict, optional): Further filters messages based on their origin:     -   <code>origin_sender</code> (AgentTag): The original sender of the message.     -   <code>origin_topic</code> (str): The topic the original message was on.     -   <code>origin_message_format</code> (str): The Pydantic model type of the original message.</li> <li><code>message_format</code> (str, optional): The Pydantic model type (fully qualified name) of the incoming message payload this rule should match (e.g., <code>\"rustic_ai.ui_protocol.types.TextFormat\"</code>).</li> <li><code>transformer</code> (Dict, optional): Defines how to transform the incoming message payload before sending it to the destination.     -   <code>expression</code> (str): A JSONata expression or a custom transformation logic to apply to the incoming message payload.     -   <code>output_format</code> (str): The Pydantic model type (fully qualified name) of the transformed payload (e.g., <code>\"rustic_ai.agents.laira.research_manager.UserQuery\"</code>).     Example: <code>{\"expression\": \"{\\\"query\\\": text}\", \"output_format\": \"rustic_ai.agents.laira.research_manager.UserQuery\"}</code></li> <li><code>destination</code> (Dict, optional): Specifies where the (transformed) message should be sent. If <code>null</code>, the message is typically sent back to the original sender or follows routing slip logic from the incoming message.     -   <code>topics</code> (str | List[str]): The topic(s) to publish the message to (e.g., <code>\"echo_topic\"</code>, <code>\"user_message_broadcast\"</code>).     -   <code>recipient_list</code> (List[AgentTag]): A list of specific agents to send the message to.     -   <code>priority</code> (int, optional): Message priority.</li> <li><code>route_times</code> (int): How many times this rule can be applied. <code>1</code> means it applies once. <code>-1</code> means it can apply indefinitely for messages matching its criteria.</li> <li><code>mark_forwarded</code> (bool, default: <code>false</code>): If <code>true</code>, marks the message as forwarded, which can influence subsequent routing decisions.</li> </ul>"},{"location":"core/guilds.html#example-route-step","title":"Example Route Step:","text":"<p>This rule takes a <code>TextFormat</code> message from a <code>UserProxyAgent</code>, transforms its <code>text</code> field into a <code>UserQuery</code>'s <code>query</code> field, and sends it to the <code>default_topic</code>.</p> <pre><code>// Inside RoutingSlip.steps list\n{\n    \"agent_type\": \"rustic_ai.agents.utils.user_proxy_agent.UserProxyAgent\",\n    \"method_name\": \"unwrap_and_forward_message\", // From UserProxyAgent\n    \"message_format\": \"rustic_ai.ui_protocol.types.TextFormat\",\n    \"transformer\": {\n        \"expression\": \"{\\\"query\\\": text}\",\n        \"output_format\": \"rustic_ai.agents.laira.research_manager.UserQuery\"\n    },\n    \"destination\": {\n        \"topics\": \"default_topic\"\n    },\n    \"route_times\": 1\n}\n</code></pre> <p>Routing slips enable powerful patterns: -   Sequential Processing: Message passed from agent A -&gt; B -&gt; C. -   Fan-out/Fan-in: One message triggers multiple agents, results are aggregated. -   Content-Based Routing: Message content dictates the next recipient. -   Transformations: Messages are reshaped between agents to match differing interfaces.</p>"},{"location":"core/guilds.html#guild-lifecycle-management","title":"Guild Lifecycle &amp; Management","text":"<p>Managing the lifecycle of a Guild involves defining its structure, instantiating it, launching its agents, facilitating their interactions, and eventually shutting it down. Rustic AI provides different mechanisms for bringing a Guild to life, suited for development versus production environments.</p> <ol> <li>Definition (<code>GuildSpec</code>): The blueprint for a Guild is its <code>GuildSpec</code>. This can be defined in a YAML/JSON file or constructed programmatically using <code>GuildBuilder</code> and <code>AgentBuilder</code>.</li> </ol> <p>```python     # Basic programmatic GuildSpec construction     from rustic_ai.core.guild.builders import GuildBuilder, AgentBuilder, RouteBuilder     from rustic_ai.core.guild.dsl import GuildSpec, AgentSpec, RoutingSlip, RoutingRule     from rustic_ai.core.messaging.core.message import AgentTag     # Assuming EchoAgent and UserProxyAgent are defined/imported     # from rustic_ai.core.agents.testutils import EchoAgent     # from rustic_ai.core.agents.utils import UserProxyAgent </p> <pre><code># Define an AgentSpec\necho_agent_spec = AgentBuilder(EchoAgent) \\\n    .set_name(\"echo_agent_1\") \\\n    .set_description(\"Echoes input\") \\\n    .add_additional_topic(\"echo_topic\") \\\n    .listen_to_default_topic(False) \\\n    .build_spec()\n\n# Define a Route\nroute1 = RouteBuilder(from_agent=UserProxyAgent) \\\n    .from_method(\"unwrap_and_forward_message\") \\\n    .on_message_format(\"rustic_ai.ui_protocol.types.TextFormat\") \\\n    .set_destination_topics(\"echo_topic\") \\\n    .set_route_times(1) \\\n    .build()\n\nroute2 = RouteBuilder(from_agent=AgentTag(name=\"echo_agent_1\")) \\\n    .set_destination_topics(\"user_message_broadcast\") \\\n    .set_route_times(1) \\\n    .build()\n\nrouting_slip = RoutingSlip(steps=[route1, route2])\n\n# Build the GuildSpec\nguild_builder = GuildBuilder(guild_name=\"MyDevGuild\", guild_description=\"For local testing.\") \\\n    .set_execution_engine(\"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\") \\\n    .set_messaging(\n        backend_module=\"rustic_ai.core.messaging.backend\",\n        backend_class=\"InMemoryMessagingBackend\",\n        backend_config={}\n    ) \\\n    .add_agent_spec(echo_agent_spec) \\\n    .set_routes(routing_slip)\n\nguild_spec = guild_builder.build_spec()\n```\n</code></pre> <ol> <li>Instantiation and Launching Agents:</li> </ol> <p>There are two main approaches to instantiate a <code>Guild</code> from a <code>GuildSpec</code> and launch its agents, provided by the <code>GuildBuilder</code>:</p> <pre><code>*   **`guild_builder.launch()` - For Development &amp; Testing:**\n    *   **How it works:** This method is a convenient way to quickly bring up an entire Guild and its agents in the current environment. \n        1. It first creates a `Guild` instance from the `GuildSpec` (a \"shallow\" guild without agents running).\n        2. Then, it iterates through all `AgentSpec`s defined within the `GuildSpec` and calls `guild.launch_agent(agent_spec)` for each. The `guild.launch_agent()` method handles registering the agent with the guild and then uses the Guild's configured `ExecutionEngine` to start the agent.\n    *   **Outcome:** A fully operational `Guild` with all its agents running.\n    *   **Use Case:** Best suited for local development, running examples, and automated tests where immediate, self-contained execution is desired.\n    ```python\n    # Assuming guild_builder is configured as above\n    # development_guild = guild_builder.launch(org_id=\"myawesomeorgid\")\n    # print(f\"Guild '{development_guild.name}' launched with {development_guild.get_agent_count()} agent(s).\")\n    # # ... interact with the guild ...\n    # development_guild.shutdown()\n    ```\n\n*   **`guild_builder.bootstrap(metastore_database_url: str, org_id: str = \"myawesomeorgid\")` - For Production:**\n    *   **How it works:** This method is designed for more robust, production-like deployments.\n        1. It also starts by creating a \"shallow\" `Guild` instance from the `GuildSpec`.\n        2. However, instead of directly launching the agents from the `GuildSpec`, it instantiates and launches a special system agent called `GuildManagerAgent`.\n        3. This `GuildManagerAgent` is configured with the original `GuildSpec` and the `metastore_database_url`.\n        4. The `GuildManagerAgent` then takes on the responsibility of persisting the `GuildSpec` to the metastore and managing the lifecycle (launching, monitoring, stopping) of the user-defined agents based on this persisted specification. \n    *   **Outcome:** A `Guild` instance where the primary user-defined agents are managed by the `GuildManagerAgent`, facilitating persistence, and potentially more advanced lifecycle operations suitable for production (like distributed execution, depending on the execution engine).\n    *   **Use Case:** Recommended for production or staging environments where Guilds need to be persistent, managed centrally, and potentially operate in a distributed manner.\n    ```python\n    # Assuming guild_builder is configured as above\n    # METASTORE_URL = \"sqlite:///./rusticai_metastore.db\" # Example\n    # production_guild = guild_builder.bootstrap(metastore_database_url=METASTORE_URL, org_id=\"myawesomeorgid\")\n    # print(f\"Guild '{production_guild.name}' bootstrapped. GuildManagerAgent is running.\")\n    # # Agents defined in guild_spec will be launched by GuildManagerAgent\n    # # ... (Guild operates, likely in a separate process or managed environment) ...\n    # # Shutdown would typically be managed by the environment or the GuildManagerAgent's signals\n    ```\n\n**Important Note on `guild.launch_agent()`:** While `guild.launch_agent(agent_spec)` is the underlying method that starts an individual agent, you typically **do not call it directly** when setting up a guild from a specification. Instead, rely on `guild_builder.launch()` for development or `guild_builder.bootstrap()` for production scenarios, as these methods handle the overall setup process correctly.\n</code></pre> <ol> <li> <p>Interaction: Once launched, agents within the Guild communicate via messages, with their interactions orchestrated by the Guild's defined routes and messaging system.</p> </li> <li> <p>Agent Management (Runtime): After initial launch, you might interact with the guild or its agents:     *   Via API endpoints if the Guild is managed by a service.     *   Programmatically in some scenarios (less common for bootstrapped guilds directly):         *   <code>guild.remove_agent(agent_id)</code>: Stops and removes an agent from the guild's tracking and execution engine.         *   <code>guild.get_agent(agent_id)</code>: Retrieves an <code>AgentSpec</code> by its ID.         *   <code>guild.list_agents()</code>: Lists all <code>AgentSpec</code>s currently registered with the guild instance.         *   <code>guild.list_all_running_agents()</code>: Lists <code>AgentSpec</code>s of agents the execution engine reports as running for this guild.</p> </li> <li> <p>Shutdown:     *   For guilds started with <code>guild_builder.launch()</code>: Call <code>guild.shutdown()</code>. This will attempt to gracefully stop all agents and release resources associated with the guild and its execution engine.     *   For guilds started with <code>guild_builder.bootstrap()</code>: Shutdown is typically managed by the environment hosting the <code>GuildManagerAgent</code> or through signals sent to it. The <code>GuildManagerAgent</code> would then handle the graceful shutdown of the agents it manages.</p> </li> </ol>"},{"location":"core/guilds.html#guild-object-api","title":"Guild Object API","text":"<p>Once a <code>Guild</code> object is instantiated (e.g., via <code>GuildBuilder().launch(org_id=\"myawesomeorgid\")</code> or <code>GuildBuilder().load()</code>), it provides several methods for interaction and introspection:</p> <ul> <li><code>guild.id</code>, <code>guild.name</code>, <code>guild.description</code>: Access basic properties.</li> <li><code>guild.register_agent(agent_spec: AgentSpec)</code>: Registers an agent spec with the guild. Does not run the agent.</li> <li><code>guild.launch_agent(agent_spec: AgentSpec, execution_engine: Optional[ExecutionEngine] = None)</code>: (As noted, primarily for internal/system use) Registers and runs an agent using the specified or guild's default execution engine.</li> <li><code>guild.remove_agent(agent_id: str)</code>: Stops the agent in the execution engine and removes it from the guild's internal tracking.</li> <li><code>guild.get_agent(agent_id: str) -&gt; Optional[AgentSpec]</code>: Retrieves a registered agent's specification by ID.</li> <li><code>guild.get_agent_by_name(name: str) -&gt; Optional[AgentSpec]</code>: Retrieves a registered agent's specification by name.</li> <li><code>guild.list_agents() -&gt; List[AgentSpec]</code>: Returns a list of all registered (not necessarily running) agent specifications.</li> <li><code>guild.list_all_running_agents() -&gt; List[AgentSpec]</code>: Queries the execution engine for agents it considers currently running for this guild.</li> <li><code>guild.get_agent_count() -&gt; int</code>: Returns the number of registered agents.</li> <li><code>guild.to_spec() -&gt; GuildSpec</code>: Converts the current state of the guild instance (including its registered agents, routes, etc.) back into a <code>GuildSpec</code> object.</li> <li><code>guild.shutdown()</code>: Initiates the shutdown process for the guild and its associated execution engine(s), attempting to stop all managed agents.</li> </ul>"},{"location":"core/guilds.html#execution-engines","title":"Execution Engines","text":"<p>Guilds use execution engines to manage how agents are run. Supported modes include synchronous, multithreaded, and more (see Execution). The execution engine is typically specified in the <code>GuildSpec.properties</code>.</p>"},{"location":"core/guilds.html#observability-remote-management","title":"Observability &amp; Remote Management","text":"<p>Large deployments expose a Guild Control Plane (HTTP/REST or gRPC) that allows operators to:</p> Endpoint Verb Description <code>/agents</code> GET List running agents <code>/agents</code> POST Register + launch a new agent <code>/agents/{id}</code> DELETE Stop and remove an agent <code>/state</code> GET Dump guild-level state snapshot <code>/metrics</code> GET Prometheus scrape endpoint <p>These endpoints are backed by the same APIs shown earlier (<code>register_agent</code>, <code>launch_agent</code>, etc.) and secured via JWT bearer tokens.</p>"},{"location":"core/guilds.html#monitoring","title":"Monitoring","text":"<p>Guilds emit the following metrics: *   <code>guild_agents_running</code> \u2013 Gauge labelled by <code>guild_id</code> and <code>agent_type</code>. *   <code>guild_messages_total</code> \u2013 Counter for messages processed. *   <code>guild_errors_total</code> \u2013 Counter for processing errors.</p> <p>Integrate with Grafana dashboards for a helicopter view of the system.</p>"},{"location":"core/guilds.html#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Dynamic Guilds: Guilds can be created, modified, and managed at runtime, especially when using a <code>GuildManagerAgent</code>.</li> <li>State Propagation: Guild-level state changes can be broadcast or made available to agents.</li> <li>Cross-Guild Communication: While guilds provide encapsulation, advanced scenarios might involve routing messages between guilds.</li> </ul> <p>See the Agents, Messaging, Execution, and Dependencies sections for more details on related components. </p>"},{"location":"core/messaging.html","title":"Messaging","text":"<p>The messaging system in Rustic AI enables asynchronous, topic-based communication between agents within guilds. It provides a layered architecture with pluggable backends for different deployment scenarios, from development to distributed production systems.</p>"},{"location":"core/messaging.html#purpose","title":"Purpose","text":"<ul> <li>Facilitate communication between agents within and across guilds</li> <li>Support topic-based publish/subscribe messaging with namespace isolation</li> <li>Enable message persistence, retrieval, and real-time notifications</li> <li>Provide pluggable storage backends for different deployment needs</li> </ul>"},{"location":"core/messaging.html#architecture-overview","title":"Architecture Overview","text":"<p>The messaging system consists of three main layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Clients     \u2502\u2500\u2500\u2500\u25b6\u2502 MessagingInterface\u2502\u2500\u2500\u2500\u25b6\u2502 MessagingBackend\u2502\n\u2502   (Agents)      \u2502    \u2502  (Message Bus)   \u2502    \u2502   (Storage)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"core/messaging.html#key-concepts","title":"Key Concepts","text":""},{"location":"core/messaging.html#messages","title":"Messages","text":"<p>Structured data packets exchanged between agents with the following key properties: - Unique IDs: Generated using <code>GemstoneID</code> with embedded timestamp and priority - Topics: Support single or multiple topic publishing - Threading: Maintain conversation threads and message history - Namespacing: Automatic namespace isolation per guild</p>"},{"location":"core/messaging.html#topics","title":"Topics","text":"<p>Channels for message delivery with automatic namespace prefixing: - Guild Isolation: Each guild gets its own namespace (e.g., <code>guild-123:topic-name</code>) - Subscription Management: Agents subscribe to topics to receive relevant messages - Multi-Topic Publishing: Single message can be published to multiple topics</p>"},{"location":"core/messaging.html#clients","title":"Clients","text":"<p>Agents interact with the messaging system via client interfaces: - MessageTrackingClient: Default client with message ordering and tracking - SimpleClient: Basic client for simple use cases - Specialized Clients: Pipeline, filtering, throttling, and other decorators</p>"},{"location":"core/messaging.html#backends","title":"Backends","text":"<p>Pluggable storage implementations: - InMemoryMessagingBackend: Fast, in-memory storage for development/testing - EmbeddedMessagingBackend: Embedded messaging for testing without external dependencies - RedisMessagingBackend: Persistent, distributed storage for production - Custom Backends: Implement <code>MessagingBackend</code> interface for specialized needs</p>"},{"location":"core/messaging.html#message-schema","title":"Message Schema","text":"<p>Every <code>Message</code> instance has the following structure:</p> <pre><code>class Message(BaseModel):\n    # Core fields\n    sender: AgentTag                    # Who sent the message\n    topics: Union[str, List[str]]       # Target topic(s)\n    payload: JsonDict                   # Message content\n    format: str                         # Message format (default: \"generic_json\")\n\n    # Optional fields\n    recipient_list: List[AgentTag]      # Tagged recipients\n    in_response_to: Optional[int]       # Reply to message ID\n    thread: List[int]                   # Conversation thread\n    conversation_id: Optional[int]      # Conversation grouping\n    forward_header: Optional[ForwardHeader]  # Forwarding information\n    routing_slip: Optional[RoutingSlip] # Multi-step routing\n    message_history: List[ProcessEntry] # Processing history\n    ttl: Optional[int]                  # Time to live\n\n    # Computed fields (read-only)\n    id: int                            # Unique message ID\n    priority: Priority                 # Message priority (0-9)\n    timestamp: float                   # Creation timestamp\n</code></pre>"},{"location":"core/messaging.html#json-serialization-example","title":"JSON Serialization Example","text":"<pre><code>{\n  \"id\": 123456789,\n  \"sender\": {\"id\": \"agent-1\", \"name\": \"Agent One\"},\n  \"topics\": \"updates\",\n  \"payload\": {\"text\": \"Hello, World!\"},\n  \"format\": \"generic_json\",\n  \"priority\": 4,\n  \"timestamp\": 1640995200.123,\n  \"thread\": [123456789],\n  \"recipient_list\": [],\n  \"in_response_to\": null,\n  \"conversation_id\": null,\n  \"forward_header\": null,\n  \"routing_slip\": null,\n  \"message_history\": [],\n  \"ttl\": null,\n  \"is_error_message\": false,\n  \"traceparent\": null,\n  \"session_state\": null,\n  \"topic_published_to\": \"updates\",\n  \"enrich_with_history\": 0\n}\n</code></pre>"},{"location":"core/messaging.html#messaginginterface-the-message-bus","title":"MessagingInterface: The Message Bus","text":"<p>The <code>MessagingInterface</code> serves as the central message bus with the following responsibilities:</p>"},{"location":"core/messaging.html#client-management","title":"Client Management","text":"<pre><code># Register agent as messaging client\nmessaging.register_client(client)\n\n# Unregister when agent shuts down\nmessaging.unregister_client(client)\n</code></pre>"},{"location":"core/messaging.html#topic-subscription","title":"Topic Subscription","text":"<pre><code># Subscribe agent to topic\nmessaging.subscribe(\"updates\", client)\n\n# Unsubscribe from topic\nmessaging.unsubscribe(\"updates\", client)\n</code></pre>"},{"location":"core/messaging.html#message-publishing","title":"Message Publishing","text":"<pre><code># Publish message to topic(s)\nmessaging.publish(sender_client, message)\n</code></pre>"},{"location":"core/messaging.html#message-retrieval","title":"Message Retrieval","text":"<pre><code># Get all messages for a topic\nmessages = messaging.get_messages(\"updates\")\n\n# Get messages since specific ID\nrecent_messages = messaging.get_messages_for_topic_since(\"updates\", last_id)\n\n# Get messages for a specific client across all subscribed topics\nclient_messages = messaging.get_messages_for_client_since(client_id, last_id)\n</code></pre>"},{"location":"core/messaging.html#advanced-features","title":"Advanced Features","text":""},{"location":"core/messaging.html#namespace-isolation","title":"Namespace Isolation","text":"<ul> <li>Automatic topic prefixing: <code>topic</code> \u2192 <code>guild-123:topic</code></li> <li>Prevents message leakage between guilds</li> <li>Transparent to agents</li> </ul>"},{"location":"core/messaging.html#message-history-enrichment","title":"Message History Enrichment","text":"<pre><code># Messages can request conversation history\nmessage.enrich_with_history = 5  # Include last 5 messages\n# History automatically added to message.session_state[\"enriched_history\"]\n</code></pre>"},{"location":"core/messaging.html#smart-subscription-management","title":"Smart Subscription Management","text":"<ul> <li>Lazy backend subscription (only when first client subscribes)</li> <li>Reference counting (unsubscribe from backend when last client leaves)</li> <li>Automatic cleanup on client disconnect</li> </ul>"},{"location":"core/messaging.html#messagingbackend-storage-layer","title":"MessagingBackend: Storage Layer","text":"<p>The <code>MessagingBackend</code> abstract base class defines the interface for message storage:</p>"},{"location":"core/messaging.html#core-interface","title":"Core Interface","text":"<pre><code>class MessagingBackend(ABC):\n    @abstractmethod\n    def store_message(self, namespace: str, topic: str, message: Message) -&gt; None:\n        \"\"\"Store a message in the backend\"\"\"\n\n    @abstractmethod\n    def get_messages_for_topic(self, topic: str) -&gt; List[Message]:\n        \"\"\"Retrieve all messages for a topic\"\"\"\n\n    @abstractmethod\n    def get_messages_for_topic_since(self, topic: str, msg_id_since: int) -&gt; List[Message]:\n        \"\"\"Retrieve messages since a specific ID\"\"\"\n\n    @abstractmethod\n    def subscribe(self, topic: str, handler: Callable[[Message], None]) -&gt; None:\n        \"\"\"Subscribe to real-time notifications\"\"\"\n\n    @abstractmethod\n    def get_messages_by_id(self, namespace: str, msg_ids: List[int]) -&gt; List[Message]:\n        \"\"\"Batch retrieve messages by ID\"\"\"\n</code></pre>"},{"location":"core/messaging.html#available-backends","title":"Available Backends","text":""},{"location":"core/messaging.html#inmemorymessagingbackend","title":"InMemoryMessagingBackend","text":"<pre><code># Configuration\nMessagingConfig(\n    backend_module=\"rustic_ai.core.messaging.backend\",\n    backend_class=\"InMemoryMessagingBackend\",\n    backend_config={}\n)\n</code></pre> <p>Features:</p> <ul> <li>Performance: Extremely fast in-memory operations</li> <li>Real-time: Immediate callback-based notifications</li> <li>Singleton: Shared state across multiple interface instances</li> <li>Development: Perfect for testing and development</li> </ul> <p>Limitations:</p> <ul> <li>Not Persistent: Data lost on restart</li> <li>Single Process: Cannot share across processes</li> <li>Memory Bound: Limited by available RAM</li> </ul>"},{"location":"core/messaging.html#embeddedmessagingbackend","title":"EmbeddedMessagingBackend","text":"<pre><code># Configuration with auto-start server\nMessagingConfig(\n    backend_module=\"rustic_ai.core.messaging.backend.embedded_backend\",\n    backend_class=\"EmbeddedMessagingBackend\",\n    backend_config={}\n)\n\n# Configuration with external server\nMessagingConfig(\n    backend_module=\"rustic_ai.core.messaging.backend.embedded_backend\",\n    backend_class=\"EmbeddedMessagingBackend\",\n    backend_config={\n        \"port\": 31134,\n        \"auto_start_server\": False\n    }\n)\n</code></pre> <p>Features:</p> <ul> <li>Cross-Process: Enables communication between separate processes</li> <li>Socket-Based: Fast TCP socket communication with asyncio</li> <li>No External Dependencies: Uses only Python standard library</li> <li>Real-time Subscriptions: True push delivery with asyncio</li> <li>Message TTL: Automatic message expiration</li> <li>Auto-cleanup: Automatic resource management and cleanup</li> <li>Back-pressure Handling: Per-connection queues with overflow protection</li> <li>Testing Focused: Ideal for testing multiprocess scenarios</li> </ul> <p>Use Cases:</p> <ul> <li>Multiprocess Testing: Test agents running in separate processes</li> <li>Development: Fast messaging without external setup</li> <li>CI/CD: Testing distributed scenarios without infrastructure</li> <li>Process Isolation: When you need true process separation</li> </ul> <p>Limitations:</p> <ul> <li>Memory Only: Data not persisted to disk</li> <li>Single Server: No clustering or high availability</li> <li>Testing Scope: Designed for testing rather than production</li> </ul>"},{"location":"core/messaging.html#redismessagingbackend","title":"RedisMessagingBackend","text":"<pre><code># Configuration\nMessagingConfig(\n    backend_module=\"rustic_ai.redis.messaging.backend\",\n    backend_class=\"RedisMessagingBackend\",\n    backend_config={\n        \"redis_client\": {\n            \"host\": \"localhost\",\n            \"port\": 6379,\n            \"ssl\": False\n        }\n    }\n)\n</code></pre> <p>Features:</p> <ul> <li>Persistent: Data survives restarts</li> <li>Distributed: Shared across processes and machines</li> <li>Scalable: Redis clustering support</li> <li>Real-time: Redis pub/sub for notifications</li> <li>TTL Support: Configurable message expiration</li> <li>Efficient: Pipeline operations for batch processing</li> </ul> <p>Storage Strategy:</p> <ul> <li>Sorted Sets: Messages stored with timestamp scores for ordering</li> <li>Secondary Index: Direct ID lookup via <code>msg:namespace:id</code> keys</li> <li>Pub/Sub: Real-time notifications via Redis pub/sub</li> </ul>"},{"location":"core/messaging.html#configuration","title":"Configuration","text":""},{"location":"core/messaging.html#messagingconfig","title":"MessagingConfig","text":"<pre><code>class MessagingConfig(BaseModel):\n    backend_module: str      # Python module containing backend\n    backend_class: str       # Backend class name\n    backend_config: Dict     # Backend-specific configuration\n</code></pre>"},{"location":"core/messaging.html#dynamic-backend-creation","title":"Dynamic Backend Creation","text":"<pre><code># MessagingConfig automatically creates backend instances\nconfig = MessagingConfig(\n    backend_module=\"rustic_ai.core.messaging.backend\",\n    backend_class=\"InMemoryMessagingBackend\",\n    backend_config={}\n)\n\n# Socket messaging backend helper\nfrom rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\nembedded_config = create_embedded_messaging_config()\n\n# MessagingInterface uses config to create backend\nmessaging = MessagingInterface(namespace=\"guild-123\", messaging_config=config)\n</code></pre>"},{"location":"core/messaging.html#message-flow-example","title":"Message Flow Example","text":"<pre><code># 1. Agent A sends message\nmessage = Message(\n    id_obj=generator.get_id(Priority.NORMAL),\n    sender=AgentTag(id=\"agent-a\", name=\"Agent A\"),\n    topics=\"updates\",\n    payload={\"text\": \"Hello, Agent B!\"}\n)\n\n# 2. Publish via messaging interface\nmessaging_interface.publish(client_a, message)\n\n# 3. MessagingInterface processes:\n#    - Adds namespace prefix: \"updates\" \u2192 \"guild-123:updates\"\n#    - Stores in backend\n#    - Notifies subscribers\n\n# 4. Backend stores and notifies:\n#    - InMemory: Immediate callback\n#    - SocketMessaging: Socket push delivery\n#    - Redis: Pub/sub notification\n\n# 5. Agent B receives message:\n#    - Client notified via callback\n#    - Message delivered to agent's message handler\n</code></pre>"},{"location":"core/messaging.html#cross-process-messaging-example","title":"Cross-Process Messaging Example","text":"<pre><code># Process 1: Setup embedded messaging backend with MultiProcessExecutionEngine\nfrom rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\nfrom rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\n\n# Create messaging config for cross-process communication\nmessaging_config = create_embedded_messaging_config()\n\n# Create guild with multiprocess execution\nguild = Guild(\n    guild_id=\"distributed-guild\",\n    execution_engine=MultiProcessExecutionEngine(guild_id=\"distributed-guild\"),\n    messaging_config=messaging_config\n)\n\n# Launch agents in separate processes\nfor i in range(3):\n    agent_spec = create_worker_agent_spec(f\"worker-{i}\")\n    guild.launch_agent(agent_spec)\n\n# Agents can now communicate across processes via socket messaging backend\n# - No Redis setup required\n# - Process isolation maintained\n# - Real-time messaging via socket push delivery\n</code></pre>"},{"location":"core/messaging.html#client-types","title":"Client Types","text":""},{"location":"core/messaging.html#messagetrackingclient-default","title":"MessageTrackingClient (Default)","text":"<pre><code>class MessageTrackingClient(Client):\n    \"\"\"Tracks message processing with ordering and deduplication\"\"\"\n</code></pre> <ul> <li>Message Ordering: Processes messages in ID order</li> <li>Tracking: Tracks last processed message ID</li> <li>Threading: Uses events and heaps for efficient processing</li> </ul>"},{"location":"core/messaging.html#simpleclient","title":"SimpleClient","text":"<p><pre><code>class SimpleClient(Client):\n    \"\"\"Basic client for simple messaging needs\"\"\"\n</code></pre> - Lightweight: Minimal overhead - Direct: Immediate message processing</p>"},{"location":"core/messaging.html#specialized-clients","title":"Specialized Clients","text":"<ul> <li>PipelineClient: Chain multiple processing steps</li> <li>FilteringClient: Filter messages based on criteria</li> <li>ThrottlingClient: Rate-limit message processing</li> <li>RetryingClient: Automatic retry on failures</li> <li>LoggingClient: Add logging to message processing</li> </ul>"},{"location":"core/messaging.html#integration-with-execution-engines","title":"Integration with Execution Engines","text":""},{"location":"core/messaging.html#execution-engine-compatibility","title":"Execution Engine Compatibility","text":"<p>Different execution engines work optimally with different messaging backends:</p> Execution Engine Recommended Backend Reason <code>SyncExecutionEngine</code> <code>InMemoryMessagingBackend</code> Fast, single-process operation <code>MultiThreadedEngine</code> <code>InMemoryMessagingBackend</code> or <code>RedisMessagingBackend</code> Thread-safe with shared memory <code>MultiProcessExecutionEngine</code> <code>EmbeddedMessagingBackend</code> or <code>RedisMessagingBackend</code> Cross-process communication <code>RayExecutionEngine</code> <code>RedisMessagingBackend</code> Distributed messaging <p>The EmbeddedMessagingBackend is particularly well-suited for the <code>MultiProcessExecutionEngine</code> because: - No External Dependencies: Works without Redis setup - Process Isolation: Each process gets proper isolation while maintaining communication - Testing Friendly: Ideal for testing distributed scenarios in CI/CD - Redis-like Features: Provides coordination primitives for process synchronization</p>"},{"location":"core/messaging.html#execution-engine-responsibilities","title":"Execution Engine Responsibilities","text":"<ul> <li>Configuration: Provide <code>MessagingConfig</code> to agent wrappers</li> <li>Lifecycle: Coordinate messaging setup during agent initialization</li> <li>Isolation: Each agent gets its own messaging client</li> </ul>"},{"location":"core/messaging.html#agent-wrapper-integration","title":"Agent Wrapper Integration","text":"<pre><code>class AgentWrapper:\n    def initialize_agent(self):\n        # Create MessagingInterface from config\n        self.messaging = MessagingInterface(self.agent.guild_id, self.messaging_config)\n\n        # Create and register client\n        client = self.client_type(\n            id=self.agent.id,\n            name=self.agent.name,\n            message_handler=self.agent._on_message\n        )\n        self.messaging.register_client(client)\n\n        # Subscribe to agent's topics\n        for topic in self.agent.subscribed_topics:\n            self.messaging.subscribe(topic, client)\n</code></pre>"},{"location":"core/messaging.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"core/messaging.html#messaginginterface-performance","title":"MessagingInterface Performance","text":"<ul> <li>Client Lookup: O(1) by client ID</li> <li>Topic Subscription: O(1) for subscription management</li> <li>Message Copying: Deep copies for isolation (memory overhead)</li> <li>Namespace Processing: O(1) string operations</li> </ul>"},{"location":"core/messaging.html#backend-performance-comparison","title":"Backend Performance Comparison","text":"Feature InMemoryBackend EmbeddedMessagingBackend RedisBackend Latency ~1\u03bcs ~0.1-1ms ~1-10ms Throughput Very High Very High High Persistence None None Full Scalability Single Process Multi-Process Distributed Memory Usage High (all in RAM) Medium (socket overhead) Low (Redis manages) Real-time Immediate Push delivery Near real-time Cross-Process No Yes Yes External Dependencies None None Redis Server"},{"location":"core/messaging.html#best-practices","title":"Best Practices","text":""},{"location":"core/messaging.html#development","title":"Development","text":"<ul> <li>Use <code>InMemoryMessagingBackend</code> for fast iteration and single-process testing</li> <li>Use <code>EmbeddedMessagingBackend</code> for testing multiprocess scenarios and process isolation</li> <li>Enable debug logging for message flow visibility</li> <li>Use <code>SyncExecutionEngine</code> for deterministic testing</li> </ul>"},{"location":"core/messaging.html#testing","title":"Testing","text":"<ul> <li>Use <code>EmbeddedMessagingBackend</code> with <code>MultiProcessExecutionEngine</code> for realistic testing</li> <li>Leverage embedded messaging backend's message-based operations for test coordination</li> <li>Use real-time subscriptions for responsive test monitoring</li> <li>Take advantage of automatic cleanup for test isolation</li> </ul>"},{"location":"core/messaging.html#production","title":"Production","text":"<ul> <li>Use <code>RedisMessagingBackend</code> for persistence and scalability</li> <li>Configure appropriate message TTL to manage storage</li> <li>Use <code>MultiThreadedEngine</code> or <code>RayExecutionEngine</code> for concurrency</li> <li>Monitor Redis memory usage and performance</li> </ul>"},{"location":"core/messaging.html#message-design","title":"Message Design","text":"<ul> <li>Keep payloads reasonably sized (&lt; 1MB recommended)</li> <li>Use meaningful topic names with clear hierarchy</li> <li>Include correlation IDs for request/response patterns</li> <li>Leverage message threading for conversation tracking</li> </ul>"},{"location":"core/messaging.html#error-handling","title":"Error Handling","text":""},{"location":"core/messaging.html#message-validation","title":"Message Validation","text":"<ul> <li>Pydantic-based validation for message structure</li> <li>Automatic type checking and conversion</li> <li>Clear error messages for invalid data</li> </ul>"},{"location":"core/messaging.html#backend-failures","title":"Backend Failures","text":"<ul> <li>MessagingInterface handles backend initialization errors</li> <li>Graceful degradation when backend unavailable</li> <li>Proper cleanup on shutdown</li> </ul>"},{"location":"core/messaging.html#client-disconnection","title":"Client Disconnection","text":"<ul> <li>Automatic cleanup of subscriptions</li> <li>Resource cleanup on client disconnect</li> <li>Graceful handling of client failures</li> </ul>"},{"location":"core/messaging.html#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"core/messaging.html#built-in-logging","title":"Built-in Logging","text":"<ul> <li>Structured logging for message flow</li> <li>Debug-level logging for detailed tracing</li> <li>Error logging for failure scenarios</li> </ul>"},{"location":"core/messaging.html#opentelemetry-support","title":"OpenTelemetry Support","text":"<ul> <li>Trace context propagation via <code>traceparent</code> field</li> <li>Distributed tracing across agent interactions</li> <li>Integration with observability platforms</li> </ul>"},{"location":"core/messaging.html#metrics-recommended","title":"Metrics (Recommended)","text":"<ul> <li>Message throughput per topic</li> <li>Client subscription counts</li> <li>Backend performance metrics</li> <li>Error rates and types</li> </ul> <p>See the Execution section for how messaging integrates with execution engines, Embedded Messaging Backend for detailed information about cross-process messaging, and Agents for agent-specific messaging patterns. </p>"},{"location":"core/multiprocess_execution.html","title":"Multiprocess Execution Engine","text":"<p>The Multiprocess Execution Engine provides true parallel execution by running agents in separate processes, completely escaping Python's Global Interpreter Lock (GIL). This enables CPU-intensive tasks to run with genuine parallelism while providing process isolation for enhanced robustness.</p>"},{"location":"core/multiprocess_execution.html#overview","title":"Overview","text":"<p>The multiprocess execution engine consists of three main components:</p> <ol> <li>MultiProcessExecutionEngine: The main execution engine that manages agent processes</li> <li>MultiProcessAgentWrapper: Wraps agents and runs them in separate processes</li> <li>MultiProcessAgentTracker: Tracks and manages agent processes using shared memory</li> </ol>"},{"location":"core/multiprocess_execution.html#key-features","title":"Key Features","text":""},{"location":"core/multiprocess_execution.html#core-execution-features","title":"Core Execution Features","text":"<ul> <li>True Parallelism: Completely escapes Python's GIL for genuine concurrent execution</li> <li>Process Isolation: Each agent runs in its own process, providing fault tolerance</li> <li>Shared Memory Tracking: Cross-process agent management using multiprocessing.Manager</li> <li>Graceful Shutdown: Proper process termination with timeout handling</li> <li>Process Limits: Configurable maximum number of concurrent processes</li> <li>Automatic Cleanup: Dead process detection and cleanup</li> </ul>"},{"location":"core/multiprocess_execution.html#process-management-features","title":"Process Management Features","text":"<ul> <li>Process Health Monitoring: Real-time monitoring of agent process status</li> <li>Resource Management: Proper cleanup of processes and shared memory</li> <li>Fault Tolerance: Automatic detection and handling of crashed processes</li> <li>Process Information: Detailed process info including PID, status, and memory usage</li> <li>Cross-platform Support: Uses 'spawn' start method for compatibility</li> </ul>"},{"location":"core/multiprocess_execution.html#integration-features","title":"Integration Features","text":"<ul> <li>Messaging Support: Works seamlessly with socket messaging and Redis backends</li> <li>Dependency Injection: Full support for agent dependencies across processes</li> <li>Guild Integration: Complete integration with guild lifecycle management</li> <li>Statistics: Comprehensive engine and process statistics</li> </ul>"},{"location":"core/multiprocess_execution.html#basic-usage","title":"Basic Usage","text":""},{"location":"core/multiprocess_execution.html#simple-setup","title":"Simple Setup","text":"<pre><code>from rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\n\n# Create engine with default CPU count\nengine = MultiProcessExecutionEngine(guild_id=\"my-guild\")\n\n# Create engine with specific process limit\nengine = MultiProcessExecutionEngine(guild_id=\"my-guild\", max_processes=8)\n</code></pre>"},{"location":"core/multiprocess_execution.html#with-guild","title":"With Guild","text":"<pre><code>from rustic_ai.core.guild import Guild\nfrom rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\nfrom rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\n\n# Create messaging config that works well with multiprocess\nmessaging_config = create_embedded_messaging_config()\n\n# Create guild with multiprocess engine\nguild = Guild(\n    guild_id=\"cpu_intensive_guild\",\n    execution_engine=MultiProcessExecutionEngine(\n        guild_id=\"cpu_intensive_guild\",\n        max_processes=multiprocessing.cpu_count()\n    ),\n    messaging_config=messaging_config\n)\n\n# Launch CPU-intensive agents\nfor i in range(4):\n    agent_spec = create_cpu_intensive_agent_spec(f\"worker_{i}\")\n    guild.launch_agent(agent_spec)\n</code></pre>"},{"location":"core/multiprocess_execution.html#advanced-usage","title":"Advanced Usage","text":""},{"location":"core/multiprocess_execution.html#cpu-intensive-workloads","title":"CPU-Intensive Workloads","text":"<pre><code>from rustic_ai.core.guild import AgentBuilder\nimport multiprocessing\n\n# Create agents for parallel computation\ndef create_computation_agents(guild, data_chunks):\n    engine = MultiProcessExecutionEngine(\n        guild_id=guild.id,\n        max_processes=multiprocessing.cpu_count()\n    )\n\n    agents = []\n    for i, chunk in enumerate(data_chunks):\n        agent_spec = (AgentBuilder()\n            .set_name(f\"compute_worker_{i}\")\n            .set_description(f\"Process data chunk {i}\")\n            .set_class_name(\"ComputeAgent\")\n            .add_dependency(\"data_chunk\", chunk)\n            .build_spec())\n\n        guild.launch_agent(agent_spec, execution_engine=engine)\n        agents.append(agent_spec)\n\n    return agents\n</code></pre>"},{"location":"core/multiprocess_execution.html#process-monitoring","title":"Process Monitoring","text":"<pre><code># Monitor agent processes\ndef monitor_agents(engine, guild_id):\n    agents = engine.get_agents_in_guild(guild_id)\n\n    for agent_id, agent_spec in agents.items():\n        process_info = engine.get_process_info(guild_id, agent_id)\n        is_alive = engine.is_agent_running(guild_id, agent_id)\n\n        print(f\"Agent {agent_id}:\")\n        print(f\"  PID: {process_info.get('pid')}\")\n        print(f\"  Alive: {is_alive}\")\n        print(f\"  Name: {agent_spec.name}\")\n\n# Get engine statistics\nstats = engine.get_engine_stats()\nprint(f\"Total agents: {stats['owned_agents_count']}\")\nprint(f\"Max processes: {stats['max_processes']}\")\n</code></pre>"},{"location":"core/multiprocess_execution.html#fault-tolerance","title":"Fault Tolerance","text":"<pre><code>import time\n\ndef robust_agent_management(engine, guild_id):\n    \"\"\"Example of robust agent management with fault tolerance.\"\"\"\n\n    while True:\n        try:\n            # Clean up any dead processes\n            engine.cleanup_dead_processes()\n\n            # Check each agent\n            agents = engine.get_agents_in_guild(guild_id)\n            for agent_id in list(agents.keys()):\n                if not engine.is_agent_running(guild_id, agent_id):\n                    print(f\"Agent {agent_id} has died, restarting...\")\n\n                    # Get the agent spec for restarting\n                    agent_spec = agents[agent_id]\n\n                    # Remove the dead agent\n                    engine.stop_agent(guild_id, agent_id)\n\n                    # Restart the agent (would need proper guild integration)\n                    # guild.launch_agent(agent_spec, execution_engine=engine)\n\n            time.sleep(5)  # Check every 5 seconds\n\n        except KeyboardInterrupt:\n            print(\"Shutting down...\")\n            engine.shutdown()\n            break\n        except Exception as e:\n            print(f\"Error in monitoring: {e}\")\n            time.sleep(0.01)\n</code></pre>"},{"location":"core/multiprocess_execution.html#configuration-options","title":"Configuration Options","text":""},{"location":"core/multiprocess_execution.html#engine-configuration","title":"Engine Configuration","text":"<pre><code>engine = MultiProcessExecutionEngine(\n    guild_id=\"my-guild\",\n    max_processes=8,  # Maximum concurrent processes (default: CPU count)\n)\n</code></pre>"},{"location":"core/multiprocess_execution.html#messaging-configuration","title":"Messaging Configuration","text":"<p>For multiprocess execution, use messaging backends that support cross-process communication:</p> <pre><code># Option 1: Embedded Messaging Backend (recommended)\nfrom rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\n\nmessaging_config = create_embedded_messaging_config()\n\n# Option 2: Redis Backend\nfrom rustic_ai.core.messaging.core.messaging_config import MessagingConfig\n\nmessaging_config = MessagingConfig(\n    backend_module=\"rustic_ai.redis.messaging\",\n    backend_class=\"RedisMessagingBackend\",\n    backend_config={\n        \"host\": \"localhost\",\n        \"port\": 6379,\n        \"db\": 0\n    }\n)\n</code></pre>"},{"location":"core/multiprocess_execution.html#process-start-method","title":"Process Start Method","text":"<p>The engine automatically sets the multiprocessing start method to 'spawn' for better cross-platform compatibility:</p> <pre><code># This is done automatically by the engine\nimport multiprocessing\nmultiprocessing.set_start_method('spawn', force=True)\n</code></pre>"},{"location":"core/multiprocess_execution.html#api-reference","title":"API Reference","text":""},{"location":"core/multiprocess_execution.html#multiprocessexecutionengine","title":"MultiProcessExecutionEngine","text":""},{"location":"core/multiprocess_execution.html#constructor","title":"Constructor","text":"<pre><code>__init__(guild_id: str, max_processes: Optional[int] = None)\n</code></pre> <ul> <li><code>guild_id</code>: ID of the guild this engine manages</li> <li><code>max_processes</code>: Maximum number of processes (defaults to CPU count)</li> </ul>"},{"location":"core/multiprocess_execution.html#core-methods","title":"Core Methods","text":"<pre><code># Agent management\nrun_agent(guild_spec, agent_spec, messaging_config, machine_id, **kwargs)\nstop_agent(guild_id: str, agent_id: str)\nshutdown()\n\n# Agent querying\nget_agents_in_guild(guild_id: str) -&gt; Dict[str, AgentSpec]\nis_agent_running(guild_id: str, agent_id: str) -&gt; bool\nfind_agents_by_name(guild_id: str, agent_name: str) -&gt; List[AgentSpec]\n\n# Process management\nget_process_info(guild_id: str, agent_id: str) -&gt; Dict\nget_engine_stats() -&gt; Dict\ncleanup_dead_processes()\n</code></pre>"},{"location":"core/multiprocess_execution.html#multiprocessagentwrapper","title":"MultiProcessAgentWrapper","text":""},{"location":"core/multiprocess_execution.html#core-methods_1","title":"Core Methods","text":"<pre><code>run()  # Start the agent process\nshutdown()  # Stop the agent process\nis_alive() -&gt; bool  # Check if process is alive\nget_process_id() -&gt; Optional[int]  # Get process PID\n</code></pre>"},{"location":"core/multiprocess_execution.html#multiprocessagenttracker","title":"MultiProcessAgentTracker","text":""},{"location":"core/multiprocess_execution.html#core-methods_2","title":"Core Methods","text":"<pre><code># Agent tracking\nadd_agent(guild_id: str, agent_spec: AgentSpec, wrapper: MultiProcessAgentWrapper)\nremove_agent(guild_id: str, agent_id: str)\nupdate_process_info(guild_id: str, agent_id: str)\n\n# Agent querying\nget_agent_spec(guild_id: str, agent_id: str) -&gt; Optional[AgentSpec]\nget_agent_wrapper(guild_id: str, agent_id: str) -&gt; Optional[MultiProcessAgentWrapper]\nis_agent_alive(guild_id: str, agent_id: str) -&gt; bool\n\n# Statistics and management\nget_stats() -&gt; Dict\nclear()\n</code></pre>"},{"location":"core/multiprocess_execution.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"core/multiprocess_execution.html#advantages","title":"Advantages","text":"<ul> <li>True Parallelism: Completely escapes Python's GIL</li> <li>Fault Isolation: Process crashes don't affect other agents</li> <li>Memory Isolation: Each process has its own memory space</li> <li>CPU Utilization: Can fully utilize multiple CPU cores</li> <li>Scalability: Can handle CPU-intensive workloads efficiently</li> </ul>"},{"location":"core/multiprocess_execution.html#limitations","title":"Limitations","text":"<ul> <li>Memory Overhead: Each process has its own Python interpreter</li> <li>IPC Overhead: Inter-process communication has serialization costs</li> <li>Startup Time: Process creation is slower than thread creation</li> <li>Resource Usage: More system resources required than threading</li> </ul>"},{"location":"core/multiprocess_execution.html#best-use-cases","title":"Best Use Cases","text":"<ul> <li>CPU-intensive computations: Mathematical calculations, data processing</li> <li>Parallel algorithms: Monte Carlo simulations, optimization problems</li> <li>Fault-tolerant systems: Systems that need process isolation</li> <li>Mixed workloads: Combination of CPU and IO-bound tasks</li> <li>Long-running agents: Agents that run for extended periods</li> </ul>"},{"location":"core/multiprocess_execution.html#best-practices","title":"Best Practices","text":""},{"location":"core/multiprocess_execution.html#for-performance","title":"For Performance","text":"<ol> <li>Right-size Process Count: Use <code>multiprocessing.cpu_count()</code> as a starting point</li> <li>Batch Work: Process larger chunks of work to amortize process overhead</li> <li>Efficient Serialization: Use efficient data structures for inter-process communication</li> <li>Monitor Resource Usage: Track memory and CPU usage to optimize performance</li> </ol>"},{"location":"core/multiprocess_execution.html#for-reliability","title":"For Reliability","text":"<ol> <li>Health Monitoring: Regularly check process health with <code>is_agent_running()</code></li> <li>Graceful Shutdown: Always call <code>engine.shutdown()</code> for proper cleanup</li> <li>Error Handling: Implement proper error handling for process failures</li> <li>Resource Limits: Set appropriate <code>max_processes</code> to avoid resource exhaustion</li> </ol>"},{"location":"core/multiprocess_execution.html#for-development","title":"For Development","text":"<ol> <li>Start Simple: Begin with <code>SyncExecutionEngine</code> for development and debugging</li> <li>Test Isolation: Ensure agents work correctly in process isolation</li> <li>Logging: Use proper logging to debug cross-process issues</li> <li>Messaging Testing: Test with the shared memory backend for development</li> </ol>"},{"location":"core/multiprocess_execution.html#error-handling","title":"Error Handling","text":"<pre><code>try:\n    engine = MultiProcessExecutionEngine(guild_id=\"my-guild\")\n    guild.launch_agent(agent_spec, execution_engine=engine)\nexcept RuntimeError as e:\n    if \"Maximum number of processes\" in str(e):\n        # Handle process limit exceeded\n        engine.cleanup_dead_processes()\n        # Retry or reduce load\n    else:\n        raise\nexcept Exception as e:\n    print(f\"Failed to start agent: {e}\")\n    engine.shutdown()\n</code></pre>"},{"location":"core/multiprocess_execution.html#examples","title":"Examples","text":""},{"location":"core/multiprocess_execution.html#parallel-data-processing","title":"Parallel Data Processing","text":"<pre><code>import multiprocessing\nfrom rustic_ai.core.guild import Guild, AgentBuilder\nfrom rustic_ai.core.guild.execution.multiprocess import MultiProcessExecutionEngine\n\ndef parallel_data_processing():\n    # Create embedded messaging for cross-process communication\n    from rustic_ai.core.messaging.backend.embedded_backend import create_embedded_messaging_config\n    messaging_config = create_embedded_messaging_config()\n\n    # Create guild with multiprocess engine\n    guild = Guild(\n        guild_id=\"data_processing\",\n        messaging_config=messaging_config\n    )\n\n    engine = MultiProcessExecutionEngine(\n        guild_id=\"data_processing\",\n        max_processes=multiprocessing.cpu_count()\n    )\n\n    # Create worker agents for parallel processing\n    for i in range(4):\n        worker_spec = (AgentBuilder()\n            .set_name(f\"data_worker_{i}\")\n            .set_description(f\"Process data partition {i}\")\n            .set_class_name(\"DataProcessingAgent\")\n            .add_dependency(\"partition_id\", i)\n            .build_spec())\n\n        guild.launch_agent(worker_spec, execution_engine=engine)\n\n    # Create coordinator agent\n    coordinator_spec = (AgentBuilder()\n        .set_name(\"coordinator\")\n        .set_description(\"Coordinate data processing tasks\")\n        .set_class_name(\"CoordinatorAgent\")\n        .build_spec())\n\n    guild.launch_agent(coordinator_spec, execution_engine=engine)\n\n    # Monitor progress\n    try:\n        while True:\n            stats = engine.get_engine_stats()\n            print(f\"Running agents: {stats['owned_agents_count']}\")\n            time.sleep(0.01)\n    except KeyboardInterrupt:\n        print(\"Shutting down...\")\n        guild.shutdown()\n</code></pre>"},{"location":"core/multiprocess_execution.html#cpu-intensive-monte-carlo-simulation","title":"CPU-Intensive Monte Carlo Simulation","text":"<pre><code>def monte_carlo_simulation(num_workers=None):\n    if num_workers is None:\n        num_workers = multiprocessing.cpu_count()\n\n    # Setup\n    messaging_config = create_embedded_messaging_config()\n    guild = Guild(guild_id=\"monte_carlo\", messaging_config=messaging_config)\n    engine = MultiProcessExecutionEngine(guild_id=\"monte_carlo\", max_processes=num_workers)\n\n    # Create simulation workers\n    for i in range(num_workers):\n        worker_spec = (AgentBuilder()\n            .set_name(f\"simulation_worker_{i}\")\n            .set_class_name(\"MonteCarloWorkerAgent\")\n            .add_dependency(\"worker_id\", i)\n            .add_dependency(\"num_samples\", 1000000 // num_workers)\n            .build_spec())\n\n        guild.launch_agent(worker_spec, execution_engine=engine)\n\n    # Create results aggregator\n    aggregator_spec = (AgentBuilder()\n        .set_name(\"results_aggregator\")\n        .set_class_name(\"ResultsAggregatorAgent\")\n        .add_dependency(\"expected_workers\", num_workers)\n        .build_spec())\n\n    guild.launch_agent(aggregator_spec, execution_engine=engine)\n\n    return guild, engine\n</code></pre>"},{"location":"core/multiprocess_execution.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"core/multiprocess_execution.html#fork-deprecation-warning","title":"Fork() Deprecation Warning","text":"<p>When running tests, you may encounter warnings like: <pre><code>DeprecationWarning: This process (pid=297226) is multi-threaded, use of fork() may lead to deadlocks in the child.\n</code></pre></p> <p>This warning occurs because Python's multiprocessing module defaults to using the \"fork\" start method on POSIX systems. In multi-threaded environments (like test suites running with pytest), fork() can cause deadlocks since only the current thread survives in the child process while other threads' locks remain held.</p> <p>Solution: The codebase is configured to use the \"spawn\" start method instead:</p> <pre><code>multiprocessing.set_start_method('spawn', force=True)\n</code></pre> <p>This creates entirely new Python interpreter processes instead of forking, avoiding the multi-threading issues. This configuration is automatically applied in:</p> <ul> <li>Core tests via <code>rustic-ai/core/tests/conftest.py</code></li> <li>Integration tests via individual test fixtures</li> <li>Production code examples in documentation</li> </ul> <p>Performance Note: The \"spawn\" method is slightly slower than \"fork\" since it needs to create new Python interpreters, but it's much safer and more predictable in multi-threaded environments.</p>"},{"location":"core/multiprocess_execution.html#pytest-hanging-issue","title":"Pytest Hanging Issue","text":"<p>Problem: Tests using multiprocessing were causing pytest to hang and not exit after test completion.</p> <p>Root Cause: The <code>multiprocessing.Manager()</code> creates background processes that weren't being properly cleaned up, preventing pytest from exiting.</p> <p>Solution: Enhanced cleanup mechanisms have been implemented:</p> <ol> <li> <p>Manager Shutdown: The <code>MultiProcessAgentTracker.clear()</code> method now explicitly shuts down the multiprocessing manager:    <pre><code>if hasattr(self, 'manager') and self.manager:\n    self.manager.shutdown()\n</code></pre></p> </li> <li> <p>Process Force Cleanup: The <code>MultiProcessExecutionEngine.shutdown()</code> method now includes comprehensive process cleanup:</p> <ul> <li>Terminates and kills remaining processes</li> <li>Cleans up process tracking structures</li> <li>Forces cleanup of any remaining multiprocessing children</li> </ul> </li> <li> <p>Test Fixtures Enhanced: Test fixtures now include additional cleanup steps:</p> <ul> <li>Wait for processes to fully terminate</li> <li>Double-check multiprocessing cleanup</li> <li>Session-level cleanup to ensure no processes remain</li> </ul> </li> <li> <p>Session-Level Cleanup: A session-scoped pytest fixture ensures all multiprocessing resources are cleaned up when the test session ends.</p> </li> </ol> <p>These changes ensure that: - \u2705 No fork() warnings - Tests use \"spawn\" method - \u2705 No pytest hanging - All processes properly cleaned up - \u2705 Fast test execution - Tests complete quickly without delays - \u2705 Reliable cleanup - Comprehensive process termination</p>"},{"location":"core/multiprocess_execution.html#configuration","title":"Configuration","text":""},{"location":"core/multiprocess_execution.html#common-issues","title":"Common Issues","text":"<ol> <li>Process Won't Start: Check process limits and available memory</li> <li>Serialization Errors: Ensure all data passed to processes is serializable</li> <li>Hanging Processes: Use timeout in shutdown and implement proper cleanup</li> <li>Memory Leaks: Monitor process memory usage and implement cleanup</li> </ol>"},{"location":"core/multiprocess_execution.html#debugging","title":"Debugging","text":"<pre><code># Check process status\nagents = engine.get_agents_in_guild(guild_id)\nfor agent_id, spec in agents.items():\n    process_info = engine.get_process_info(guild_id, agent_id)\n    print(f\"Agent {agent_id}: PID={process_info.get('pid')}, Alive={process_info.get('is_alive')}\")\n\n# Get detailed statistics\nstats = engine.get_engine_stats()\nprint(f\"Engine stats: {stats}\")\n\n# Manual cleanup\nengine.cleanup_dead_processes()\n</code></pre>"},{"location":"core/multiprocess_execution.html#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import psutil\n\ndef monitor_engine_performance(engine, guild_id):\n    \"\"\"Monitor engine performance metrics.\"\"\"\n    stats = engine.get_engine_stats()\n    agents = engine.get_agents_in_guild(guild_id)\n\n    total_memory = 0\n    total_cpu = 0\n\n    for agent_id in agents:\n        process_info = engine.get_process_info(guild_id, agent_id)\n        pid = process_info.get('pid')\n\n        if pid:\n            try:\n                process = psutil.Process(pid)\n                memory_mb = process.memory_info().rss / 1024 / 1024\n                cpu_percent = process.cpu_percent()\n\n                total_memory += memory_mb\n                total_cpu += cpu_percent\n\n                print(f\"Agent {agent_id}: Memory={memory_mb:.1f}MB, CPU={cpu_percent:.1f}%\")\n            except psutil.NoSuchProcess:\n                print(f\"Agent {agent_id}: Process no longer exists\")\n\n    print(f\"Total: Memory={total_memory:.1f}MB, CPU={total_cpu:.1f}%\")\n    print(f\"Agents: {len(agents)}/{stats['max_processes']}\")\n</code></pre>"},{"location":"core/multiprocess_execution.html#integration-with-embedded-messaging-backend","title":"Integration with Embedded Messaging Backend","text":"<p>The multiprocess execution engine works particularly well with the Embedded Messaging Backend:</p> <pre><code>from rustic_ai.core.messaging.backend.embedded_backend import (\n    EmbeddedMessagingBackend,\n    EmbeddedServer\n)\nimport asyncio\nimport threading\n\n# Start socket server for cross-process messaging\ndef start_server(port=31134):\n    def run_server():\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        server = EmbeddedServer(port=port)\n        loop.run_until_complete(server.start())\n        try:\n            loop.run_forever()\n        finally:\n            loop.run_until_complete(server.stop())\n            loop.close()\n\n    thread = threading.Thread(target=run_server, daemon=True)\n    thread.start()\n    return port\n\nport = start_server(31134)\n\n# Create multiprocess engine with embedded messaging\nmessaging_config = MessagingConfig(\n    backend_module=\"rustic_ai.core.messaging.backend.embedded_backend\",\n    backend_class=\"EmbeddedMessagingBackend\",\n    backend_config={\"port\": port, \"auto_start_server\": False}\n)\n\nengine = MultiProcessExecutionEngine(guild_id=\"my-guild\")\nguild = Guild(guild_id=\"my-guild\", messaging_config=messaging_config)\n\n# Agents can now communicate across processes\n# without external dependencies\n</code></pre>"},{"location":"core/multiprocess_execution.html#conclusion","title":"Conclusion","text":"<p>The Multiprocess Execution Engine provides a powerful solution for CPU-intensive and fault-tolerant agent systems. By escaping Python's GIL and providing process isolation, it enables true parallel execution while maintaining the full feature set of the Rustic AI framework. Combined with the embedded messaging backend, it offers a robust platform for building high-performance, distributed agent systems. </p>"},{"location":"core/state_management.html","title":"State Management","text":"<p>State is the backbone that allows agents and guilds to remember the past, reason about the present, and influence the future. Rustic AI offers a unified State Management layer that is both simple for trivial use-cases and powerful enough for distributed deployments.</p>"},{"location":"core/state_management.html#why-a-dedicated-state-layer","title":"Why a Dedicated State Layer?","text":"<ol> <li>Consistency \u2013 Shared state establishes a single source of truth across agents.</li> <li>Resilience \u2013 Persisting critical data protects conversations and workflows from process crashes.</li> <li>Observability \u2013 A well-structured state store enables auditing, monitoring and replay-debugging.</li> </ol>"},{"location":"core/state_management.html#scopes-and-lifetimes","title":"Scopes and Lifetimes","text":"Scope Owner Lifetime Typical Use-Case Agent State Individual agent Until the agent is removed Conversation context, local counters Guild State Guild While the guild is running Shared knowledge base, collaborative draft Global State Application Unlimited Cross-guild configuration, global indexes <p>All scopes share the same API surface but may be backed by different persistence drivers.</p>"},{"location":"core/state_management.html#the-statemanager-interface","title":"The <code>StateManager</code> Interface","text":"<p><pre><code>class BaseStateManager(Protocol):\n    def get(self, scope: Scope, key: str) -&gt; Any: ...\n    def set(self, scope: Scope, key: str, value: Any) -&gt; None: ...\n    def delete(self, scope: Scope, key: str) -&gt; None: ...\n    def list(self, scope: Scope, prefix: str | None = None) -&gt; dict[str, Any]: ...\n</code></pre> Key characteristics: - Transactional \u2013 Changes can be committed or rolled back atomically. - Pluggable \u2013 Swap implementations without touching agent code. - Thread-Safe \u2013 Guarantees correctness under concurrent access.</p>"},{"location":"core/state_management.html#built-in-back-ends","title":"Built-In Back-Ends","text":"Driver Description When to Use <code>InMemoryStateManager</code> Fast, non-persistent <code>dict</code>-based store Unit tests, ephemeral prototypes <code>SQLiteStateManager</code> Lightweight, file-based SQL store Desktop apps, single-node deployments <code>RedisStateManager</code> Networked, in-memory store with persistence Multi-process / Docker compose <code>PostgresStateManager</code> Full ACID guarantees &amp; rich querying Production workloads, analytics <p>You can add your own driver by implementing <code>BaseStateManager</code> and registering it with the DI container.</p>"},{"location":"core/state_management.html#working-with-agent-state","title":"Working with Agent State","text":"<pre><code>from rustic_ai.core.state import Scope\n\n@processor(MyRequest)\ndef handle(self, ctx):\n    visits = ctx.state.get(Scope.AGENT, \"visits\") or 0\n    ctx.state.set(Scope.AGENT, \"visits\", visits + 1)\n</code></pre>"},{"location":"core/state_management.html#concurrency-consistency-strategies","title":"Concurrency &amp; Consistency Strategies","text":"<p>Depending on your chosen back-end, you may need to handle concurrent modifications.</p> <ul> <li>Optimistic Locking \u2013 Each record carries a version; conflicting writes raise an error.</li> <li>Pessimistic Locking \u2013 A write lock is held for the duration of the transaction.</li> <li>Event Sourcing \u2013 Model state transitions as an append-only event log (advanced).</li> </ul>"},{"location":"core/state_management.html#snapshotting-replay","title":"Snapshotting &amp; Replay","text":"<p>The state layer can periodically snapshot agent state and (optionally) persist message history. This allows you to: 1. Pause and resume long-running guilds. 2. Replay a conversation for debugging. 3. Fork a guild into an alternate timeline for what-if analysis.</p>"},{"location":"core/state_management.html#best-practices","title":"Best Practices","text":"<ol> <li>Store only what you need \u2013 large payloads belong in object storage.</li> <li>Use typed Pydantic models for complex values to ensure schema evolution.</li> <li>Version state explicitly when doing breaking changes.</li> <li>Tightly scope writes to prevent accidental cross-agent leakage.</li> </ol>"},{"location":"core/state_management.html#example-pluggable-driver-via-dependency-injection","title":"Example: Pluggable Driver via Dependency Injection","text":"<pre><code>from rustic_ai.core.state import RedisStateManager\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nstate_dep = {\n    \"state_manager\": DependencySpec(\n        class_name=\"rustic_ai.core.state.RedisStateManager\",\n        properties={\"redis_url\": \"redis://localhost:6379/0\"},\n    )\n}\n\nguild_spec = GuildSpec(..., dependency_map=state_dep)\n</code></pre>"},{"location":"core/state_management.html#further-reading","title":"Further Reading","text":"<ul> <li>Execution \u2013 how state persists across agent restarts</li> <li>Agents \u2013 accessing state inside message handlers</li> <li>Architecture \u2013 where state fits in the big picture </li> </ul>"},{"location":"dependencies/index.html","title":"Dependency Resolvers","text":"<p>Dependency resolvers are a key component of Rustic AI's dependency injection system. They provide agents with access to external services, resources, and capabilities in a modular, configurable way.</p>"},{"location":"dependencies/index.html#overview","title":"Overview","text":"<p>Rustic AI's dependency resolver system allows agents to:</p> <ul> <li>Access external services (databases, APIs, LLMs, etc.)</li> <li>Share resources efficiently</li> <li>Swap implementations without changing agent code</li> <li>Configure services in a consistent way</li> <li>Test with mock dependencies</li> </ul>"},{"location":"dependencies/index.html#available-resolvers-by-package","title":"Available Resolvers by Package","text":"<p>Rustic AI provides dependency resolvers across multiple packages:</p>"},{"location":"dependencies/index.html#core","title":"Core","text":"<p>Core dependencies for essential functionality: - FileSystemResolver - File system access - InMemoryKVStoreResolver - In-memory key-value store - PythonExecExecutorResolver - Python code execution - InProcessCodeInterpreterResolver - In-process code interpretation - EnvSecretProviderResolver - Environment-based secret management</p>"},{"location":"dependencies/index.html#redis","title":"Redis","text":"<p>Redis-based dependencies: - RedisKVStoreResolver - Persistent key-value store backed by Redis</p>"},{"location":"dependencies/index.html#litellm","title":"LiteLLM","text":"<p>Large language model integration: - LiteLLMResolver - Unified LLM access across multiple providers</p>"},{"location":"dependencies/index.html#chroma","title":"Chroma","text":"<p>Vector database integration: - ChromaResolver - Vector database for embeddings</p>"},{"location":"dependencies/index.html#langchain","title":"LangChain","text":"<p>LangChain framework integration: - OpenAIEmbeddingsResolver - OpenAI embeddings - CharacterSplitterResolver - Character-based text splitting - RecursiveSplitterResolver - Recursive text splitting</p>"},{"location":"dependencies/index.html#using-dependency-resolvers","title":"Using Dependency Resolvers","text":"<p>Dependency resolvers are configured in guild or agent specifications and then injected into agent handlers:</p> <pre><code># In guild configuration\nfrom rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"my_guild\", \"My Guild\", \"Guild with dependencies\")\n    .add_dependency_resolver(\n        \"filesystem\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.filesystem.FileSystemResolver\", \n            properties={\"path_base\": \"/tmp/rusticai/files\", \"protocol\": \"file\", \"storage_options\": {}}\n        )\n    )\n)\n\n# In agent code\nfrom rustic_ai.core.guild import Agent, agent\n\nclass FileAgent(Agent):\n    @agent.processor(clz=FileRequest, depends_on=[\"filesystem\"])\n    def handle_file_request(self, ctx: agent.ProcessContext, filesystem):\n        # Use the filesystem dependency\n        with filesystem.open(\"data.txt\", \"w\") as f:\n            f.write(\"Hello, World!\")\n</code></pre>"},{"location":"dependencies/index.html#dependency-resolution-process","title":"Dependency Resolution Process","text":"<p>When an agent handler with dependencies is invoked:</p> <ol> <li>The system identifies dependencies listed in <code>depends_on</code></li> <li>For each dependency:<ul> <li>First checks agent-level <code>dependency_map</code></li> <li>Then checks guild-level <code>dependency_map</code></li> </ul> </li> <li>For each dependency specification:<ul> <li>The resolver class is instantiated with the provided properties</li> <li>The resolver's <code>resolve()</code> method is called to create the dependency</li> <li>The result is injected as an argument to the handler</li> </ul> </li> </ol>"},{"location":"dependencies/index.html#creating-custom-resolvers","title":"Creating Custom Resolvers","text":"<p>To create a custom resolver:</p> <ol> <li>Extend the <code>DependencyResolver</code> base class</li> <li>Implement the <code>resolve(guild_id, agent_id)</code> method</li> <li>Configure the resolver in your guild or agent specification</li> </ol> <p>For detailed information on the dependency system, see Dependencies Core Documentation and Dependency Injection Guide. </p>"},{"location":"dependencies/chroma/index.html","title":"Chroma Dependencies","text":"<p>The Chroma package provides dependency resolvers that integrate the Chroma vector database into Rustic AI agents. Chroma is a lightweight, open-source vector database for storing and searching embeddings.</p>"},{"location":"dependencies/chroma/index.html#available-resolvers","title":"Available Resolvers","text":"<ul> <li>ChromaResolver - Vector database for storing, managing, and searching embeddings</li> </ul>"},{"location":"dependencies/chroma/index.html#usage","title":"Usage","text":"<p>Chroma dependencies enable agents to perform vector-based operations like semantic search, similarity matching, and retrieval-augmented generation (RAG). These capabilities are essential for building agents that can work with unstructured data and provide contextually relevant responses.</p> <p>For details on how to configure and use each resolver, please refer to the specific documentation links above. </p>"},{"location":"dependencies/chroma/chroma_resolver.html","title":"ChromaResolver","text":"<p>The <code>ChromaResolver</code> provides a vector database for storing, retrieving, and searching vector embeddings. It leverages the Chroma vector database to enable semantic search and retrieval-augmented generation (RAG) capabilities for agents.</p>"},{"location":"dependencies/chroma/chroma_resolver.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[VectorStore]</code></li> <li>Provided Dependency: <code>ChromaVectorStore</code></li> <li>Package: <code>rustic_ai.chroma.agent_ext.vectorstore</code></li> </ul>"},{"location":"dependencies/chroma/chroma_resolver.html#features","title":"Features","text":"<ul> <li>Vector Storage: Store document embeddings in a persistent database</li> <li>Semantic Search: Find semantically similar documents based on vector similarity</li> <li>Metadata Filtering: Filter search results based on metadata</li> <li>Document Management: Add, update, delete, and retrieve documents</li> <li>Multiple Distance Metrics: Cosine similarity, dot product, and Euclidean distance</li> </ul>"},{"location":"dependencies/chroma/chroma_resolver.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>collection_name</code> <code>str</code> Name of the Chroma collection Required <code>embedding_function</code> <code>str</code> Fully qualified class name of the embedding function Required <code>persist_directory</code> <code>str</code> Directory for persisting the database <code>None</code> (in-memory) <code>client_settings</code> <code>Dict[str, Any]</code> Settings for the Chroma client <code>{}</code> <code>collection_metadata</code> <code>Dict[str, Any]</code> Metadata for the collection <code>{}</code> <code>distance_function</code> <code>str</code> Distance function for similarity (<code>\"cosine\"</code>, <code>\"l2\"</code>, <code>\"ip\"</code>) <code>\"cosine\"</code>"},{"location":"dependencies/chroma/chroma_resolver.html#usage","title":"Usage","text":""},{"location":"dependencies/chroma/chroma_resolver.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"vector_guild\", \"Vector Search Guild\", \"Guild with vector search capabilities\")\n    .add_dependency_resolver(\n        \"vectorstore\",\n        DependencySpec(\n            class_name=\"rustic_ai.chroma.agent_ext.vectorstore.ChromaResolver\",\n            properties={\n                \"collection_name\": \"my_documents\",\n                \"embedding_function\": \"rustic_ai.langchain.agent_ext.embeddings.openai.OpenAIEmbeddings\",\n                \"persist_directory\": \"/path/to/chroma_db\",\n                \"distance_function\": \"cosine\"\n            }\n        )\n    )\n    # Note: You also need to configure the embedding function dependency\n    .add_dependency_resolver(\n        \"embeddings\",\n        DependencySpec(\n            class_name=\"rustic_ai.langchain.agent_ext.embeddings.openai.OpenAIEmbeddingsResolver\",\n            properties={\n                \"model\": \"text-embedding-ada-002\",\n                \"dimensions\": 1536\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/chroma/chroma_resolver.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.chroma.agent_ext.vectorstore import ChromaVectorStore\nfrom rustic_ai.core.agents.commons.media import Document\n\nclass VectorSearchAgent(Agent):\n    @agent.processor(clz=DocumentUpsertRequest, depends_on=[\"vectorstore\"])\n    def add_documents(self, ctx: agent.ProcessContext, vectorstore: ChromaVectorStore):\n        # Create documents\n        documents = [\n            Document(\n                id=\"doc1\",\n                text=\"Artificial intelligence is transforming industries worldwide.\",\n                metadata={\"source\": \"article\", \"category\": \"technology\"}\n            ),\n            Document(\n                id=\"doc2\",\n                text=\"Machine learning models require large amounts of training data.\",\n                metadata={\"source\": \"textbook\", \"category\": \"technology\"}\n            )\n        ]\n\n        # Add documents to vector store\n        response = vectorstore.upsert(documents)\n\n        ctx.send_dict({\n            \"success_count\": len(response.succeeded),\n            \"failed_count\": len(response.failed)\n        })\n\n    @agent.processor(clz=SearchRequest, depends_on=[\"vectorstore\"])\n    def search_documents(self, ctx: agent.ProcessContext, vectorstore: ChromaVectorStore):\n        query = ctx.payload.query\n\n        # Perform semantic search\n        results = vectorstore.similarity_search(\n            query=query,\n            k=5,  # Number of results to return\n            metadata_filter={\"category\": \"technology\"}  # Optional metadata filter\n        )\n\n        # Send back search results\n        ctx.send_dict({\n            \"query\": query,\n            \"results\": [\n                {\n                    \"text\": doc.text,\n                    \"metadata\": doc.metadata,\n                    \"score\": score\n                }\n                for doc, score in zip(results.documents, results.scores)\n            ]\n        })\n</code></pre>"},{"location":"dependencies/chroma/chroma_resolver.html#document-structure","title":"Document Structure","text":"<p>Documents in the vector store have these components:</p> <ul> <li>ID: Unique identifier for the document</li> <li>Text: The document content</li> <li>Metadata: Key-value pairs of additional information about the document</li> <li>Embedding: Vector representation of the document (generated automatically)</li> </ul>"},{"location":"dependencies/chroma/chroma_resolver.html#api-reference","title":"API Reference","text":"<p>The <code>ChromaVectorStore</code> class provides these primary methods:</p> Method Description <code>upsert(documents: List[Document]) -&gt; UpsertResponse</code> Add or update documents <code>similarity_search(query: str, k: int = 4, metadata_filter: Optional[Dict[str, str]] = None) -&gt; VectorSearchResults</code> Search for similar documents <code>delete(ids: Optional[List[str]] = None) -&gt; Optional[bool]</code> Delete documents by IDs (or all if None) <code>get_by_ids(ids: List[str]) -&gt; List[Document]</code> Retrieve documents by IDs"},{"location":"dependencies/chroma/chroma_resolver.html#example-retrieval-augmented-generation-rag","title":"Example: Retrieval-Augmented Generation (RAG)","text":"<pre><code>@agent.processor(clz=RAGRequest, depends_on=[\"vectorstore\", \"llm\"])\ndef answer_with_rag(self, ctx: agent.ProcessContext, vectorstore: ChromaVectorStore, llm: LLM):\n    query = ctx.payload.query\n\n    # Step 1: Retrieve relevant documents\n    search_results = vectorstore.similarity_search(query, k=3)\n\n    # Step 2: Build context from retrieved documents\n    context = \"\\n\\n\".join([doc.text for doc in search_results.documents])\n\n    # Step 3: Generate answer using LLM with context\n    request = ChatCompletionRequest(\n        messages=[\n            ChatMessage(\n                role=ChatMessageRole.SYSTEM, \n                content=f\"Answer the question based on the following context:\\n\\n{context}\"\n            ),\n            ChatMessage(role=ChatMessageRole.USER, content=query)\n        ]\n    )\n\n    response = llm.completion(request)\n\n    # Step 4: Return the answer with sources\n    ctx.send_dict({\n        \"answer\": response.choices[0].message.content,\n        \"sources\": [\n            {\"text\": doc.text, \"metadata\": doc.metadata}\n            for doc in search_results.documents\n        ]\n    })\n</code></pre>"},{"location":"dependencies/chroma/chroma_resolver.html#persistence-modes","title":"Persistence Modes","text":"<p>ChromaResolver supports two modes of operation:</p> <ol> <li>In-memory: When <code>persist_directory</code> is <code>None</code>, data is kept only in memory</li> <li>Persistent: When <code>persist_directory</code> is specified, data is saved to disk</li> </ol> <p>For production use, always specify a <code>persist_directory</code> to ensure data is not lost on restart.</p>"},{"location":"dependencies/chroma/chroma_resolver.html#embedding-functions","title":"Embedding Functions","text":"<p>The <code>embedding_function</code> parameter is crucial - it determines how text documents are converted to vector embeddings. You must provide the fully qualified class name of a compatible embedding function.</p> <p>Common choices include: - <code>rustic_ai.langchain.agent_ext.embeddings.openai.OpenAIEmbeddings</code> - <code>rustic_ai.langchain.agent_ext.embeddings.huggingface.HuggingFaceEmbeddings</code> - Other custom embedding functions that implement the required interface</p>"},{"location":"dependencies/chroma/chroma_resolver.html#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Document Size: Keep documents reasonably sized (chunking large documents is recommended)</li> <li>Collection Size: Very large collections may require more resources</li> <li>Query Frequency: High-volume search may require scaling the Chroma backend</li> <li>Persistence: Disk-based persistence has lower performance than in-memory</li> </ul>"},{"location":"dependencies/chroma/chroma_resolver.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>OpenAIEmbeddingsResolver - For generating embeddings with OpenAI models </li> </ul>"},{"location":"dependencies/core/index.html","title":"Core Dependencies","text":"<p>The Core package provides several essential dependency resolvers that form the foundation of Rustic AI's dependency injection system.</p>"},{"location":"dependencies/core/index.html#available-resolvers","title":"Available Resolvers","text":"<ul> <li>FileSystemResolver - Provides access to file system operations with configurable base paths and protocols</li> <li>InMemoryKVStoreResolver - Simple key-value store backed by in-memory storage</li> <li>PythonExecExecutorResolver - Safe execution of Python code with configurable import restrictions</li> <li>InProcessCodeInterpreterResolver - In-process Python code interpretation for agent code execution</li> <li>EnvSecretProviderResolver - Environment variable-based secret management</li> </ul>"},{"location":"dependencies/core/index.html#usage","title":"Usage","text":"<p>Core dependencies can be used across any agent in the Rustic AI ecosystem. They provide fundamental capabilities like storage, code execution, and security that are useful in many agent scenarios.</p> <p>For details on how to configure and use each resolver, please refer to the specific documentation links above. </p>"},{"location":"dependencies/core/env_secret_provider.html","title":"EnvSecretProviderDependencyResolver","text":"<p>The <code>EnvSecretProviderDependencyResolver</code> provides a secure way for agents to access sensitive configuration values like API keys, credentials, and tokens from environment variables, without exposing the actual secrets in code or configuration files.</p>"},{"location":"dependencies/core/env_secret_provider.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[SecretProvider]</code></li> <li>Provided Dependency: <code>EnvSecretProvider</code></li> <li>Package: <code>rustic_ai.core.guild.agent_ext.depends.secrets.env_secret_provider</code></li> </ul>"},{"location":"dependencies/core/env_secret_provider.html#features","title":"Features","text":"<ul> <li>Environment-Based: Retrieves secrets from environment variables</li> <li>Prefix Support: Optional prefix for environment variable names</li> <li>Default Values: Fallback values for missing environment variables</li> <li>Caching: Secrets are cached for efficient retrieval</li> <li>Guild-Specific Secrets: Can scope secrets to specific guilds</li> </ul>"},{"location":"dependencies/core/env_secret_provider.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>prefix</code> <code>str</code> Prefix for environment variable names <code>\"\"</code> (empty string) <code>default_values</code> <code>Dict[str, str]</code> Default values for secrets <code>{}</code> (empty dict)"},{"location":"dependencies/core/env_secret_provider.html#usage","title":"Usage","text":""},{"location":"dependencies/core/env_secret_provider.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"my_guild\", \"Secret Guild\", \"Guild with access to environment secrets\")\n    .add_dependency_resolver(\n        \"secrets\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.secrets.env_secret_provider.EnvSecretProviderDependencyResolver\",\n            properties={\n                \"prefix\": \"RUSTICAI_\",\n                \"default_values\": {\n                    \"api_url\": \"https://api.example.com\"\n                }\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/core/env_secret_provider.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent_ext.depends.secrets.env_secret_provider import EnvSecretProvider\n\nclass ApiAgent(Agent):\n    @agent.processor(clz=ApiRequest, depends_on=[\"secrets\"])\n    def call_api(self, ctx: agent.ProcessContext, secrets: EnvSecretProvider):\n        # Get API key from environment variable RUSTICAI_API_KEY\n        api_key = secrets.get_secret(\"api_key\")\n\n        # Get API URL from environment variable RUSTICAI_API_URL or use default\n        api_url = secrets.get_secret(\"api_url\")\n\n        # Use the secrets to make an API call\n        response = self._make_api_call(api_url, api_key, ctx.payload.request_data)\n\n        ctx.send_dict({\"response\": response})\n\n    def _make_api_call(self, url, key, data):\n        # Implementation of API call\n        return {\"status\": \"success\", \"data\": \"API response\"}\n</code></pre>"},{"location":"dependencies/core/env_secret_provider.html#secret-retrieval","title":"Secret Retrieval","text":"<p>The <code>EnvSecretProvider</code> class provides these methods:</p> Method Description <code>get_secret(name: str) -&gt; str</code> Get a secret by name <code>has_secret(name: str) -&gt; bool</code> Check if a secret exists <code>list_available_secrets() -&gt; List[str]</code> List all available secret names (without values)"},{"location":"dependencies/core/env_secret_provider.html#environment-variable-naming","title":"Environment Variable Naming","text":"<p>Given a <code>prefix</code> of <code>\"RUSTICAI_\"</code> and a secret name <code>\"api_key\"</code>, the resolver will look for an environment variable named <code>RUSTICAI_API_KEY</code> (the secret name is automatically upper-cased).</p>"},{"location":"dependencies/core/env_secret_provider.html#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Don't hardcode secrets: Never include actual secrets in your code or configuration files</li> <li>Use environment variables: Set secrets as environment variables or use a secure secret management service</li> <li>Limit access: Only provide access to secrets that agents actually need</li> <li>Rotate secrets: Regularly update API keys and other credentials</li> <li>Review logs: Ensure secrets aren't accidentally logged</li> </ol>"},{"location":"dependencies/core/env_secret_provider.html#examples","title":"Examples","text":""},{"location":"dependencies/core/env_secret_provider.html#setting-environment-variables","title":"Setting Environment Variables","text":"<pre><code># Set environment variables before starting your application\nexport RUSTICAI_API_KEY=your_api_key_here\nexport RUSTICAI_DATABASE_URL=postgresql://user:password@localhost/db\n</code></pre>"},{"location":"dependencies/core/env_secret_provider.html#using-guild-specific-secrets","title":"Using Guild-Specific Secrets","text":"<pre><code>@agent.processor(clz=ConfigRequest, depends_on=[\"secrets\"])\ndef handle_config(self, ctx: agent.ProcessContext, secrets: EnvSecretProvider):\n    # Get guild-specific environment variables if they exist\n    # For a guild with ID \"payment_guild\", will look for RUSTICAI_PAYMENT_GUILD_API_KEY\n    guild_api_key = secrets.get_guild_secret(self.guild_id, \"api_key\")\n\n    # Or use a more explicit approach\n    payment_key = secrets.get_secret(f\"{self.guild_id}_api_key\")\n\n    ctx.send_dict({\"configured\": True})\n</code></pre>"},{"location":"dependencies/core/env_secret_provider.html#fallback-to-default-values","title":"Fallback to Default Values","text":"<pre><code>@agent.processor(clz=ServerRequest, depends_on=[\"secrets\"])\ndef handle_server_request(self, ctx: agent.ProcessContext, secrets: EnvSecretProvider):\n    # If RUSTICAI_SERVER_URL isn't set, will use the default value\n    server_url = secrets.get_secret(\"server_url\")\n\n    ctx.send_dict({\"server\": server_url})\n</code></pre>"},{"location":"dependencies/core/env_secret_provider.html#use-cases","title":"Use Cases","text":"<ul> <li>API Integration: Securely use API keys for external services</li> <li>Database Access: Store database connection credentials</li> <li>Authentication: Manage authentication tokens for services</li> <li>Configuration: Centralize sensitive configuration</li> <li>Multi-Environment Setup: Different secrets for development, testing, and production</li> </ul>"},{"location":"dependencies/core/env_secret_provider.html#alternative-secret-managers","title":"Alternative Secret Managers","text":"<p>For more advanced secret management needs, consider:</p> <ul> <li>Using a cloud-based secret manager (AWS Secrets Manager, Google Secret Manager, Azure Key Vault)</li> <li>Implementing a custom <code>DependencyResolver</code> that integrates with your preferred secret management solution</li> <li>Using Hashicorp Vault or similar tools for enterprise-grade secret management </li> </ul>"},{"location":"dependencies/core/filesystem.html","title":"FileSystemResolver","text":"<p>The <code>FileSystemResolver</code> provides agents with secure, configurable access to the file system. It creates an isolated filesystem view for each agent, ensuring separation of concerns and preventing agents from accessing files outside their designated areas.</p>"},{"location":"dependencies/core/filesystem.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[FileSystem]</code></li> <li>Provided Dependency: <code>fsspec.implementations.dirfs.DirFileSystem</code></li> <li>Package: <code>rustic_ai.core.guild.agent_ext.depends.filesystem.filesystem</code></li> </ul>"},{"location":"dependencies/core/filesystem.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>path_base</code> <code>str</code> Base path for files; agent directories will be created under this path Required <code>protocol</code> <code>str</code> File system protocol to use (e.g., 'file', 's3', 'gcs') Required <code>storage_options</code> <code>dict</code> Protocol-specific options for the underlying filesystem Required"},{"location":"dependencies/core/filesystem.html#usage","title":"Usage","text":""},{"location":"dependencies/core/filesystem.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"my_guild\", \"File System Guild\", \"Guild with file system access\")\n    .add_dependency_resolver(\n        \"filesystem\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.filesystem.FileSystemResolver\",\n            properties={\n                \"path_base\": \"/tmp/rusticai/files\",\n                \"protocol\": \"file\",\n                \"storage_options\": {}\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/core/filesystem.html#agent-usage","title":"Agent Usage","text":"<pre><code>from fsspec.implementations.dirfs import DirFileSystem\nfrom rustic_ai.core.guild import Agent, agent\n\nclass FileAgent(Agent):\n    @agent.processor(clz=FileRequest, depends_on=[\"filesystem\"])\n    def handle_file_request(self, ctx: agent.ProcessContext, filesystem: DirFileSystem):\n        # Use filesystem to read/write files\n        with filesystem.open(\"data.txt\", \"w\") as f:\n            f.write(\"Hello, World!\")\n\n        with filesystem.open(\"data.txt\", \"r\") as f:\n            content = f.read()\n\n        ctx.send_dict({\"content\": content})\n</code></pre>"},{"location":"dependencies/core/filesystem.html#path-isolation","title":"Path Isolation","text":"<p>The resolver creates agent-specific paths using the pattern:</p> <pre><code>{path_base}/{guild_id}/{agent_id}/\n</code></pre> <p>This ensures each agent has its own isolated file space, preventing one agent from accessing another's files.</p>"},{"location":"dependencies/core/filesystem.html#supported-backends","title":"Supported Backends","text":"<p><code>FileSystemResolver</code> leverages fsspec, which supports multiple storage backends:</p> <ul> <li>Local file system (<code>file://</code>)</li> <li>Amazon S3 (<code>s3://</code>)</li> <li>Google Cloud Storage (<code>gcs://</code>)</li> <li>Azure Blob Storage (<code>abfs://</code>)</li> <li>HDFS (<code>hdfs://</code>)</li> <li>HTTP/HTTPS (<code>http://</code>, <code>https://</code>)</li> <li>And many more</li> </ul> <p>To use a particular backend, specify the appropriate protocol and include any authentication details in <code>storage_options</code>.</p>"},{"location":"dependencies/core/filesystem.html#example-s3-configuration","title":"Example: S3 Configuration","text":"<pre><code>DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.filesystem.FileSystemResolver\",\n    properties={\n        \"path_base\": \"my-bucket/agent-files\",\n        \"protocol\": \"s3\",\n        \"storage_options\": {\n            \"key\": \"AWS_ACCESS_KEY\",\n            \"secret\": \"AWS_SECRET_KEY\",\n            \"client_kwargs\": {\"region_name\": \"us-west-2\"}\n        }\n    }\n)\n</code></pre>"},{"location":"dependencies/core/filesystem.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Ensure the <code>path_base</code> is in a safe location that doesn't contain sensitive system files</li> <li>When using cloud storage, follow the principle of least privilege for access credentials</li> <li>Consider implementing additional checks for sensitive operations in your agent code </li> </ul>"},{"location":"dependencies/core/in_memory_kvstore.html","title":"InMemoryKVStoreResolver","text":"<p>The <code>InMemoryKVStoreResolver</code> provides a lightweight, in-memory key-value store for agents. It's ideal for development, testing, or situations where persistence isn't required.</p>"},{"location":"dependencies/core/in_memory_kvstore.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[InMemoryKVStore]</code></li> <li>Provided Dependency: <code>InMemoryKVStore</code></li> <li>Package: <code>rustic_ai.core.guild.agent_ext.depends.kvstore.in_memory_kvstore</code></li> </ul>"},{"location":"dependencies/core/in_memory_kvstore.html#features","title":"Features","text":"<ul> <li>Simple key-value storage with string keys and arbitrary JSON-serializable values</li> <li>Fast performance (RAM-based)</li> <li>Optional namespacing for organizing keys</li> <li>Supports basic CRUD operations</li> </ul>"},{"location":"dependencies/core/in_memory_kvstore.html#limitations","title":"Limitations","text":"<ul> <li>Data is not persisted between application restarts</li> <li>Not suitable for sharing data across different processes</li> <li>Limited to memory capacity of the host machine</li> </ul>"},{"location":"dependencies/core/in_memory_kvstore.html#configuration","title":"Configuration","text":"<p>The resolver accepts no configuration parameters.</p> <pre><code>from rustic_ai.core.guild.dsl import DependencySpec\n\nspec = DependencySpec(\n    class_name=\"rustic_ai.core.guild.agent_ext.depends.kvstore.in_memory_kvstore.InMemoryKVStoreResolver\",\n    properties={}\n)\n</code></pre>"},{"location":"dependencies/core/in_memory_kvstore.html#usage","title":"Usage","text":""},{"location":"dependencies/core/in_memory_kvstore.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"my_guild\", \"KV Guild\", \"Guild with in-memory key-value store\")\n    .add_dependency_resolver(\n        \"kvstore\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.kvstore.in_memory_kvstore.InMemoryKVStoreResolver\",\n            properties={}\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/core/in_memory_kvstore.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent_ext.depends.kvstore.in_memory_kvstore import InMemoryKVStore\n\nclass KVStoreAgent(Agent):\n    @agent.processor(clz=StoreRequest, depends_on=[\"kvstore\"])\n    def handle_store_request(self, ctx: agent.ProcessContext, kvstore: InMemoryKVStore):\n        # Basic operations\n        kvstore.set(\"my_key\", {\"value\": \"Hello, World!\"})\n        value = kvstore.get(\"my_key\")\n\n        # Namespace operations\n        kvstore.set(\"user:123:name\", \"Alice\")\n        kvstore.set(\"user:123:email\", \"alice@example.com\")\n\n        # Get all keys with a prefix\n        user_data = kvstore.get_by_prefix(\"user:123:\")\n\n        # Delete a key\n        kvstore.delete(\"my_key\")\n\n        ctx.send_dict({\"result\": user_data})\n</code></pre>"},{"location":"dependencies/core/in_memory_kvstore.html#api-reference","title":"API Reference","text":"<p>The <code>InMemoryKVStore</code> class provides these primary methods:</p> Method Description <code>get(key: str) -&gt; Any</code> Get a value by its key <code>set(key: str, value: Any) -&gt; None</code> Set a value for a key <code>delete(key: str) -&gt; bool</code> Delete a key; returns <code>True</code> if deleted, <code>False</code> if it didn't exist <code>get_by_prefix(prefix: str) -&gt; Dict[str, Any]</code> Get all key-value pairs where the key starts with the given prefix <code>exists(key: str) -&gt; bool</code> Check if a key exists <code>clear() -&gt; None</code> Delete all stored key-value pairs"},{"location":"dependencies/core/in_memory_kvstore.html#use-cases","title":"Use Cases","text":"<ul> <li>Stateful agents: Store temporary state during agent execution</li> <li>Caching: Cache expensive computations or API responses</li> <li>Testing: Easily test agent logic without complex persistence setup</li> <li>Prototyping: Quick development of agents before implementing permanent storage</li> </ul>"},{"location":"dependencies/core/in_memory_kvstore.html#example-session-management","title":"Example: Session Management","text":"<pre><code>@agent.processor(clz=UserMessage, depends_on=[\"kvstore\"])\ndef handle_message(self, ctx: agent.ProcessContext, kvstore: InMemoryKVStore):\n    user_id = ctx.payload.user_id\n    session_key = f\"session:{user_id}\"\n\n    # Retrieve or initialize session\n    session = kvstore.get(session_key) or {\"message_count\": 0, \"last_seen\": None}\n\n    # Update session\n    session[\"message_count\"] += 1\n    session[\"last_seen\"] = datetime.now().isoformat()\n    kvstore.set(session_key, session)\n\n    # Use session information in response\n    response = f\"Welcome back! This is your {session['message_count']} message.\"\n    ctx.send_dict({\"response\": response})\n</code></pre>"},{"location":"dependencies/core/in_memory_kvstore.html#migration-path","title":"Migration Path","text":"<p>When you need to migrate from <code>InMemoryKVStore</code> to a persistent solution:</p> <ol> <li>Replace the resolver with <code>RedisKVStoreResolver</code> or another persistent implementation</li> <li>Keep your agent code unchanged, as the KVStore interface remains the same</li> <li>Test to ensure proper data serialization and persistence</li> </ol> <p>See also: RedisKVStoreResolver for a persistent alternative. </p>"},{"location":"dependencies/core/in_process_interpreter.html","title":"InProcessCodeInterpreterResolver","text":"<p>The <code>InProcessCodeInterpreterResolver</code> provides a lightweight Python code execution environment that runs code directly in the current process. It offers a simpler alternative to <code>PythonExecExecutorResolver</code> for cases where full isolation isn't required.</p>"},{"location":"dependencies/core/in_process_interpreter.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[CodeRunner]</code></li> <li>Provided Dependency: <code>InProcessCodeInterpreter</code></li> <li>Package: <code>rustic_ai.core.guild.agent_ext.depends.code_execution.stateless.in_process_interpreter</code></li> </ul>"},{"location":"dependencies/core/in_process_interpreter.html#features","title":"Features","text":"<ul> <li>Fast Execution: Runs code directly in the current process without spawning subprocesses</li> <li>Stateless: Each execution is independent (no variables persisting between runs)</li> <li>Lightweight: Minimal overhead compared to other execution methods</li> <li>Simple API: Easy-to-use interface for basic code execution needs</li> </ul>"},{"location":"dependencies/core/in_process_interpreter.html#limitations","title":"Limitations","text":"<ul> <li>Security: Less isolated than other executors - use only with trusted code</li> <li>Stateless: Variables don't persist between executions (by design)</li> <li>Resource Management: Shares resources with the main application</li> </ul>"},{"location":"dependencies/core/in_process_interpreter.html#configuration","title":"Configuration","text":"<p>The resolver has minimal configuration options:</p> Parameter Type Description Default <code>timeout_seconds</code> <code>int</code> Maximum execution time in seconds <code>5</code>"},{"location":"dependencies/core/in_process_interpreter.html#usage","title":"Usage","text":""},{"location":"dependencies/core/in_process_interpreter.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"simple_code_guild\", \"Simple Code Guild\", \"Guild with basic Python execution\")\n    .add_dependency_resolver(\n        \"code_runner\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.code_execution.stateless.in_process_interpreter.InProcessCodeInterpreterResolver\",\n            properties={\n                \"timeout_seconds\": 10\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/core/in_process_interpreter.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent_ext.depends.code_execution.stateless.in_process_interpreter import InProcessCodeInterpreter\n\nclass SimpleCodeAgent(Agent):\n    @agent.processor(clz=SimpleCodeRequest, depends_on=[\"code_runner\"])\n    def run_simple_code(self, ctx: agent.ProcessContext, code_runner: InProcessCodeInterpreter):\n        code = ctx.payload.code\n\n        # Execute the code\n        result = code_runner.run(code)\n\n        if result.success:\n            ctx.send_dict({\n                \"status\": \"success\",\n                \"output\": result.output,\n                \"result_value\": result.result\n            })\n        else:\n            ctx.send_dict({\n                \"status\": \"error\",\n                \"error\": result.error\n            })\n</code></pre>"},{"location":"dependencies/core/in_process_interpreter.html#execution-results","title":"Execution Results","text":"<p>The <code>run()</code> method returns a <code>CodeRunResult</code> object with the following fields:</p> Field Type Description <code>success</code> <code>bool</code> Whether the execution was successful <code>error</code> <code>str</code> Error message if <code>success</code> is <code>False</code> <code>output</code> <code>str</code> Captured standard output <code>result</code> <code>Any</code> The value of the last expression evaluated"},{"location":"dependencies/core/in_process_interpreter.html#example-simple-calculation","title":"Example: Simple Calculation","text":"<pre><code>@agent.processor(clz=CalculationRequest, depends_on=[\"code_runner\"])\ndef perform_calculation(self, ctx: agent.ProcessContext, code_runner: InProcessCodeInterpreter):\n    expression = ctx.payload.expression\n\n    # Safe way to calculate expressions\n    code = f\"\"\"\n    result = {expression}\n    print(f\"Calculating: {expression} = {{result}}\")\n    \"\"\"\n\n    result = code_runner.run(code)\n\n    if result.success:\n        ctx.send_dict({\n            \"expression\": expression,\n            \"result\": result.result,\n            \"calculation_log\": result.output\n        })\n    else:\n        ctx.send_dict({\n            \"expression\": expression,\n            \"error\": result.error\n        })\n</code></pre>"},{"location":"dependencies/core/in_process_interpreter.html#security-considerations","title":"Security Considerations","text":"<p>The <code>InProcessCodeInterpreter</code> runs code directly in the same process as your application, which means:</p> <ol> <li>Use only with trusted code: Never run untrusted user input through this interpreter</li> <li>Resource access: Code has access to the same resources as your application</li> <li>Imports: All available Python modules can be imported</li> <li>System calls: System operations can be performed if the relevant modules are imported</li> </ol> <p>For executing untrusted code, use <code>PythonExecExecutorResolver</code> which provides better isolation.</p>"},{"location":"dependencies/core/in_process_interpreter.html#use-cases","title":"Use Cases","text":"<ul> <li>Simple calculations: Evaluate mathematical expressions</li> <li>Data transformations: Apply simple transformations to data</li> <li>Testing: Quick execution of agent-generated code in development</li> <li>Configuration evaluation: Dynamic configuration logic</li> </ul>"},{"location":"dependencies/core/in_process_interpreter.html#when-to-use","title":"When to Use","text":"<p>Choose <code>InProcessCodeInterpreterResolver</code> when:</p> <ul> <li>You need simple, fast code execution</li> <li>The code is trusted (not from external users)</li> <li>You don't need state to persist between executions</li> <li>The lower overhead compared to <code>PythonExecExecutorResolver</code> is beneficial</li> </ul>"},{"location":"dependencies/core/in_process_interpreter.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>PythonExecExecutorResolver - For stateful, secure Python execution with better isolation </li> </ul>"},{"location":"dependencies/core/python_exec_executor.html","title":"PythonExecExecutorResolver","text":"<p>The <code>PythonExecExecutorResolver</code> provides a secure way for agents to execute Python code dynamically. It includes safeguards like import whitelisting to prevent potentially harmful operations.</p>"},{"location":"dependencies/core/python_exec_executor.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[CodeExecutor]</code></li> <li>Provided Dependency: <code>PythonExecExecutor</code></li> <li>Package: <code>rustic_ai.core.guild.agent_ext.depends.code_execution.stateful.python_exec_executor</code></li> </ul>"},{"location":"dependencies/core/python_exec_executor.html#security-features","title":"Security Features","text":"<ul> <li>Import Whitelisting: Only pre-approved modules can be imported</li> <li>Agent Isolation: Each agent gets its own execution environment</li> <li>Default Imports: Common, safe packages can be pre-imported</li> <li>No File System Access: By default, file system access is restricted</li> </ul>"},{"location":"dependencies/core/python_exec_executor.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>whitelisted_imports</code> <code>Set[str]</code> Set of package names that are allowed to be imported <code>None</code> (all imports blocked) <code>default_imports</code> <code>Dict[str, str]</code> Dictionary mapping import names to their module paths <code>None</code> (no default imports)"},{"location":"dependencies/core/python_exec_executor.html#usage","title":"Usage","text":""},{"location":"dependencies/core/python_exec_executor.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"code_guild\", \"Code Execution Guild\", \"Guild with Python execution capabilities\")\n    .add_dependency_resolver(\n        \"code_executor\",\n        DependencySpec(\n            class_name=\"rustic_ai.core.guild.agent_ext.depends.code_execution.stateful.python_exec_executor.PythonExecExecutorResolver\",\n            properties={\n                \"whitelisted_imports\": [\"numpy\", \"pandas\", \"matplotlib.pyplot\"],\n                \"default_imports\": {\n                    \"np\": \"numpy\",\n                    \"pd\": \"pandas\",\n                    \"plt\": \"matplotlib.pyplot\"\n                }\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/core/python_exec_executor.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.agent_ext.depends.code_execution.stateful.python_exec_executor import PythonExecExecutor\n\nclass CodeExecutionAgent(Agent):\n    @agent.processor(clz=CodeRequest, depends_on=[\"code_executor\"])\n    def execute_code(self, ctx: agent.ProcessContext, code_executor: PythonExecExecutor):\n        code = ctx.payload.code\n        input_data = ctx.payload.input_data\n\n        # Execute the code with the provided input data\n        result = code_executor.execute(\n            code=code,\n            globals_dict={\"input_data\": input_data},\n            return_globals=[\"output\"]\n        )\n\n        if result.success:\n            output = result.globals.get(\"output\", \"No output variable defined\")\n            ctx.send_dict({\"status\": \"success\", \"output\": output})\n        else:\n            ctx.send_dict({\"status\": \"error\", \"error\": result.error})\n</code></pre>"},{"location":"dependencies/core/python_exec_executor.html#execution-results","title":"Execution Results","text":"<p>The <code>execute()</code> method returns an <code>ExecutionResult</code> object with the following fields:</p> Field Type Description <code>success</code> <code>bool</code> Whether the execution was successful <code>error</code> <code>str</code> Error message if <code>success</code> is <code>False</code> <code>stdout</code> <code>str</code> Captured standard output <code>stderr</code> <code>str</code> Captured standard error <code>globals</code> <code>Dict[str, Any]</code> Global variables after execution (if <code>return_globals</code> specified)"},{"location":"dependencies/core/python_exec_executor.html#state-management","title":"State Management","text":"<p>The <code>PythonExecExecutor</code> preserves state between executions for the same agent. This means:</p> <ol> <li>Variables defined in one execution are available in the next</li> <li>Functions and classes persist across executions</li> <li>Each agent gets its own isolated execution environment</li> </ol>"},{"location":"dependencies/core/python_exec_executor.html#security-considerations","title":"Security Considerations","text":"<p>To prevent security issues:</p> <ul> <li>Carefully select which imports to whitelist</li> <li>Never whitelist system modules that can execute shell commands (<code>os</code>, <code>subprocess</code>, etc.)</li> <li>Use input validation before passing user-generated code to the executor</li> <li>Monitor resource usage to prevent runaway computations</li> <li>Consider using timeouts for code execution</li> </ul>"},{"location":"dependencies/core/python_exec_executor.html#example-data-analysis-agent","title":"Example: Data Analysis Agent","text":"<pre><code>@agent.processor(clz=AnalysisRequest, depends_on=[\"code_executor\"])\ndef run_analysis(self, ctx: agent.ProcessContext, code_executor: PythonExecExecutor):\n    # Let's assume we have pandas whitelisted\n    code = \"\"\"\n    import pandas as pd\n\n    # Process the input data\n    df = pd.DataFrame(input_data)\n\n    # Perform some analysis\n    summary = df.describe()\n    correlation = df.corr()\n\n    # Set output variable to be returned\n    output = {\n        \"summary\": summary.to_dict(),\n        \"correlation\": correlation.to_dict()\n    }\n    \"\"\"\n\n    result = code_executor.execute(\n        code=code,\n        globals_dict={\"input_data\": ctx.payload.data},\n        return_globals=[\"output\"]\n    )\n\n    if result.success:\n        ctx.send_dict({\"analysis_results\": result.globals[\"output\"]})\n    else:\n        ctx.send_dict({\"error\": result.error})\n</code></pre>"},{"location":"dependencies/core/python_exec_executor.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>InProcessCodeInterpreterResolver - For simpler code execution needs </li> </ul>"},{"location":"dependencies/langchain/index.html","title":"LangChain Dependencies","text":"<p>The LangChain package provides dependency resolvers that integrate the LangChain framework into Rustic AI agents. LangChain is a popular framework for developing applications powered by language models.</p>"},{"location":"dependencies/langchain/index.html#available-resolvers","title":"Available Resolvers","text":"<ul> <li>OpenAIEmbeddingsResolver - Generate vector embeddings using OpenAI's embedding models</li> <li>CharacterSplitterResolver - Text splitter based on characters with configurable chunk size</li> <li>RecursiveSplitterResolver - Text splitter that recursively splits by different separators</li> </ul>"},{"location":"dependencies/langchain/index.html#usage","title":"Usage","text":"<p>LangChain dependencies provide essential tools for working with text data, from embedding generation to text chunking. These capabilities are especially useful for natural language processing tasks and for preparing data for vector databases and retrieval systems.</p> <p>For details on how to configure and use each resolver, please refer to the specific documentation links above. </p>"},{"location":"dependencies/langchain/character_splitter.html","title":"CharacterSplitterResolver","text":"<p>The <code>CharacterSplitterResolver</code> provides a text splitting service that divides text into smaller chunks based on character separators. This is particularly useful for processing large documents before embedding or generating summaries.</p>"},{"location":"dependencies/langchain/character_splitter.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[TextSplitter]</code></li> <li>Provided Dependency: <code>CharacterTextSplitter</code></li> <li>Package: <code>rustic_ai.langchain.agent_ext.text_splitter.character_splitter</code></li> </ul>"},{"location":"dependencies/langchain/character_splitter.html#features","title":"Features","text":"<ul> <li>Character-Based Splitting: Split text at specified separator characters</li> <li>Configurable Chunk Size: Control the approximate size of each text chunk</li> <li>Chunk Overlap: Define overlap between chunks to maintain context</li> <li>Multiple Separators: Use different separators with priority ordering</li> <li>Metadata Retention: Preserve document metadata across splits</li> </ul>"},{"location":"dependencies/langchain/character_splitter.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>separator</code> <code>str</code> Character(s) to split on <code>\"\\n\\n\"</code> (blank line) <code>chunk_size</code> <code>int</code> Maximum chunk size in characters <code>1000</code> <code>chunk_overlap</code> <code>int</code> Number of characters to overlap between chunks <code>200</code> <code>add_start_index</code> <code>bool</code> Add chunk start index to metadata <code>True</code> <code>strip_whitespace</code> <code>bool</code> Strip whitespace from chunk beginnings/ends <code>True</code>"},{"location":"dependencies/langchain/character_splitter.html#usage","title":"Usage","text":""},{"location":"dependencies/langchain/character_splitter.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"text_processing_guild\", \"Text Processing Guild\", \"Guild with text processing capabilities\")\n    .add_dependency_resolver(\n        \"text_splitter\",\n        DependencySpec(\n            class_name=\"rustic_ai.langchain.agent_ext.text_splitter.character_splitter.CharacterSplitterResolver\",\n            properties={\n                \"separator\": \"\\n\\n\",  # Split on blank lines\n                \"chunk_size\": 1000,\n                \"chunk_overlap\": 200\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/langchain/character_splitter.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.langchain.agent_ext.text_splitter.character_splitter import CharacterTextSplitter\nfrom rustic_ai.core.agents.commons.media import Document\n\nclass TextProcessingAgent(Agent):\n    @agent.processor(clz=DocumentChunkRequest, depends_on=[\"text_splitter\"])\n    def split_document(self, ctx: agent.ProcessContext, text_splitter: CharacterTextSplitter):\n        # Create a document\n        document = Document(\n            id=\"doc1\",\n            text=ctx.payload.text,\n            metadata={\"source\": ctx.payload.source}\n        )\n\n        # Split the document into smaller chunks\n        chunks = text_splitter.split_document(document)\n\n        # Each chunk is a Document object with its own ID and metadata\n        ctx.send_dict({\n            \"original_id\": document.id,\n            \"chunk_count\": len(chunks),\n            \"chunks\": [\n                {\n                    \"id\": chunk.id,\n                    \"text\": chunk.text,\n                    \"metadata\": chunk.metadata\n                }\n                for chunk in chunks\n            ]\n        })\n\n    @agent.processor(clz=TextChunkRequest, depends_on=[\"text_splitter\"])\n    def split_text(self, ctx: agent.ProcessContext, text_splitter: CharacterTextSplitter):\n        # Split raw text (without creating a Document)\n        text = ctx.payload.text\n        chunks = text_splitter.split_text(text)\n\n        ctx.send_dict({\n            \"chunk_count\": len(chunks),\n            \"chunks\": chunks\n        })\n</code></pre>"},{"location":"dependencies/langchain/character_splitter.html#api-reference","title":"API Reference","text":"<p>The <code>CharacterTextSplitter</code> class provides these primary methods:</p> Method Description <code>split_text(text: str) -&gt; List[str]</code> Split a single text string into chunks <code>split_documents(documents: List[Document]) -&gt; List[Document]</code> Split multiple Document objects <code>split_document(document: Document) -&gt; List[Document]</code> Split a single Document object <code>create_documents(texts: List[str], metadatas: List[Dict] = None) -&gt; List[Document]</code> Create Document objects from texts"},{"location":"dependencies/langchain/character_splitter.html#working-with-document-objects","title":"Working with Document Objects","text":"<p>When splitting Document objects, important points to note:</p> <ol> <li>The original document's metadata is preserved in each chunk</li> <li>Each chunk gets a unique ID (based on the original ID with a suffix)</li> <li>Additional metadata is added to track the chunk's position and content:<ul> <li><code>chunk_index</code>: The position of the chunk in the sequence</li> <li><code>start_index</code>: The character position in the original text where the chunk starts</li> </ul> </li> </ol>"},{"location":"dependencies/langchain/character_splitter.html#example-processing-large-documents-for-rag","title":"Example: Processing Large Documents for RAG","text":"<pre><code>@agent.processor(clz=PrepareForRAGRequest, depends_on=[\"text_splitter\", \"vectorstore\"])\ndef prepare_for_rag(self, ctx: agent.ProcessContext, text_splitter: CharacterTextSplitter, vectorstore: VectorStore):\n    # Convert input text to a Document\n    document = Document(\n        id=f\"doc-{uuid.uuid4()}\",\n        text=ctx.payload.text,\n        metadata={\n            \"source\": ctx.payload.source,\n            \"author\": ctx.payload.author,\n            \"date\": ctx.payload.date\n        }\n    )\n\n    # Split into manageable chunks\n    chunks = text_splitter.split_document(document)\n\n    # Store chunks in vector database for later retrieval\n    result = vectorstore.upsert(chunks)\n\n    ctx.send_dict({\n        \"processed\": True,\n        \"document_id\": document.id,\n        \"chunk_count\": len(chunks),\n        \"success_count\": len(result.succeeded),\n        \"failed_count\": len(result.failed)\n    })\n</code></pre>"},{"location":"dependencies/langchain/character_splitter.html#custom-separators","title":"Custom Separators","text":"<p>You can use different separators with varying priorities:</p> <pre><code>DependencySpec(\n    class_name=\"rustic_ai.langchain.agent_ext.text_splitter.character_splitter.CharacterSplitterResolver\",\n    properties={\n        \"separator\": [\"\\n\\n\", \"\\n\", \". \", \", \"],  # Try these separators in order\n        \"chunk_size\": 800,\n        \"chunk_overlap\": 150\n    }\n)\n</code></pre> <p>With this configuration, the splitter will: 1. First try to split on blank lines (<code>\"\\n\\n\"</code>) 2. If chunks are still too large, split on newlines (<code>\"\\n\"</code>) 3. If still too large, split on sentence endings (<code>.</code>) 4. If still too large, split on commas (<code>,</code>)</p>"},{"location":"dependencies/langchain/character_splitter.html#when-to-use-character-splitting","title":"When to Use Character Splitting","text":"<p>Character splitting works well when:</p> <ul> <li>Documents have natural separators (paragraphs, lines, etc.)</li> <li>You need simple, fast splitting without complex logic</li> <li>Text is relatively well-structured</li> </ul> <p>For more complex splitting needs involving recursive separators or language-aware splitting, consider using RecursiveSplitterResolver.</p>"},{"location":"dependencies/langchain/character_splitter.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>RecursiveSplitterResolver - More advanced text splitting with recursive separator logic</li> <li>OpenAIEmbeddingsResolver - For embedding the split chunks</li> <li>ChromaResolver - For storing embedded chunks in a vector database </li> </ul>"},{"location":"dependencies/langchain/openai_embeddings.html","title":"OpenAIEmbeddingsResolver","text":"<p>The <code>OpenAIEmbeddingsResolver</code> provides access to OpenAI's embedding models for generating vector representations of text. These embeddings capture semantic meaning, allowing agents to perform operations like semantic search, clustering, and similarity matching.</p>"},{"location":"dependencies/langchain/openai_embeddings.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[Embeddings]</code></li> <li>Provided Dependency: <code>OpenAIEmbeddings</code></li> <li>Package: <code>rustic_ai.langchain.agent_ext.embeddings.openai</code></li> </ul>"},{"location":"dependencies/langchain/openai_embeddings.html#features","title":"Features","text":"<ul> <li>High-Quality Embeddings: Generate state-of-the-art text embeddings using OpenAI models</li> <li>Batch Processing: Efficiently embed multiple texts in a single API call</li> <li>Dimensionality Control: Specify the number of dimensions for embeddings</li> <li>Dynamic Sizing: Automatically handle texts of different lengths</li> <li>API Key Management: Flexible API key configuration</li> </ul>"},{"location":"dependencies/langchain/openai_embeddings.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>model</code> <code>str</code> Embedding model name <code>\"text-embedding-ada-002\"</code> <code>dimensions</code> <code>int</code> Number of dimensions for the embeddings Model-dependent <code>api_key</code> <code>str</code> OpenAI API key <code>None</code> (uses environment variables) <code>organization</code> <code>str</code> OpenAI organization ID <code>None</code> <code>timeout</code> <code>int</code> Request timeout in seconds <code>60</code> <code>max_retries</code> <code>int</code> Maximum number of retries for failed requests <code>6</code> <code>batch_size</code> <code>int</code> Maximum number of texts to embed in one API call <code>100</code> <code>chunk_size</code> <code>int</code> Maximum chunk size when dealing with very long texts <code>1000</code>"},{"location":"dependencies/langchain/openai_embeddings.html#usage","title":"Usage","text":""},{"location":"dependencies/langchain/openai_embeddings.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"embedding_guild\", \"Embedding Guild\", \"Guild with text embedding capabilities\")\n    .add_dependency_resolver(\n        \"embeddings\",\n        DependencySpec(\n            class_name=\"rustic_ai.langchain.agent_ext.embeddings.openai.OpenAIEmbeddingsResolver\",\n            properties={\n                \"model\": \"text-embedding-ada-002\",\n                \"dimensions\": 1536,\n                \"api_key\": \"sk-...\"  # or use environment variable OPENAI_API_KEY\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/langchain/openai_embeddings.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.langchain.agent_ext.embeddings.openai import OpenAIEmbeddings\n\nclass EmbeddingAgent(Agent):\n    @agent.processor(clz=EmbeddingRequest, depends_on=[\"embeddings\"])\n    def generate_embeddings(self, ctx: agent.ProcessContext, embeddings: OpenAIEmbeddings):\n        texts = ctx.payload.texts\n\n        # Generate embeddings for all texts\n        embedding_vectors = embeddings.embed_documents(texts)\n\n        # Generate embedding for a single text\n        query_vector = embeddings.embed_query(ctx.payload.query)\n\n        # Calculate similarities\n        similarities = []\n        for text, vector in zip(texts, embedding_vectors):\n            # Simple dot product similarity\n            similarity = sum(v1 * v2 for v1, v2 in zip(query_vector, vector))\n            similarities.append({\n                \"text\": text,\n                \"similarity\": similarity\n            })\n\n        # Sort by similarity (highest first)\n        similarities.sort(key=lambda x: x[\"similarity\"], reverse=True)\n\n        ctx.send_dict({\n            \"query\": ctx.payload.query,\n            \"results\": similarities\n        })\n</code></pre>"},{"location":"dependencies/langchain/openai_embeddings.html#api-reference","title":"API Reference","text":"<p>The <code>OpenAIEmbeddings</code> class provides these primary methods:</p> Method Description <code>embed_documents(texts: List[str]) -&gt; List[List[float]]</code> Generate embeddings for multiple texts <code>embed_query(text: str) -&gt; List[float]</code> Generate an embedding for a single text"},{"location":"dependencies/langchain/openai_embeddings.html#supported-models","title":"Supported Models","text":"<p>OpenAI offers several embedding models, each with different characteristics:</p> Model Dimensions Context Length Description <code>text-embedding-ada-002</code> 1536 8191 General purpose embeddings <code>text-embedding-3-small</code> 1536 8191 Newer model with improved performance <code>text-embedding-3-large</code> 3072 8191 High-performance, larger dimensional model"},{"location":"dependencies/langchain/openai_embeddings.html#cost-considerations","title":"Cost Considerations","text":"<ul> <li>Embedding models are charged per token</li> <li>The cost is significantly lower than completion models</li> <li>Batch processing is more cost-effective than single requests</li> <li>Consider caching embeddings for frequently used texts</li> </ul>"},{"location":"dependencies/langchain/openai_embeddings.html#example-semantic-search","title":"Example: Semantic Search","text":"<pre><code>@agent.processor(clz=SearchRequest, depends_on=[\"embeddings\"])\ndef semantic_search(self, ctx: agent.ProcessContext, embeddings: OpenAIEmbeddings):\n    query = ctx.payload.query\n    documents = self._get_documents()  # Method to retrieve documents\n\n    # Embed the query\n    query_embedding = embeddings.embed_query(query)\n\n    # Embed all documents (in a real implementation, you'd likely cache these)\n    document_embeddings = embeddings.embed_documents([doc[\"text\"] for doc in documents])\n\n    # Calculate similarity scores\n    search_results = []\n    for doc, doc_embedding in zip(documents, document_embeddings):\n        # Cosine similarity calculation\n        dot_product = sum(q * d for q, d in zip(query_embedding, doc_embedding))\n        magnitude1 = sum(q * q for q in query_embedding) ** 0.5\n        magnitude2 = sum(d * d for d in doc_embedding) ** 0.5\n        similarity = dot_product / (magnitude1 * magnitude2)\n\n        search_results.append({\n            \"text\": doc[\"text\"],\n            \"metadata\": doc[\"metadata\"],\n            \"similarity\": similarity\n        })\n\n    # Sort by similarity (highest first)\n    search_results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n\n    # Return top 5 results\n    ctx.send_dict({\n        \"query\": query,\n        \"results\": search_results[:5]\n    })\n</code></pre>"},{"location":"dependencies/langchain/openai_embeddings.html#integration-with-vector-databases","title":"Integration with Vector Databases","text":"<p>OpenAIEmbeddings works seamlessly with vector databases:</p> <pre><code>@agent.processor(clz=PopulateVectorDBRequest, depends_on=[\"embeddings\", \"vectorstore\"])\ndef populate_vector_db(self, ctx: agent.ProcessContext, embeddings: OpenAIEmbeddings, vectorstore: VectorStore):\n    documents = [\n        Document(\n            id=f\"doc{i}\",\n            text=text,\n            metadata={\"source\": \"example\"}\n        )\n        for i, text in enumerate(ctx.payload.documents)\n    ]\n\n    # The vector store will use the embeddings internally\n    result = vectorstore.upsert(documents)\n\n    ctx.send_dict({\n        \"success_count\": len(result.succeeded),\n        \"failed_count\": len(result.failed)\n    })\n</code></pre>"},{"location":"dependencies/langchain/openai_embeddings.html#security-and-authentication","title":"Security and Authentication","text":"<p>To authenticate with OpenAI, you can:</p> <ol> <li>Pass the API key directly in the resolver properties</li> <li>Set the <code>OPENAI_API_KEY</code> environment variable</li> <li>Use a secure secret manager via the <code>EnvSecretProviderDependencyResolver</code></li> </ol> <p>For security best practices, avoid hardcoding API keys and use environment variables or a secret management service.</p>"},{"location":"dependencies/langchain/openai_embeddings.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>ChromaResolver - Vector database for storing and searching embeddings</li> <li>CharacterSplitterResolver - Text splitter for breaking documents into chunks</li> <li>RecursiveSplitterResolver - Advanced text splitting for document processing </li> </ul>"},{"location":"dependencies/langchain/recursive_splitter.html","title":"RecursiveSplitterResolver","text":"<p>The <code>RecursiveSplitterResolver</code> provides an advanced text splitting service that recursively divides text using a hierarchy of separators. This enables more intelligent splitting that respects document structure, making it ideal for processing complex, structured documents.</p>"},{"location":"dependencies/langchain/recursive_splitter.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[TextSplitter]</code></li> <li>Provided Dependency: <code>RecursiveCharacterTextSplitter</code></li> <li>Package: <code>rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter</code></li> </ul>"},{"location":"dependencies/langchain/recursive_splitter.html#features","title":"Features","text":"<ul> <li>Hierarchical Splitting: Uses a prioritized list of separators to recursively split text</li> <li>Structure-Aware: Respects document structure by trying larger semantic units first</li> <li>Custom Separators: Configurable separators for different document types</li> <li>Chunk Control: Configure size and overlap of text chunks</li> <li>Language-Specific Presets: Built-in separator configurations for common languages/formats</li> </ul>"},{"location":"dependencies/langchain/recursive_splitter.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>separators</code> <code>List[str]</code> Ordered list of separators to split on See below <code>chunk_size</code> <code>int</code> Maximum chunk size in characters <code>1000</code> <code>chunk_overlap</code> <code>int</code> Number of characters to overlap between chunks <code>200</code> <code>add_start_index</code> <code>bool</code> Add chunk start index to metadata <code>True</code> <code>strip_whitespace</code> <code>bool</code> Strip whitespace from chunk beginnings/ends <code>True</code> <code>language</code> <code>str</code> Predefined separator set for a language/format <code>None</code>"},{"location":"dependencies/langchain/recursive_splitter.html#default-separators","title":"Default Separators","text":"<p>If not specified, the default separators (in order) are: 1. <code>\"\\n\\n\"</code> (blank line) 2. <code>\"\\n\"</code> (newline) 3. <code>\" \"</code> (space) 4. <code>\"\"</code> (character-by-character)</p>"},{"location":"dependencies/langchain/recursive_splitter.html#predefined-language-separators","title":"Predefined Language Separators","text":"Language Description Separators <code>\"python\"</code> Python code Module, class, function, line breaks <code>\"markdown\"</code> Markdown files Headers, paragraphs, lists <code>\"html\"</code> HTML documents Elements, paragraphs, breaks <code>\"cpp\"</code> C++ code Class, function, line separations <code>\"java\"</code> Java code Class, method, line separations"},{"location":"dependencies/langchain/recursive_splitter.html#usage","title":"Usage","text":""},{"location":"dependencies/langchain/recursive_splitter.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"text_processing_guild\", \"Text Processing Guild\", \"Guild with advanced text processing\")\n    .add_dependency_resolver(\n        \"recursive_splitter\",\n        DependencySpec(\n            class_name=\"rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter.RecursiveSplitterResolver\",\n            properties={\n                \"chunk_size\": 1000,\n                \"chunk_overlap\": 200,\n                \"separators\": [\"\\n## \", \"\\n### \", \"\\n#### \", \"\\n\", \" \", \"\"]\n            }\n        )\n    )\n    # Or use a predefined language configuration\n    .add_dependency_resolver(\n        \"markdown_splitter\",\n        DependencySpec(\n            class_name=\"rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter.RecursiveSplitterResolver\",\n            properties={\n                \"language\": \"markdown\",\n                \"chunk_size\": 1500,\n                \"chunk_overlap\": 300\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/langchain/recursive_splitter.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter import RecursiveCharacterTextSplitter\nfrom rustic_ai.core.agents.commons.media import Document\n\nclass DocumentProcessor(Agent):\n    @agent.processor(clz=DocumentRequest, depends_on=[\"recursive_splitter\"])\n    def process_document(self, ctx: agent.ProcessContext, recursive_splitter: RecursiveCharacterTextSplitter):\n        document = Document(\n            id=ctx.payload.doc_id,\n            text=ctx.payload.content,\n            metadata=ctx.payload.metadata\n        )\n\n        # Split document using recursive logic\n        chunks = recursive_splitter.split_document(document)\n\n        # Process the chunks\n        ctx.send_dict({\n            \"original_id\": document.id,\n            \"chunk_count\": len(chunks),\n            \"chunks\": [\n                {\n                    \"id\": chunk.id,\n                    \"text\": chunk.text[:100] + \"...\" if len(chunk.text) &gt; 100 else chunk.text,\n                    \"size\": len(chunk.text),\n                    \"metadata\": chunk.metadata\n                }\n                for chunk in chunks\n            ]\n        })\n</code></pre>"},{"location":"dependencies/langchain/recursive_splitter.html#how-recursive-splitting-works","title":"How Recursive Splitting Works","text":"<p>The recursive splitting process follows these steps:</p> <ol> <li>Start with the first separator in the list</li> <li>Split the text using this separator</li> <li>For each resulting segment:<ul> <li>If the segment is smaller than <code>chunk_size</code>, keep it</li> <li>Otherwise, recursively split it using the next separator in the list</li> </ul> </li> <li>Continue until all segments are within the specified size or no more separators are available</li> <li>Apply overlaps between adjacent chunks as specified by <code>chunk_overlap</code></li> </ol> <p>This approach results in more natural splits that respect document structure.</p>"},{"location":"dependencies/langchain/recursive_splitter.html#api-reference","title":"API Reference","text":"<p>The <code>RecursiveCharacterTextSplitter</code> class provides these primary methods:</p> Method Description <code>split_text(text: str) -&gt; List[str]</code> Split a single text string into chunks <code>split_documents(documents: List[Document]) -&gt; List[Document]</code> Split multiple Document objects <code>split_document(document: Document) -&gt; List[Document]</code> Split a single Document object <code>create_documents(texts: List[str], metadatas: List[Dict] = None) -&gt; List[Document]</code> Create Document objects from texts"},{"location":"dependencies/langchain/recursive_splitter.html#example-processing-code-files-for-embedding","title":"Example: Processing Code Files for Embedding","text":"<pre><code>@agent.processor(clz=CodeProcessingRequest, depends_on=[\"recursive_splitter\", \"vectorstore\"])\ndef process_code(self, ctx: agent.ProcessContext, recursive_splitter: RecursiveCharacterTextSplitter, vectorstore: VectorStore):\n    code_text = ctx.payload.code\n    language = ctx.payload.language\n\n    # Use language-specific splitter\n    language_specific_splitter = RecursiveCharacterTextSplitter.from_language(\n        language=language,\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n\n    # Create document\n    document = Document(\n        id=f\"code-{uuid.uuid4()}\",\n        text=code_text,\n        metadata={\n            \"filename\": ctx.payload.filename,\n            \"language\": language,\n            \"repository\": ctx.payload.repository\n        }\n    )\n\n    # Split code into semantically meaningful chunks\n    chunks = language_specific_splitter.split_document(document)\n\n    # Store in vector database\n    result = vectorstore.upsert(chunks)\n\n    ctx.send_dict({\n        \"success\": True,\n        \"chunk_count\": len(chunks),\n        \"stored_chunks\": len(result.succeeded)\n    })\n</code></pre>"},{"location":"dependencies/langchain/recursive_splitter.html#custom-separator-strategies","title":"Custom Separator Strategies","text":""},{"location":"dependencies/langchain/recursive_splitter.html#for-legal-documents","title":"For Legal Documents","text":"<pre><code>DependencySpec(\n    class_name=\"rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter.RecursiveSplitterResolver\",\n    properties={\n        \"separators\": [\n            \"\\nARTICLE \",      # Split on articles first\n            \"\\nSection \",      # Then on sections\n            \"\\nSubsection \",   # Then on subsections\n            \"\\n\\n\",            # Then on paragraphs\n            \"\\n\",              # Then on lines\n            \". \",              # Then on sentences\n            \" \",               # Then on words\n            \"\"                 # Finally on characters\n        ],\n        \"chunk_size\": 1000,\n        \"chunk_overlap\": 200\n    }\n)\n</code></pre>"},{"location":"dependencies/langchain/recursive_splitter.html#for-research-papers","title":"For Research Papers","text":"<pre><code>DependencySpec(\n    class_name=\"rustic_ai.langchain.agent_ext.text_splitter.recursive_splitter.RecursiveSplitterResolver\",\n    properties={\n        \"separators\": [\n            \"\\n# \",            # Split on main headers\n            \"\\n## \",           # Then on subheaders\n            \"\\n### \",          # Then on sub-subheaders\n            \"\\n\\n\",            # Then on paragraphs\n            \". \",              # Then on sentences\n            \", \",              # Then on clauses\n            \" \",               # Then on words\n            \"\"                 # Finally on characters\n        ],\n        \"chunk_size\": 1500,\n        \"chunk_overlap\": 300\n    }\n)\n</code></pre>"},{"location":"dependencies/langchain/recursive_splitter.html#when-to-use-recursive-splitting","title":"When to Use Recursive Splitting","text":"<p>Recursive splitting is ideal for:</p> <ul> <li>Complex, structured documents (code, legal texts, etc.)</li> <li>Documents where the hierarchy of content is important</li> <li>Cases where you want to preserve semantic units as much as possible</li> <li>Documents with varying section sizes</li> </ul> <p>For simpler documents or when performance is critical, consider CharacterSplitterResolver instead.</p>"},{"location":"dependencies/langchain/recursive_splitter.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>CharacterSplitterResolver - Simpler text splitting for less structured content</li> <li>OpenAIEmbeddingsResolver - For embedding the split chunks</li> <li>ChromaResolver - For storing embedded chunks in a vector database </li> </ul>"},{"location":"dependencies/litellm/index.html","title":"LiteLLM Dependencies","text":"<p>The LiteLLM package provides dependency resolvers that integrate AI language models into Rustic AI agents through the LiteLLM library. This enables consistent access to various large language models (LLMs) across different providers.</p>"},{"location":"dependencies/litellm/index.html#available-resolvers","title":"Available Resolvers","text":"<ul> <li>LiteLLMResolver - Unified access to LLMs from OpenAI, Anthropic, Google, and other providers</li> </ul>"},{"location":"dependencies/litellm/index.html#usage","title":"Usage","text":"<p>LiteLLM dependencies simplify working with large language models by providing a consistent interface across different LLM providers. This allows agents to seamlessly use and switch between different models without changing their code.</p> <p>For details on how to configure and use each resolver, please refer to the specific documentation links above. </p>"},{"location":"dependencies/litellm/litellm_resolver.html","title":"LiteLLMResolver","text":"<p>The <code>LiteLLMResolver</code> provides a unified interface for interacting with large language models (LLMs) from various providers like OpenAI, Anthropic, Google, and others. It leverages the LiteLLM library to standardize API calls across different LLM providers.</p>"},{"location":"dependencies/litellm/litellm_resolver.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[LLM]</code></li> <li>Provided Dependency: <code>LLM</code></li> <li>Package: <code>rustic_ai.litellm.agent_ext.llm</code></li> </ul>"},{"location":"dependencies/litellm/litellm_resolver.html#features","title":"Features","text":"<ul> <li>Provider Agnostic: Consistent interface across different LLM providers</li> <li>Model Switching: Easily switch between models without changing code</li> <li>Fallback Models: Configure backup models for reliability</li> <li>Cost Tracking: Optional tracking of token usage and costs</li> <li>Streaming Support: Stream responses for real-time interaction</li> <li>Async API: Support for both synchronous and asynchronous calls</li> </ul>"},{"location":"dependencies/litellm/litellm_resolver.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>model</code> <code>str</code> Model identifier (e.g., <code>\"gpt-4\"</code>, <code>\"claude-3-opus\"</code>) Required <code>api_key</code> <code>str</code> API key for the model provider <code>None</code> (uses environment variables) <code>organization_id</code> <code>str</code> Organization ID for API access <code>None</code> <code>base_url</code> <code>str</code> Custom base URL for API requests Provider's default URL <code>timeout</code> <code>float</code> Request timeout in seconds <code>600.0</code> (10 minutes) <code>max_retries</code> <code>int</code> Maximum number of retries on failure <code>2</code> <code>fallback_models</code> <code>List[str]</code> List of models to try if primary fails <code>[]</code> <code>temperature</code> <code>float</code> Model temperature (0.0-2.0) <code>0.7</code> <code>max_tokens</code> <code>int</code> Maximum tokens to generate <code>None</code> (model default) <code>top_p</code> <code>float</code> Nucleus sampling parameter <code>1.0</code> <code>frequency_penalty</code> <code>float</code> Penalty for token frequency <code>0.0</code> <code>presence_penalty</code> <code>float</code> Penalty for token presence <code>0.0</code> <code>extra_headers</code> <code>Dict[str, str]</code> Additional headers for API requests <code>{}</code>"},{"location":"dependencies/litellm/litellm_resolver.html#usage","title":"Usage","text":""},{"location":"dependencies/litellm/litellm_resolver.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"llm_guild\", \"LLM Guild\", \"Guild with LLM capabilities\")\n    .add_dependency_resolver(\n        \"llm\",\n        DependencySpec(\n            class_name=\"rustic_ai.litellm.agent_ext.llm.LiteLLMResolver\",\n            properties={\n                \"model\": \"gpt-4\",\n                \"temperature\": 0.5,\n                \"max_tokens\": 1000,\n                \"fallback_models\": [\"gpt-3.5-turbo\", \"claude-instant-1\"]\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.litellm.agent_ext.llm import LLM\nfrom rustic_ai.core.guild.agent_ext.depends.llm.models import ChatCompletionRequest, ChatMessage, ChatMessageRole\n\nclass LLMAgent(Agent):\n    @agent.processor(clz=QueryRequest, depends_on=[\"llm\"])\n    def process_query(self, ctx: agent.ProcessContext, llm: LLM):\n        query = ctx.payload.query\n\n        # Create chat completion request\n        request = ChatCompletionRequest(\n            messages=[\n                ChatMessage(role=ChatMessageRole.SYSTEM, content=\"You are a helpful assistant.\"),\n                ChatMessage(role=ChatMessageRole.USER, content=query)\n            ]\n        )\n\n        # Call the LLM\n        response = llm.completion(request)\n\n        # Send response back\n        ctx.send_dict({\n            \"response\": response.choices[0].message.content,\n            \"model\": response.model,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens\n            }\n        })\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#asynchronous-usage","title":"Asynchronous Usage","text":"<pre><code>@agent.processor(clz=QueryRequest, depends_on=[\"llm\"])\nasync def process_query_async(self, ctx: agent.ProcessContext, llm: LLM):\n    query = ctx.payload.query\n\n    # Create chat completion request\n    request = ChatCompletionRequest(\n        messages=[\n            ChatMessage(role=ChatMessageRole.SYSTEM, content=\"You are a helpful assistant.\"),\n            ChatMessage(role=ChatMessageRole.USER, content=query)\n        ]\n    )\n\n    # Call the LLM asynchronously\n    response = await llm.async_completion(request)\n\n    # Send response back\n    ctx.send_dict({\n        \"response\": response.choices[0].message.content,\n        \"model\": response.model\n    })\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#supported-llm-providers","title":"Supported LLM Providers","text":"<p>The LiteLLMResolver supports a wide range of LLM providers through the LiteLLM library:</p> <ul> <li>OpenAI: GPT-3.5, GPT-4, etc.</li> <li>Anthropic: Claude, Claude Instant, etc.</li> <li>Google: Gemini, PaLM, etc.</li> <li>Azure OpenAI: Hosted OpenAI models</li> <li>HuggingFace: Open source models</li> <li>Cohere: Command models</li> <li>Many others: See LiteLLM documentation for the full list</li> </ul>"},{"location":"dependencies/litellm/litellm_resolver.html#model-specification","title":"Model Specification","text":"<p>Models are specified using the format defined by LiteLLM. Some examples:</p> Provider Model Specification OpenAI <code>\"gpt-4\"</code>, <code>\"gpt-3.5-turbo\"</code> Anthropic <code>\"anthropic/claude-3-opus\"</code>, <code>\"anthropic/claude-instant-1\"</code> Google <code>\"google/gemini-pro\"</code> Azure OpenAI <code>\"azure/gpt-4\"</code> HuggingFace <code>\"huggingface/meta-llama/Llama-2-7b\"</code>"},{"location":"dependencies/litellm/litellm_resolver.html#api-keys","title":"API Keys","text":"<p>API keys can be provided in three ways (in order of precedence):</p> <ol> <li>Directly in the resolver properties (<code>api_key</code> parameter)</li> <li>Environment variables (e.g., <code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>)</li> <li>LiteLLM config file (see LiteLLM documentation)</li> </ol>"},{"location":"dependencies/litellm/litellm_resolver.html#cost-management","title":"Cost Management","text":"<p>LiteLLM provides built-in cost tracking. You can access usage information from the response:</p> <pre><code>response = llm.completion(request)\nprompt_tokens = response.usage.prompt_tokens\ncompletion_tokens = response.usage.completion_tokens\ntotal_tokens = response.usage.total_tokens\n\n# Estimate cost (provider and model dependent)\nestimated_cost = total_tokens * 0.00002  # Example rate for GPT-3.5-turbo\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#error-handling","title":"Error Handling","text":"<p>The LiteLLM resolver handles common errors like rate limits, timeouts, and model-specific errors:</p> <pre><code>try:\n    response = llm.completion(request)\n    # Process response\nexcept Exception as e:\n    # Handle error\n    error_message = str(e)\n    if \"rate limit\" in error_message.lower():\n        # Handle rate limiting\n        time.sleep(5)\n        # Retry or use fallback\n    elif \"context length\" in error_message.lower():\n        # Handle context length exceeded\n        # Truncate input or use different model\n    else:\n        # Handle other errors\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#example-multimodal-input","title":"Example: Multimodal Input","text":"<p>For models that support images (like GPT-4 Vision):</p> <pre><code>from rustic_ai.core.guild.agent_ext.depends.llm.models import ImageURL\n\nrequest = ChatCompletionRequest(\n    messages=[\n        ChatMessage(\n            role=ChatMessageRole.USER,\n            content=[\n                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                {\"type\": \"image_url\", \"image_url\": ImageURL(url=\"https://example.com/image.jpg\")}\n            ]\n        )\n    ]\n)\n\nresponse = llm.completion(request)\n</code></pre>"},{"location":"dependencies/litellm/litellm_resolver.html#related-resolvers","title":"Related Resolvers","text":"<p>Other LLM-related resolvers that might be useful in conjunction with LiteLLMResolver:</p> <ul> <li>OpenAI Embeddings (from LangChain package)</li> <li>Vector stores (for retrieval-augmented generation)</li> <li>KV stores (for caching responses) </li> </ul>"},{"location":"dependencies/redis/index.html","title":"Redis Dependencies","text":"<p>The Redis package provides dependency resolvers that integrate Redis services with Rustic AI agents. Redis is a popular in-memory data structure store that can be used as a database, cache, and message broker.</p>"},{"location":"dependencies/redis/index.html#available-resolvers","title":"Available Resolvers","text":"<ul> <li>RedisKVStoreResolver - Persistent key-value store backed by Redis</li> </ul>"},{"location":"dependencies/redis/index.html#usage","title":"Usage","text":"<p>Redis dependencies offer persistence and cross-process sharing capabilities that are essential for distributed and production deployments. These resolvers provide the persistence of a database with the performance of an in-memory solution.</p> <p>For details on how to configure and use each resolver, please refer to the specific documentation links above. </p>"},{"location":"dependencies/redis/redis_kvstore.html","title":"RedisKVStoreResolver","text":"<p>The <code>RedisKVStoreResolver</code> provides a persistent, shared key-value store backed by Redis. It offers a scalable solution for storing data that needs to be accessible across multiple agents, processes, or servers.</p>"},{"location":"dependencies/redis/redis_kvstore.html#overview","title":"Overview","text":"<ul> <li>Type: <code>DependencyResolver[RedisKVStore]</code></li> <li>Provided Dependency: <code>RedisKVStore</code></li> <li>Package: <code>rustic_ai.redis.agent_ext.kvstore</code></li> </ul>"},{"location":"dependencies/redis/redis_kvstore.html#features","title":"Features","text":"<ul> <li>Persistence: Data survives application restarts</li> <li>Distributed Access: Multiple processes can share the same data</li> <li>Namespacing: Organize keys with prefixes</li> <li>Expiration: Set TTL (Time-To-Live) for keys</li> <li>Transactions: Atomic operations for data consistency</li> <li>Serialization: Automatic JSON serialization/deserialization</li> </ul>"},{"location":"dependencies/redis/redis_kvstore.html#configuration","title":"Configuration","text":"Parameter Type Description Default <code>host</code> <code>str</code> Redis server hostname <code>\"localhost\"</code> <code>port</code> <code>int</code> Redis server port <code>6379</code> <code>db</code> <code>int</code> Redis database number <code>0</code> <code>password</code> <code>str</code> Redis password <code>None</code> <code>prefix</code> <code>str</code> Prefix for all keys <code>\"\"</code> (empty string) <code>socket_timeout</code> <code>float</code> Socket timeout in seconds <code>5.0</code> <code>socket_connect_timeout</code> <code>float</code> Socket connection timeout in seconds <code>5.0</code> <code>connection_pool</code> <code>Dict[str, Any]</code> Additional Redis connection pool options <code>{}</code>"},{"location":"dependencies/redis/redis_kvstore.html#usage","title":"Usage","text":""},{"location":"dependencies/redis/redis_kvstore.html#guild-configuration","title":"Guild Configuration","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\nguild_builder = (\n    GuildBuilder(\"redis_guild\", \"Redis Guild\", \"Guild with Redis-backed key-value store\")\n    .add_dependency_resolver(\n        \"kvstore\",\n        DependencySpec(\n            class_name=\"rustic_ai.redis.agent_ext.kvstore.RedisKVStoreResolver\",\n            properties={\n                \"host\": \"redis.example.com\",\n                \"port\": 6379,\n                \"password\": \"redis_password\",  # Or use an environment variable\n                \"prefix\": \"my_app:\"\n            }\n        )\n    )\n)\n</code></pre>"},{"location":"dependencies/redis/redis_kvstore.html#agent-usage","title":"Agent Usage","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.redis.agent_ext.kvstore import RedisKVStore\n\nclass PersistentDataAgent(Agent):\n    @agent.processor(clz=DataRequest, depends_on=[\"kvstore\"])\n    def handle_data(self, ctx: agent.ProcessContext, kvstore: RedisKVStore):\n        # Basic operations\n        kvstore.set(\"user:profile\", {\"name\": \"Alice\", \"email\": \"alice@example.com\"})\n        profile = kvstore.get(\"user:profile\")\n\n        # Set with expiration (TTL in seconds)\n        kvstore.set(\"session:token\", \"abc123\", ttl=3600)  # Expires in 1 hour\n\n        # Get multiple keys\n        users = kvstore.get_many([\"user:1\", \"user:2\", \"user:3\"])\n\n        # Delete keys\n        kvstore.delete(\"old_data\")\n\n        # Check if key exists\n        if kvstore.exists(\"cache:results\"):\n            results = kvstore.get(\"cache:results\")\n        else:\n            results = self._compute_results()\n            kvstore.set(\"cache:results\", results, ttl=300)  # Cache for 5 minutes\n\n        ctx.send_dict({\"results\": results})\n</code></pre>"},{"location":"dependencies/redis/redis_kvstore.html#api-reference","title":"API Reference","text":"<p>The <code>RedisKVStore</code> class provides these primary methods:</p> Method Description <code>get(key: str) -&gt; Any</code> Get a value by its key <code>get_many(keys: List[str]) -&gt; Dict[str, Any]</code> Get multiple values by their keys <code>set(key: str, value: Any, ttl: Optional[int] = None) -&gt; None</code> Set a value for a key with optional TTL in seconds <code>set_many(data: Dict[str, Any], ttl: Optional[int] = None) -&gt; None</code> Set multiple key-value pairs with optional TTL <code>delete(key: str) -&gt; bool</code> Delete a key <code>delete_many(keys: List[str]) -&gt; int</code> Delete multiple keys, returns count of deleted keys <code>exists(key: str) -&gt; bool</code> Check if a key exists <code>get_by_prefix(prefix: str) -&gt; Dict[str, Any]</code> Get all key-value pairs with keys starting with the prefix <code>clear() -&gt; None</code> Clear all keys (use with caution)"},{"location":"dependencies/redis/redis_kvstore.html#example-implementing-a-rate-limiter","title":"Example: Implementing a Rate Limiter","text":"<pre><code>@agent.processor(clz=ApiRequest, depends_on=[\"kvstore\"])\ndef process_api_request(self, ctx: agent.ProcessContext, kvstore: RedisKVStore):\n    user_id = ctx.payload.user_id\n    rate_limit_key = f\"rate_limit:{user_id}:{datetime.now().strftime('%Y-%m-%d:%H')}\"\n\n    # Get current count or 0 if not exists\n    current_count = kvstore.get(rate_limit_key) or 0\n\n    # Check if user exceeded rate limit (100 requests per hour)\n    if current_count &gt;= 100:\n        ctx.send_dict({\n            \"status\": \"error\",\n            \"message\": \"Rate limit exceeded. Try again later.\"\n        })\n        return\n\n    # Increment count and set TTL for auto-cleanup (1 hour + small buffer)\n    kvstore.set(rate_limit_key, current_count + 1, ttl=3700)\n\n    # Process the actual API request\n    result = self._call_api(ctx.payload.request_data)\n\n    ctx.send_dict({\n        \"status\": \"success\",\n        \"result\": result,\n        \"remaining_requests\": 100 - (current_count + 1)\n    })\n</code></pre>"},{"location":"dependencies/redis/redis_kvstore.html#clustering-and-high-availability","title":"Clustering and High Availability","text":"<p>For production environments, consider:</p> <ul> <li>Redis Sentinel: For high availability and automatic failover</li> <li>Redis Cluster: For scalability across multiple Redis nodes</li> <li>Redis Enterprise: For commercial support and additional features</li> </ul> <p>To use with Redis Sentinel:</p> <pre><code>DependencySpec(\n    class_name=\"rustic_ai.redis.agent_ext.kvstore.RedisKVStoreResolver\",\n    properties={\n        \"sentinel_hosts\": [\n            {\"host\": \"sentinel1.example.com\", \"port\": 26379},\n            {\"host\": \"sentinel2.example.com\", \"port\": 26379},\n            {\"host\": \"sentinel3.example.com\", \"port\": 26379}\n        ],\n        \"master_name\": \"mymaster\",\n        \"sentinel_password\": \"sentinel_password\"\n    }\n)\n</code></pre>"},{"location":"dependencies/redis/redis_kvstore.html#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Key Design: Use meaningful key names with hierarchical structure (e.g., <code>\"user:123:profile\"</code>)</li> <li>Data Size: Keep values reasonably sized; consider external storage for large objects</li> <li>TTL: Use TTL for temporary data to prevent memory leaks</li> <li>Connection Pooling: The resolver automatically uses connection pooling for efficiency</li> </ul>"},{"location":"dependencies/redis/redis_kvstore.html#comparison-with-inmemorykvstore","title":"Comparison with InMemoryKVStore","text":"Feature RedisKVStore InMemoryKVStore Persistence Yes No Multi-process Yes No Distributed Yes No TTL Support Yes No Performance Fast Extremely Fast Setup Complexity Requires Redis server No external dependencies"},{"location":"dependencies/redis/redis_kvstore.html#related-resolvers","title":"Related Resolvers","text":"<ul> <li>InMemoryKVStoreResolver - Non-persistent in-memory alternative </li> </ul>"},{"location":"howto/index.html","title":"Rustic AI How-To Guides","text":"<p>Welcome to the Rustic AI How-To Guides. These guides provide step-by-step instructions for common tasks when building systems with Rustic AI. They are designed to complement the core documentation by focusing on practical implementation.</p>"},{"location":"howto/index.html#getting-started","title":"Getting Started","text":"<ul> <li>Creating Your First Agent: Learn how to create a basic agent</li> <li>Creating a Guild with Multiple Agents: Build a system with multiple interacting agents</li> </ul>"},{"location":"howto/index.html#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Managing State in Agents: Learn how to maintain and update state in your agents</li> <li>Dependency Injection: Provide external services to your agents</li> <li>Complete Client-Server Flow: Comprehensive guide to building client applications with proper API flow, WebSocket communication, and synchronization</li> <li>Testing Agents: Effectively test your agents in isolation</li> <li>Writing Effective Agent Tests: In-depth guide with real-world testing patterns</li> </ul>"},{"location":"howto/index.html#reference","title":"Reference","text":"<ul> <li>Agent Documentation: Detailed documentation of available agents in Rustic AI</li> </ul>"},{"location":"howto/index.html#advanced-topics","title":"Advanced Topics","text":"<p>These guides will be coming soon:</p> <ul> <li>Guild Specifications: Define complex guild configurations in JSON/YAML</li> <li>Custom Routing Strategies: Control message flow between agents</li> <li>Distributed Deployments: Run agents across multiple processes or machines</li> <li>Custom State Backends: Configure alternative state persistence mechanisms</li> <li>Performance Tuning: Optimize your agent system for throughput and latency</li> </ul>"},{"location":"howto/index.html#example-projects","title":"Example Projects","text":"<p>For complete working examples, check the examples directory which contains:</p> <ol> <li>Simple Hello World implementations</li> <li>Basic agent capabilities demos</li> <li>More complex demo projects</li> <li>Example guild specifications</li> </ol>"},{"location":"howto/index.html#getting-help","title":"Getting Help","text":"<p>If you need assistance beyond what's covered in these guides:</p> <ol> <li>Check the core documentation for detailed reference</li> <li>Look at the example code for practical implementations</li> <li>Join our community channels for direct support </li> </ol>"},{"location":"howto/client_server_flow.html","title":"Complete Client-Server Flow Guide","text":"<p>This comprehensive guide covers the entire client-server interaction flow in Rustic AI, from blueprint creation through real-time messaging. It combines frontend API calls, backend orchestration, WebSocket communication, and proper synchronization strategies for building robust client applications.</p>"},{"location":"howto/client_server_flow.html#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Architecture Summary</li> <li>Phase 1: Blueprint &amp; Agent Setup</li> <li>Phase 2: Guild Creation &amp; Bootstrap</li> <li>Phase 3: System WebSocket Connection</li> <li>Phase 4: User WebSocket Connection</li> <li>Phase 5: Real-time Messaging</li> <li>Message Formats Reference</li> <li>Synchronization Strategy</li> <li>Error Handling</li> <li>Complete Example Implementation</li> </ul>"},{"location":"howto/client_server_flow.html#overview","title":"Overview","text":"<p>The Rustic AI platform provides a sophisticated multi-agent system where clients interact through a combination of REST APIs and WebSocket connections. Understanding the proper flow and synchronization is crucial for building reliable applications.</p>"},{"location":"howto/client_server_flow.html#key-concepts","title":"Key Concepts","text":"<ul> <li>Blueprints: Templates that define agent configurations and guild specifications</li> <li>Guilds: Runtime instances of agent groups working together</li> <li>System WebSocket: For guild health monitoring and system operations</li> <li>User WebSocket: For real-time chat and user interactions</li> <li>Agent Bootstrap: The process of initializing and launching agents within a guild</li> </ul>"},{"location":"howto/client_server_flow.html#architecture-summary","title":"Architecture Summary","text":"<pre><code>graph TB\n    subgraph \"Client Layer\"\n        C1[REST API Client]\n        C2[System WebSocket]\n        C3[User WebSocket]\n    end\n\n    subgraph \"API Server\"\n        A1[Catalog Router]\n        A2[Guild Router]\n        A3[System Comms Manager]\n        A4[User Comms Manager]\n        A5[Guild Service]\n    end\n\n    subgraph \"Guild Runtime\"\n        G1[GuildManagerAgent]\n        G2[Guild Agents&lt;br/&gt;from GuildSpec]\n        G3[UserProxyAgent]\n    end\n\n    subgraph \"Infrastructure\"\n        I1[Database&lt;br/&gt;SQLite/PostgreSQL]\n        I2[Messaging&lt;br/&gt;Redis/Embedded]\n        I3[State Management]\n    end\n\n    C1 --&gt; A1\n    C1 --&gt; A2\n    C2 --&gt; A3\n    C3 --&gt; A4\n    A1 --&gt;|\"POST /blueprints/id/guilds\"| A5\n    A5 --&gt;|\"bootstrap()\"| G1\n    A3 --&gt; G1\n    A4 --&gt; G3\n    G1 --&gt; G2\n    A5 --&gt; I1\n    G1 --&gt; I1\n    G2 --&gt; I2\n    G3 --&gt; I2\n    G1 --&gt; I3\n</code></pre>"},{"location":"howto/client_server_flow.html#phase-1-blueprint-agent-setup","title":"Phase 1: Blueprint &amp; Agent Setup","text":""},{"location":"howto/client_server_flow.html#11-register-agent-in-catalog","title":"1.1 Register Agent in Catalog","text":"<p>Before creating blueprints, agents must be registered in the catalog.</p> <p>Endpoint: <code>POST /catalog/agents</code></p> <pre><code>POST /catalog/agents\nContent-Type: application/json\n\n{\n  \"qualified_class_name\": \"rustic_ai.core.agents.testutils.echo_agent.EchoAgent\",\n  \"description\": \"Agent that echoes messages back to the sender\",\n  \"properties_schema\": {},\n  \"dependencies\": []\n}\n</code></pre> <p>Response: - <code>201 Created</code>: Agent registered successfully - <code>409 Conflict</code>: Agent already exists</p>"},{"location":"howto/client_server_flow.html#12-create-category","title":"1.2 Create Category","text":"<p>Organize blueprints into categories for better management.</p> <p>Endpoint: <code>POST /catalog/categories/</code></p> <pre><code>POST /catalog/categories/\nContent-Type: application/json\n\n{\n  \"name\": \"Testing\",\n  \"description\": \"Category for integration testing blueprints\"\n}\n</code></pre> <p>Response: <code>{\"id\": \"category_id\"}</code></p>"},{"location":"howto/client_server_flow.html#13-create-blueprint","title":"1.3 Create Blueprint","text":"<p>Blueprints define the guild specification and agent configurations.</p> <p>Endpoint: <code>POST /catalog/blueprints/</code></p> <pre><code>POST /catalog/blueprints/\nContent-Type: application/json\n\n{\n  \"name\": \"EchoTestBlueprint\",\n  \"description\": \"Echo agent for integration testing\",\n  \"version\": \"v1\",\n  \"author_id\": \"test_author\",\n  \"organization_id\": \"testorg456\",\n  \"exposure\": \"private\",\n  \"category_id\": \"{category_id}\",\n  \"spec\": {\n    \"name\": \"EchoTestBlueprint\",\n    \"description\": \"Echo agent for integration testing\",\n    \"agents\": [\n      {\n        \"name\": \"EchoAgent\",\n        \"description\": \"Agent that echoes messages\",\n        \"class_name\": \"rustic_ai.core.agents.testutils.echo_agent.EchoAgent\",\n        \"additional_topics\": [\"echo_topic\"],\n        \"listen_to_default_topic\": false\n      }\n    ],\n    \"properties\": {\n      \"messaging\": {\n        \"backend_module\": \"rustic_ai.redis.messaging.backend\",\n        \"backend_class\": \"RedisMessagingBackend\",\n        \"backend_config\": {\n          \"redis_client\": {\"host\": \"localhost\", \"port\": 6379}\n        }\n      },\n      \"execution_engine\": \"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\"\n    }\n  }\n}\n</code></pre> <p>Response: <code>{\"id\": \"blueprint_id\"}</code></p>"},{"location":"howto/client_server_flow.html#phase-2-guild-creation-bootstrap","title":"Phase 2: Guild Creation &amp; Bootstrap","text":""},{"location":"howto/client_server_flow.html#21-launch-guild-from-blueprint","title":"2.1 Launch Guild from Blueprint","text":"<p>Endpoint: <code>POST /catalog/blueprints/{blueprint_id}/guilds</code></p> <pre><code>POST /catalog/blueprints/{blueprint_id}/guilds\nContent-Type: application/json\n\n{\n  \"guild_name\": \"EchoTestGuild\",\n  \"user_id\": \"testuser123\",\n  \"org_id\": \"testorg456\",\n  \"description\": \"My test guild\"\n}\n</code></pre> <p>Response: <code>{\"id\": \"guild_id\"}</code></p>"},{"location":"howto/client_server_flow.html#22-backend-bootstrap-process","title":"2.2 Backend Bootstrap Process","text":"<p>When a guild is launched, the following sequence occurs:</p> <pre><code>sequenceDiagram\n    participant API as API Server\n    participant DB as Database\n    participant GM as GuildManagerAgent\n    participant GA as Guild Agents (from GuildSpec)\n    participant MS as Messaging System\n\n    API-&gt;&gt;DB: 1. Store guild spec (status: REQUESTED)\n    API-&gt;&gt;GM: 2. Bootstrap GuildManagerAgent\n    GM-&gt;&gt;DB: 3. Update status (PENDING_LAUNCH)\n    GM-&gt;&gt;GM: 4. Initialize state management\n    GM-&gt;&gt;MS: 5. Connect to messaging\n    GM-&gt;&gt;GM: 6. Send SelfReadyNotification\n    GM-&gt;&gt;GA: 7. Launch agents from GuildSpec\n    GA-&gt;&gt;MS: 8. Connect to messaging\n    GA-&gt;&gt;GA: 9. Send SelfReadyNotification\n    GA-&gt;&gt;MS: 10. Send first heartbeat\n    GM-&gt;&gt;MS: 11. Health check request\n    GA-&gt;&gt;MS: 12. Heartbeat responses\n    GM-&gt;&gt;DB: 13. Update status (RUNNING)\n    GM-&gt;&gt;MS: 14. Publish AgentsHealthReport\n</code></pre>"},{"location":"howto/client_server_flow.html#23-guild-state-transitions","title":"2.3 Guild State Transitions","text":"Status Description Next States <code>REQUESTED</code> Guild creation requested <code>PENDING_LAUNCH</code>, <code>ERROR</code> <code>PENDING_LAUNCH</code> GuildManagerAgent created <code>STARTING</code>, <code>ERROR</code> <code>STARTING</code> Agents initializing <code>RUNNING</code>, <code>ERROR</code> <code>RUNNING</code> All agents healthy <code>WARNING</code>, <code>STOPPED</code> <code>WARNING</code> Some agents unhealthy <code>RUNNING</code>, <code>ERROR</code> <code>ERROR</code> Critical failure <code>STOPPED</code> <code>STOPPED</code> Guild shut down -"},{"location":"howto/client_server_flow.html#phase-3-system-websocket-connection","title":"Phase 3: System WebSocket Connection","text":""},{"location":"howto/client_server_flow.html#31-connection-establishment","title":"3.1 Connection Establishment","text":"<p>WebSocket URL: <code>ws://host:port/ws/guilds/{guild_id}/syscomms/{user_id}</code></p> <pre><code>const systemWS = new WebSocket(`ws://localhost:8880/ws/guilds/${guild_id}/syscomms/${user_id}`);\n\nsystemWS.onopen = () =&gt; {\n  console.log(\"System WebSocket connected\");\n};\n</code></pre>"},{"location":"howto/client_server_flow.html#32-expected-system-messages","title":"3.2 Expected System Messages","text":""},{"location":"howto/client_server_flow.html#agentshealthreport","title":"AgentsHealthReport","text":"<p>Provides real-time guild and agent health status.</p> <pre><code>{\n  \"format\": \"rustic_ai.core.guild.agent_ext.mixins.health.AgentsHealthReport\",\n  \"payload\": {\n    \"agents\": {\n      \"agent_id_1\": {\n        \"checktime\": \"2025-01-15T10:00:00.000Z\",\n        \"checkstatus\": \"ok\",\n        \"responsetime\": \"2025-01-15T10:00:00.005Z\",\n        \"checkmeta\": {\n          \"qos_latency\": null,\n          \"observed_latency\": 5.2\n        }\n      }\n    },\n    \"guild_health\": \"ok\"\n  },\n  \"sender\": {\"id\": \"guild_manager_id\", \"name\": \"GuildManagerAgent\"},\n  \"timestamp\": 1642234567890\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#participantlist","title":"ParticipantList","text":"<p>List of all agents/participants in the guild.</p> <pre><code>{\n  \"format\": \"Participants\",\n  \"payload\": {\n    \"participants\": [\n      {\"id\": \"agent_id\", \"name\": \"EchoAgent\", \"type\": \"bot\"},\n      {\"id\": \"user_agent_id\", \"name\": \"Test User\", \"type\": \"human\"}\n    ]\n  }\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#33-system-commands","title":"3.3 System Commands","text":""},{"location":"howto/client_server_flow.html#request-participants","title":"Request Participants","text":"<pre><code>systemWS.send(JSON.stringify({\n  \"format\": \"participantsRequest\",\n  \"payload\": {\"guild_id\": guild_id},\n  \"sender\": {\"id\": user_id},\n  \"timestamp\": new Date().toISOString(),\n  \"conversationId\": \"conv_123\"\n}));\n</code></pre>"},{"location":"howto/client_server_flow.html#stop-guild","title":"Stop Guild","text":"<pre><code>systemWS.send(JSON.stringify({\n  \"format\": \"stopGuildRequest\",\n  \"payload\": {\"guild_id\": guild_id},\n  \"sender\": {\"id\": user_id}\n}));\n</code></pre>"},{"location":"howto/client_server_flow.html#phase-4-user-websocket-connection","title":"Phase 4: User WebSocket Connection","text":""},{"location":"howto/client_server_flow.html#41-connection-establishment","title":"4.1 Connection Establishment","text":"<p>WebSocket URL: <code>ws://host:port/ws/guilds/{guild_id}/usercomms/{user_id}/{user_name}</code></p> <pre><code>const userName = encodeURIComponent(\"Test User\");\nconst userWS = new WebSocket(`ws://localhost:8880/ws/guilds/${guild_id}/usercomms/${user_id}/${userName}`);\n</code></pre>"},{"location":"howto/client_server_flow.html#42-userproxyagent-auto-creation","title":"4.2 UserProxyAgent Auto-Creation","text":"<p>When a user WebSocket connects:</p> <ol> <li>UserAgentCreationRequest is sent to the system</li> <li>GuildManagerAgent creates a UserProxyAgent</li> <li>Updated AgentsHealthReport includes the new agent</li> <li>User can now send/receive messages</li> </ol>"},{"location":"howto/client_server_flow.html#43-user-message-flow","title":"4.3 User Message Flow","text":"<pre><code>graph LR\n    User[User WebSocket] --&gt; UPA[UserProxyAgent]\n    UPA --&gt; Inbox[user:user_id:inbox]\n    Inbox --&gt; Routes[Guild Routes]\n    Routes --&gt; Topic[agent_topic]\n    Topic --&gt; Agent[Target Agent]\n    Agent --&gt; Notif[user:user_id:notifications]\n    Notif --&gt; UPA\n    UPA --&gt; User\n</code></pre>"},{"location":"howto/client_server_flow.html#phase-5-real-time-messaging","title":"Phase 5: Real-time Messaging","text":""},{"location":"howto/client_server_flow.html#51-sending-messages","title":"5.1 Sending Messages","text":""},{"location":"howto/client_server_flow.html#text-message","title":"Text Message","text":"<pre><code>userWS.send(JSON.stringify({\n  \"id\": \"msg123\",\n  \"format\": \"text\",\n  \"payload\": {\"text\": \"Hello Echo!\"},\n  \"sender\": {\"id\": user_id, \"name\": user_name},\n  \"conversationId\": \"conv_789\",\n  \"timestamp\": new Date().toISOString()\n}));\n</code></pre>"},{"location":"howto/client_server_flow.html#file-message","title":"File Message","text":"<pre><code>userWS.send(JSON.stringify({\n  \"format\": \"rustic_ai.core.ui_protocol.types.FilesWithTextFormat\",\n  \"payload\": {\n    \"files\": [{\"name\": \"document.pdf\", \"url\": \"/files/document.pdf\"}],\n    \"text\": \"Here's the document you requested\",\n    \"tagged_users\": []\n  },\n  \"sender\": {\"id\": user_id, \"name\": user_name}\n}));\n</code></pre>"},{"location":"howto/client_server_flow.html#52-receiving-messages","title":"5.2 Receiving Messages","text":""},{"location":"howto/client_server_flow.html#echo-response","title":"Echo Response","text":"<pre><code>{\n  \"id\": 456789123,\n  \"format\": \"text\",\n  \"payload\": {\"text\": \"Echo: Hello Echo!\"},\n  \"sender\": {\"id\": \"echo_agent_id\", \"name\": \"EchoAgent\"},\n  \"topics\": [\"user:testuser123:notifications\"],\n  \"timestamp\": 1642234567890,\n  \"thread\": [123456789, 456789123],\n  \"in_response_to\": 123456789,\n  \"priority\": 4\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#message-formats-reference","title":"Message Formats Reference","text":""},{"location":"howto/client_server_flow.html#system-websocket-formats","title":"System WebSocket Formats","text":"Format Purpose Direction <code>rustic_ai.core.guild.agent_ext.mixins.health.AgentsHealthReport</code> Guild health status Server \u2192 Client <code>rustic_ai.core.guild.agent_ext.mixins.health.Heartbeat</code> Individual agent heartbeat Server \u2192 Client <code>Participants</code> Agent/participant list Server \u2192 Client <code>participantsRequest</code> Request participant list Client \u2192 Server <code>stopGuildRequest</code> Stop guild operation Client \u2192 Server"},{"location":"howto/client_server_flow.html#user-websocket-formats","title":"User WebSocket Formats","text":"Format Purpose Direction <code>text</code> Simple text messages Bidirectional <code>rustic_ai.core.ui_protocol.types.TextFormat</code> Structured text Bidirectional <code>rustic_ai.core.ui_protocol.types.FilesWithTextFormat</code> Files with text Bidirectional <code>rustic_ai.core.agents.commons.message_formats.ErrorMessage</code> Error messages Server \u2192 Client"},{"location":"howto/client_server_flow.html#common-message-properties","title":"Common Message Properties","text":"<pre><code>interface Message {\n  id: number;                    // Unique message ID\n  format: string;                // Message format/type\n  payload: object;               // Message content\n  sender: {                      // Sender information\n    id: string;\n    name: string;\n  };\n  topics?: string[];             // Routing topics\n  timestamp?: number;            // Unix timestamp\n  thread?: number[];             // Message thread chain\n  in_response_to?: number;       // Reply-to message ID\n  traceparent?: string;          // Distributed tracing\n  priority?: number;             // Priority (1-5)\n  conversation_id?: string;      // Conversation grouping\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#synchronization-strategy","title":"Synchronization Strategy","text":""},{"location":"howto/client_server_flow.html#recommended-connection-flow","title":"Recommended Connection Flow","text":"<p>The proper synchronization strategy ensures reliable initialization:</p> <pre><code>// State management\nconst ConnectionState = {\n  DISCONNECTED: 'disconnected',\n  SYSTEM_CONNECTED: 'system_connected',\n  GUILD_INITIALIZING: 'guild_initializing', \n  USER_CONNECTING: 'user_connecting',\n  AGENTS_READY: 'agents_ready',\n  FULLY_READY: 'fully_ready',\n  ERROR: 'error'\n};\n\nlet currentState = ConnectionState.DISCONNECTED;\nlet firstHealthReportReceived = false;\nlet fullyReady = false;\n\n// Step 1: Connect System WebSocket\nfunction connectSystemWebSocket() {\n  const systemWS = new WebSocket(`ws://host/ws/guilds/${guild_id}/syscomms/${user_id}`);\n\n  systemWS.onopen = () =&gt; {\n    currentState = ConnectionState.SYSTEM_CONNECTED;\n    showStatus(\"Connected to guild system...\");\n  };\n\n  systemWS.onmessage = (event) =&gt; {\n    const message = JSON.parse(event.data);\n\n    if (message.format === \"rustic_ai.core.guild.agent_ext.mixins.health.AgentsHealthReport\") {\n      // Step 2: First health report received - guild is initializing\n      if (!firstHealthReportReceived) {\n        firstHealthReportReceived = true;\n        currentState = ConnectionState.GUILD_INITIALIZING;\n        showStatus(\"Guild initializing, connecting user session...\");\n\n        // NOW safe to connect User WebSocket\n        connectUserWebSocket();\n      }\n\n      // Step 3: Guild health is \"ok\" - ready for messaging\n      if (message.payload.guild_health === \"ok\" &amp;&amp; !fullyReady) {\n        fullyReady = true;\n        currentState = ConnectionState.FULLY_READY;\n        showStatus(\"Ready! Starting with participants request...\");\n\n        // NOW safe to start messaging\n        sendParticipantsRequest();\n      }\n    }\n  };\n}\n\n// Step 2: Connect User WebSocket (only after first health report)\nfunction connectUserWebSocket() {\n  const userWS = new WebSocket(`ws://host/ws/guilds/${guild_id}/usercomms/${user_id}/${userName}`);\n\n  userWS.onopen = () =&gt; {\n    currentState = ConnectionState.USER_CONNECTING;\n    showStatus(\"User session connected, waiting for agents...\");\n  };\n}\n\n// Step 3: Start messaging (only after guild_health = \"ok\")\nfunction sendParticipantsRequest() {\n  systemWS.send(JSON.stringify({\n    \"format\": \"participantsRequest\",\n    \"payload\": {\"guild_id\": guild_id},\n    \"sender\": {\"id\": user_id}\n  }));\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#why-this-strategy-works","title":"Why This Strategy Works","text":"<ol> <li>Eliminates Race Conditions: No guessing when guild is ready</li> <li>Optimal Performance: UserProxyAgent creation happens in parallel</li> <li>Clear Readiness Signals: Each phase has explicit confirmation</li> <li>Better Error Handling: Can detect initialization failures early</li> <li>Improved UX: Clear progression feedback for users</li> </ol>"},{"location":"howto/client_server_flow.html#timeout-handling","title":"Timeout Handling","text":"<pre><code>const TIMEOUTS = {\n  HEALTH_REPORT: 10000,  // 10 seconds for first health report\n  READY_STATUS: 15000,   // 15 seconds for \"ok\" status\n  CONNECTION: 5000       // 5 seconds for WebSocket connections\n};\n\n// Timeout for first health report\nsetTimeout(() =&gt; {\n  if (!firstHealthReportReceived) {\n    currentState = ConnectionState.ERROR;\n    showError(\"Guild initialization timed out\");\n  }\n}, TIMEOUTS.HEALTH_REPORT);\n\n// Timeout for ready status\nsetTimeout(() =&gt; {\n  if (!fullyReady) {\n    currentState = ConnectionState.ERROR;\n    showError(\"Guild failed to reach ready state\");\n  }\n}, TIMEOUTS.READY_STATUS);\n</code></pre>"},{"location":"howto/client_server_flow.html#error-handling","title":"Error Handling","text":""},{"location":"howto/client_server_flow.html#websocket-errors","title":"WebSocket Errors","text":"<pre><code>systemWS.onerror = (error) =&gt; {\n  console.error(\"System WebSocket error:\", error);\n  currentState = ConnectionState.ERROR;\n  showError(\"Connection to guild system failed\");\n};\n\nsystemWS.onclose = (event) =&gt; {\n  if (currentState !== ConnectionState.FULLY_READY) {\n    showError(\"Connection lost during initialization\");\n  } else {\n    // Attempt reconnection\n    reconnectWithBackoff();\n  }\n};\n</code></pre>"},{"location":"howto/client_server_flow.html#guild-health-errors","title":"Guild Health Errors","text":"<pre><code>if (message.payload.guild_health === \"error\") {\n  currentState = ConnectionState.ERROR;\n  showError(\"Guild failed to initialize properly\");\n  return;\n}\n\nif (message.payload.guild_health === \"warning\") {\n  showWarning(\"Some agents are experiencing issues\");\n  // Continue operation but monitor\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#reconnection-strategy","title":"Reconnection Strategy","text":"<pre><code>let reconnectAttempts = 0;\nconst MAX_RECONNECT_ATTEMPTS = 5;\nconst BACKOFF_BASE = 1000; // 1 second\n\nfunction reconnectWithBackoff() {\n  if (reconnectAttempts &gt;= MAX_RECONNECT_ATTEMPTS) {\n    showError(\"Maximum reconnection attempts reached\");\n    return;\n  }\n\n  const delay = BACKOFF_BASE * Math.pow(2, reconnectAttempts);\n  reconnectAttempts++;\n\n  setTimeout(() =&gt; {\n    console.log(`Reconnection attempt ${reconnectAttempts}`);\n    connectSystemWebSocket();\n  }, delay);\n}\n</code></pre>"},{"location":"howto/client_server_flow.html#complete-example-implementation","title":"Complete Example Implementation","text":"<p>Here's a complete client implementation that demonstrates the proper flow:</p> <pre><code>class RusticAIClient {\n  constructor(baseUrl, guildId, userId, userName) {\n    this.baseUrl = baseUrl;\n    this.guildId = guildId;\n    this.userId = userId;\n    this.userName = userName;\n\n    this.systemWS = null;\n    this.userWS = null;\n    this.state = 'disconnected';\n    this.callbacks = {};\n  }\n\n  // Event handling\n  on(event, callback) {\n    this.callbacks[event] = this.callbacks[event] || [];\n    this.callbacks[event].push(callback);\n  }\n\n  emit(event, data) {\n    (this.callbacks[event] || []).forEach(cb =&gt; cb(data));\n  }\n\n  // Main connection flow\n  async connect() {\n    try {\n      this.emit('status', 'Connecting to guild system...');\n      await this.connectSystemWebSocket();\n    } catch (error) {\n      this.emit('error', `Connection failed: ${error.message}`);\n    }\n  }\n\n  connectSystemWebSocket() {\n    return new Promise((resolve, reject) =&gt; {\n      const wsUrl = `ws://${this.baseUrl}/ws/guilds/${this.guildId}/syscomms/${this.userId}`;\n      this.systemWS = new WebSocket(wsUrl);\n\n      const healthTimeout = setTimeout(() =&gt; {\n        reject(new Error('Guild initialization timeout'));\n      }, 10000);\n\n      this.systemWS.onopen = () =&gt; {\n        this.state = 'system_connected';\n        this.emit('status', 'Connected, waiting for guild initialization...');\n      };\n\n      this.systemWS.onmessage = (event) =&gt; {\n        const message = JSON.parse(event.data);\n        this.handleSystemMessage(message, resolve, healthTimeout);\n      };\n\n      this.systemWS.onerror = (error) =&gt; {\n        clearTimeout(healthTimeout);\n        reject(error);\n      };\n    });\n  }\n\n  handleSystemMessage(message, resolve, healthTimeout) {\n    if (message.format === \"rustic_ai.core.guild.agent_ext.mixins.health.AgentsHealthReport\") {\n\n      // First health report - connect user WebSocket\n      if (this.state === 'system_connected') {\n        this.state = 'guild_initializing';\n        this.emit('status', 'Guild initializing, connecting user session...');\n        this.connectUserWebSocket();\n      }\n\n      // Guild ready - start messaging\n      if (message.payload.guild_health === \"ok\" &amp;&amp; this.state !== 'ready') {\n        this.state = 'ready';\n        clearTimeout(healthTimeout);\n        this.emit('status', 'Ready!');\n        this.requestParticipants();\n        resolve();\n      }\n\n      // Handle error states\n      if (message.payload.guild_health === \"error\") {\n        clearTimeout(healthTimeout);\n        this.emit('error', 'Guild initialization failed');\n      }\n    }\n\n    // Forward other system messages\n    this.emit('system_message', message);\n  }\n\n  connectUserWebSocket() {\n    const wsUrl = `ws://${this.baseUrl}/ws/guilds/${this.guildId}/usercomms/${this.userId}/${encodeURIComponent(this.userName)}`;\n    this.userWS = new WebSocket(wsUrl);\n\n    this.userWS.onopen = () =&gt; {\n      this.emit('status', 'User session connected...');\n    };\n\n    this.userWS.onmessage = (event) =&gt; {\n      const message = JSON.parse(event.data);\n      this.emit('user_message', message);\n    };\n\n    this.userWS.onerror = (error) =&gt; {\n      this.emit('error', `User connection error: ${error.message}`);\n    };\n  }\n\n  // Messaging methods\n  requestParticipants() {\n    this.sendSystemMessage({\n      format: \"participantsRequest\",\n      payload: {guild_id: this.guildId},\n      sender: {id: this.userId}\n    });\n  }\n\n  sendChatMessage(text, conversationId = null) {\n    if (this.state !== 'ready') {\n      throw new Error('Client not ready for messaging');\n    }\n\n    this.sendUserMessage({\n      format: \"text\",\n      payload: {text},\n      sender: {id: this.userId, name: this.userName},\n      conversationId,\n      timestamp: new Date().toISOString()\n    });\n  }\n\n  sendSystemMessage(message) {\n    if (this.systemWS?.readyState === WebSocket.OPEN) {\n      this.systemWS.send(JSON.stringify(message));\n    }\n  }\n\n  sendUserMessage(message) {\n    if (this.userWS?.readyState === WebSocket.OPEN) {\n      this.userWS.send(JSON.stringify(message));\n    }\n  }\n\n  stopGuild() {\n    this.sendSystemMessage({\n      format: \"stopGuildRequest\",\n      payload: {guild_id: this.guildId},\n      sender: {id: this.userId}\n    });\n  }\n\n  disconnect() {\n    this.systemWS?.close();\n    this.userWS?.close();\n    this.state = 'disconnected';\n  }\n}\n\n// Usage example\nasync function main() {\n  const client = new RusticAIClient('localhost:8880', 'guild_123', 'user_456', 'Test User');\n\n  // Set up event handlers\n  client.on('status', (message) =&gt; console.log('Status:', message));\n  client.on('error', (error) =&gt; console.error('Error:', error));\n  client.on('system_message', (msg) =&gt; console.log('System:', msg));\n  client.on('user_message', (msg) =&gt; console.log('Message:', msg));\n\n  // Connect and start chatting\n  await client.connect();\n\n  // Send a test message\n  client.sendChatMessage('Hello Echo!');\n\n  // Stop guild after 30 seconds\n  setTimeout(() =&gt; {\n    client.stopGuild();\n    client.disconnect();\n  }, 30000);\n}\n</code></pre> <p>This guide provides a complete foundation for building robust client applications that interact with the Rustic AI platform. The key is following the proper synchronization strategy and handling all the various message types and error conditions appropriately. </p>"},{"location":"howto/creating_a_guild.html","title":"Creating a Guild with Multiple Agents","text":"<p>This guide will walk you through creating a guild with multiple agents that interact with each other using Rustic AI. In Rustic AI, a Guild serves as a container and coordination mechanism for a collection of agents.</p>"},{"location":"howto/creating_a_guild.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: - Installed Rustic AI and its dependencies - Basic understanding of agents (see Creating Your First Agent) - Familiarity with Rustic AI core concepts</p>"},{"location":"howto/creating_a_guild.html#understanding-guilds","title":"Understanding Guilds","text":"<p>A Guild in Rustic AI: - Serves as a container for multiple agents - Manages communication between agents - Handles message routing - Provides shared resources and dependencies - Manages the lifecycle of agents</p>"},{"location":"howto/creating_a_guild.html#step-1-design-your-agent-system","title":"Step 1: Design Your Agent System","text":"<p>Before coding, it's helpful to plan your multi-agent system:</p> <ol> <li>Identify the agents needed and their responsibilities</li> <li>Define message models for communication between agents</li> <li>Plan message flows and routing between agents</li> </ol> <p>For this example, we'll create a simple system with: - A <code>GreeterAgent</code> that responds to greeting requests - A <code>ProcessorAgent</code> that processes data - A <code>ProbeAgent</code> for monitoring message traffic</p>"},{"location":"howto/creating_a_guild.html#step-2-define-message-models","title":"Step 2: Define Message Models","text":"<p>Let's define our message models:</p> <pre><code>from pydantic import BaseModel\nfrom typing import Dict, Any, List\n\nclass GreetRequest(BaseModel):\n    \"\"\"A request for a greeting.\"\"\"\n    name: str\n\nclass GreetResponse(BaseModel):\n    \"\"\"A response with a greeting.\"\"\"\n    greeting: str\n\nclass ProcessRequest(BaseModel):\n    \"\"\"A request to process some data.\"\"\"\n    data: Dict[str, Any]\n    operation: str\n\nclass ProcessResponse(BaseModel):\n    \"\"\"A response with processed data.\"\"\"\n    result: Dict[str, Any]\n    processing_time: float\n</code></pre>"},{"location":"howto/creating_a_guild.html#step-3-implement-your-agents","title":"Step 3: Implement Your Agents","text":"<p>Now, let's implement our agents:</p>"},{"location":"howto/creating_a_guild.html#greeter-agent","title":"Greeter Agent","text":"<pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\nimport time\n\nclass GreeterAgent(Agent[BaseAgentProps]):\n    \"\"\"An agent that responds to greeting requests.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        print(f\"GreeterAgent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=GreetRequest)\n    def greet(self, ctx: agent.ProcessContext[GreetRequest]):\n        \"\"\"Process a greeting request and respond with a greeting.\"\"\"\n        name = ctx.payload.name\n        print(f\"[{self.name}] Received greeting request for: {name}\")\n\n        # Create and send a response\n        response = GreetResponse(greeting=f\"Hello, {name}!\")\n        ctx.send(response)\n        print(f\"[{self.name}] Sent response: {response.greeting}\")\n</code></pre>"},{"location":"howto/creating_a_guild.html#processor-agent","title":"Processor Agent","text":"<pre><code>class ProcessorAgent(Agent[BaseAgentProps]):\n    \"\"\"An agent that processes data requests.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        print(f\"ProcessorAgent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=ProcessRequest)\n    def process_data(self, ctx: agent.ProcessContext[ProcessRequest]):\n        \"\"\"Process a data processing request.\"\"\"\n        data = ctx.payload.data\n        operation = ctx.payload.operation\n\n        print(f\"[{self.name}] Processing {operation} on data: {data}\")\n\n        # Simulate processing\n        start_time = time.time()\n        result = self._perform_operation(data, operation)\n        processing_time = time.time() - start_time\n\n        # Send the response\n        ctx.send(ProcessResponse(\n            result=result,\n            processing_time=processing_time\n        ))\n        print(f\"[{self.name}] Sent processing result. Time: {processing_time:.4f}s\")\n\n    def _perform_operation(self, data: Dict[str, Any], operation: str) -&gt; Dict[str, Any]:\n        \"\"\"Perform an operation on the data.\"\"\"\n        if operation == \"count\":\n            return {\"count\": len(data)}\n        elif operation == \"sum\":\n            return {\"sum\": sum(data.values() if isinstance(data.values(), list) else data.values())}\n        elif operation == \"uppercase\":\n            return {k: v.upper() if isinstance(v, str) else v for k, v in data.items()}\n        else:\n            return {\"error\": f\"Unknown operation: {operation}\"}\n</code></pre>"},{"location":"howto/creating_a_guild.html#step-4-create-and-configure-a-guild","title":"Step 4: Create and Configure a Guild","text":"<p>Now, let's create a guild and add our agents to it:</p> <pre><code>import asyncio\nfrom rustic_ai.core.guild.builders import AgentBuilder, GuildBuilder\nfrom rustic_ai.core.agents.testutils.probe_agent import ProbeAgent\n\nasync def main():\n    # Create and launch a guild\n    guild = GuildBuilder(\"demo_guild\", \"Demo Guild\", \"A demonstration guild with multiple agents\") \\\n        .launch(organization_id=\"myawesomeorgid\", add_probe=True)  # The add_probe=True adds a ProbeAgent for monitoring\n\n    # Get the probe agent for monitoring messages\n    probe_agent = guild.get_agent_of_type(ProbeAgent)\n    print(f\"Created guild with ID: {guild.id}\")\n\n    # Create agent specs\n    greeter_agent_spec = AgentBuilder(GreeterAgent) \\\n        .set_name(\"Greeter\") \\\n        .set_description(\"An agent that responds to greeting requests\") \\\n        .build_spec()\n\n    processor_agent_spec = AgentBuilder(ProcessorAgent) \\\n        .set_name(\"Processor\") \\\n        .set_description(\"An agent that processes data requests\") \\\n        .build_spec()\n\n    # Launch the agents\n    guild.launch_agent(greeter_agent_spec)\n    guild.launch_agent(processor_agent_spec)\n\n    print(\"\\nAgents in the guild:\")\n    for agent_spec in guild.list_agents():\n        print(f\"- {agent_spec.name} (ID: {agent_spec.id}, Type: {agent_spec.class_name})\")\n\n    # Test the agents\n    print(\"\\nTesting the Greeter Agent...\")\n    probe_agent.publish(\"default_topic\", GreetRequest(name=\"World\"))\n\n    print(\"\\nTesting the Processor Agent...\")\n    probe_agent.publish(\"default_topic\", ProcessRequest(\n        data={\"a\": 1, \"b\": 2, \"c\": 3},\n        operation=\"sum\"\n    ))\n\n    # Wait for messages to be processed\n    await asyncio.sleep(1)\n\n    # Print all messages captured by the probe\n    messages = probe_agent.get_messages()\n    print(f\"\\nCaptured {len(messages)} messages:\")\n    for i, msg in enumerate(messages, 1):\n        print(f\"\\nMessage {i} from {msg.sender.name}:\")\n        print(f\"Format: {msg.format}\")\n        print(f\"Payload: {msg.payload}\")\n\n    # Shutdown the guild\n    guild.shutdown()\n    print(\"\\nGuild shutdown complete\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"howto/creating_a_guild.html#step-5-adding-custom-routing","title":"Step 5: Adding Custom Routing","text":"<p>You can customize message routing within your guild to create more complex interaction patterns:</p> <pre><code># Create a guild with custom routes\nguild = GuildBuilder(\"demo_guild\", \"Demo Guild\", \"A demonstration guild with multiple agents\")\n\n# Define a route\nroute = RouteBuilder() \\\n    .add_recipients(AgentTag(\"greeter_agent\")) \\\n    .build()\n\n# Add a custom route for greeting messages\nguild.add_route(route)\n</code></pre>"},{"location":"howto/creating_a_guild.html#step-6-using-guild-specifications","title":"Step 6: Using Guild Specifications","text":"<p>For more complex guilds, it's often easier to define them in a JSON specification file:</p> <pre><code>{\n  \"guild_id\": \"demo_guild\",\n  \"name\": \"Demo Guild\",\n  \"description\": \"A demonstration guild with multiple agents\",\n  \"agents\": [\n    {\n      \"id\": \"greeter_agent\",\n      \"name\": \"Greeter Agent\",\n      \"description\": \"An agent that handles greeting requests\",\n      \"class_name\": \"path.to.GreeterAgent\",\n      \"additional_topics\": [],\n      \"properties\": {},\n      \"listen_to_default_topic\": true\n    },\n    {\n      \"id\": \"processor_agent\",\n      \"name\": \"Processor Agent\",\n      \"description\": \"An agent that processes data\",\n      \"class_name\": \"path.to.ProcessorAgent\",\n      \"additional_topics\": [],\n      \"properties\": {},\n      \"listen_to_default_topic\": true\n    }\n  ],\n  \"default_topic\": \"default_topic\",\n  \"routes\": [\n    {\n      \"route_id\": \"greeting_route\",\n      \"match_expression\": \"$exists(payload.name)\",\n      \"to_recipient\": \"greeter_agent\",\n      \"mark_forwarded\": true,\n      \"description\": \"Route greeting messages to the greeter agent\"\n    },\n    {\n      \"route_id\": \"processing_route\",\n      \"match_expression\": \"$exists(payload.operation)\",\n      \"to_recipient\": \"processor_agent\",\n      \"mark_forwarded\": true,\n      \"description\": \"Route processing messages to the processor agent\"\n    }\n  ]\n}\n</code></pre> <p>You can load this specification using:</p> <pre><code>from rustic_ai.core.guild.builders import load_guild_from_spec\n\n# Load the guild specification from a file\nwith open(\"demo_guild_spec.json\", \"r\") as f:\n    guild_spec_json = f.read()\n\n# Create and launch the guild\nguild = load_guild_from_spec(guild_spec_json).launch(organization_id=\"myawesomeorgid\")\n</code></pre>"},{"location":"howto/creating_a_guild.html#advanced-guild-features","title":"Advanced Guild Features","text":""},{"location":"howto/creating_a_guild.html#shared-dependencies","title":"Shared Dependencies","text":"<p>You can define dependencies at the guild level that are shared by all agents:</p> <pre><code>from rustic_ai.core.guild.dsl import DependencySpec\n\n# Create a guild with shared dependencies\nguild = GuildBuilder(\"demo_guild\", \"Demo Guild\", \"A demonstration guild\")\n\n# Add a shared dependency\nguild.add_dependency(\n    key=\"database\",\n    dependency=DependencySpec(\n        class_name=\"path.to.DatabaseResolver\",\n        properties={\"connection_string\": \"sqlite:///guild.db\"}\n    )\n)\n\n# Launch the guild\nguild = guild.launch(organization_id=\"myawesomeorgid\")\n</code></pre>"},{"location":"howto/creating_a_guild.html#custom-topics","title":"Custom Topics","text":"<p>You can create custom topics for message routing:</p> <pre><code># Create agents with custom topics\ngreeter_agent_spec = AgentBuilder(GreeterAgent) \\\n    .set_name(\"Greeter\") \\\n    .set_description(\"An agent that responds to greeting requests\") \\\n    .set_additional_topics([\"greeting_topic\"]) \\\n    .build_spec()\n\n# Create a route to the custom topic\nguild.add_route(\n    route_id=\"greeting_route\",\n    match_expression=\"$exists(payload.name)\",\n    to_topic=\"greeting_topic\",\n    description=\"Route greeting messages to the greeting topic\"\n)\n</code></pre>"},{"location":"howto/creating_a_guild.html#next-steps","title":"Next Steps","text":"<p>Now that you've created a guild with multiple agents, you might want to:</p> <ul> <li>Learn about state management for sharing state between agents</li> <li>Explore dependency injection for more complex agent configurations</li> <li>Understand how to debug and test multi-agent systems</li> </ul> <p>For a complete example, see the Hello World Guild - <code>examples/hello_world/hello_world_guild.py</code> in the examples directory. </p>"},{"location":"howto/creating_your_first_agent.html","title":"Creating Your First Agent","text":"<p>This guide will walk you through creating your first agent using the Rustic AI framework. Agents are the fundamental building blocks in Rustic AI that encapsulate logic, maintain state, and communicate with other agents.</p>"},{"location":"howto/creating_your_first_agent.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: - Installed Rustic AI and its dependencies - Basic understanding of Python - Familiarity with Rustic AI core concepts</p>"},{"location":"howto/creating_your_first_agent.html#step-1-define-message-models","title":"Step 1: Define Message Models","text":"<p>First, let's define the message models our agent will process. We'll create a simple greeting agent that responds to name-based greeting requests.</p> <pre><code>from pydantic import BaseModel\n\nclass GreetRequest(BaseModel):\n    \"\"\"A simple model for greeting requests.\"\"\"\n    name: str\n\nclass GreetResponse(BaseModel):\n    \"\"\"A model for greeting responses.\"\"\"\n    greeting: str\n</code></pre>"},{"location":"howto/creating_your_first_agent.html#step-2-create-your-agent-class","title":"Step 2: Create Your Agent Class","text":"<p>Next, create a class that inherits from <code>Agent</code> and implements the message handling logic:</p> <pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\n\nclass MyGreeterAgent(Agent[BaseAgentProps]):\n    \"\"\"A simple agent that responds to greeting requests.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec):\n        super().__init__(agent_spec)\n        print(f\"Greeter Agent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=GreetRequest)\n    def greet(self, ctx: agent.ProcessContext[GreetRequest]):\n        \"\"\"Process a greeting request and respond with a greeting.\"\"\"\n        # Extract the name from the request\n        name = ctx.payload.name\n        print(f\"Received greeting request for: {name}\")\n\n        # Create and send a response\n        response = GreetResponse(greeting=f\"Hello, {name}!\")\n        ctx.send(response)\n        print(f\"Sent response: {response.greeting}\")\n</code></pre> <p>Let's break down what's happening here:</p> <ol> <li>Our agent inherits from <code>Agent[BaseAgentProps]</code> - this uses the most basic agent properties.</li> <li>The <code>__init__</code> method initializes the agent with the provided <code>AgentSpec</code>.</li> <li>The <code>@agent.processor(clz=GreetRequest)</code> decorator registers our <code>greet</code> method as a handler for <code>GreetRequest</code> messages.</li> <li>Inside the handler, we:<ul> <li>Extract the name from the request payload</li> <li>Create a <code>GreetResponse</code> object</li> <li>Send the response using <code>ctx.send()</code></li> </ul> </li> </ol>"},{"location":"howto/creating_your_first_agent.html#step-3-creating-an-agent-specification","title":"Step 3: Creating an Agent Specification","text":"<p>To use your agent, you need to create an <code>AgentSpec</code> that defines its configuration:</p> <pre><code>from rustic_ai.core.guild.builders import AgentBuilder\n\n# Create the agent specification\ngreeter_spec = AgentBuilder(MyGreeterAgent) \\\n    .set_name(\"MyGreeter\") \\\n    .set_description(\"A friendly greeter agent.\") \\\n    .build_spec()\n</code></pre>"},{"location":"howto/creating_your_first_agent.html#step-4-testing-your-agent","title":"Step 4: Testing Your Agent","text":"<p>You can test your agent directly without launching a full guild:</p> <pre><code>from rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.priority import Priority\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\n\n# Create a generator for message IDs\ngemstone_gen = GemstoneGenerator(machine_id=1)\n\n# Create the agent instance\ngreeter_agent = MyGreeterAgent(greeter_spec)\n\n# Create a test message\nmessage = Message(\n    id_obj=gemstone_gen.get_id(Priority.NORMAL),\n    topics=[\"test_topic\"],\n    sender=AgentTag(id=\"test_sender\", name=\"Test Sender\"),\n    payload=GreetRequest(name=\"World\").model_dump(),\n    format=get_qualified_class_name(GreetRequest),\n)\n\n# Process the message\ngreeter_agent._on_message(message)\n</code></pre>"},{"location":"howto/creating_your_first_agent.html#step-5-using-your-agent-in-a-guild","title":"Step 5: Using Your Agent in a Guild","text":"<p>In a real application, you would typically launch your agent as part of a guild:</p> <pre><code>from rustic_ai.core.guild.builders import GuildBuilder\n# Create an agent spec\ngreeter_spec = AgentBuilder(MyGreeterAgent) \\\n    .set_name(\"MyGreeter\") \\\n    .set_description(\"A friendly greeter agent.\") \\\n    .build_spec()\n\n\n# Create and launch a guild\nguild = GuildBuilder(\"greeting_guild\", \"Greeting Guild\", \"A guild with a greeter agent\") \\\n    .add_agent_spec(greeter_spec)\n    .launch(organization_id=\"myawesomeorgid\")\n\n...\n\n# Later, you can shut down the guild\nguild.shutdown()\n</code></pre>"},{"location":"howto/creating_your_first_agent.html#customizing-your-agent","title":"Customizing Your Agent","text":""},{"location":"howto/creating_your_first_agent.html#custom-properties","title":"Custom Properties","text":"<p>You can define custom properties for your agent by creating a subclass of <code>BaseAgentProps</code>:</p> <pre><code>class GreeterAgentProps(BaseAgentProps):\n    \"\"\"Custom properties for our greeter agent.\"\"\"\n    default_greeting: str = \"Hello\"\n    include_emoji: bool = True\n\nclass MyGreeterAgent(Agent[GreeterAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[GreeterAgentProps]):\n        super().__init__(agent_spec)\n        # Access props through agent_spec\n        self.default_greeting = agent_spec.props.default_greeting\n        self.include_emoji = agent_spec.props.include_emoji\n\n    @agent.processor(clz=GreetRequest)\n    def greet(self, ctx: agent.ProcessContext[GreetRequest]):\n        name = ctx.payload.name\n        emoji = \" \ud83d\udc4b\" if self.include_emoji else \"\"\n        greeting = f\"{self.default_greeting}, {name}!{emoji}\"\n        ctx.send(GreetResponse(greeting=greeting))\n</code></pre> <p>When creating the agent specification, provide the custom properties:</p> <pre><code>greeter_spec = AgentBuilder(MyGreeterAgent) \\\n    .set_name(\"MyGreeter\") \\\n    .set_description(\"A friendly greeter agent.\") \\\n    .set_properties(GreeterAgentProps(\n        default_greeting=\"Greetings\",\n        include_emoji=True\n    )) \\\n    .build_spec()\n</code></pre>"},{"location":"howto/creating_your_first_agent.html#next-steps","title":"Next Steps","text":"<p>Now that you've created your first agent, you might want to:</p> <ul> <li>Learn how to create a guild with multiple agents</li> <li>Understand state management in agents</li> <li>Explore dependency injection</li> </ul> <p>For a complete example, see the Hello World Agent - <code>examples/hello_world/hello_world_agent.py</code> in the examples directory. </p>"},{"location":"howto/dependency_injection.html","title":"Dependency Injection in Agents","text":"<p>This guide explains how to use dependency injection in Rustic AI agents, which allows you to provide external services and resources to your agents in a clean, modular way.</p>"},{"location":"howto/dependency_injection.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: - Installed Rustic AI and its dependencies - Basic understanding of agents (see Creating Your First Agent) - Familiarity with Rustic AI core concepts</p>"},{"location":"howto/dependency_injection.html#understanding-dependency-injection","title":"Understanding Dependency Injection","text":"<p>Dependency injection in Rustic AI allows you to:</p> <ol> <li>Separate concerns: Keep agent logic separate from external service implementations</li> <li>Enhance testability: Easily mock dependencies for testing</li> <li>Centralize configuration: Configure services once at the guild level</li> <li>Share resources: Reuse the same resources across multiple agents</li> </ol>"},{"location":"howto/dependency_injection.html#how-dependency-injection-works-in-rustic-ai","title":"How Dependency Injection Works in Rustic AI","text":"<p>The dependency injection system in Rustic AI consists of these key components:</p> <ol> <li>Dependencies: External services or resources (e.g., database connections, API clients)</li> <li>Dependency Resolvers: Classes that know how to create and configure dependencies</li> <li>Dependency Specifications: Configuration for dependency resolvers</li> <li>Injection Points: Places in your agent code where dependencies are injected</li> </ol>"},{"location":"howto/dependency_injection.html#step-1-create-a-dependency-resolver","title":"Step 1: Create a Dependency Resolver","text":"<p>A dependency resolver is a class that implements the <code>DependencyResolver</code> interface. Its job is to create and provide instances of the dependency.</p> <pre><code>from rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencyResolver\n\n# First, define your service class\nclass DatabaseService:\n    def __init__(self, connection_string: str):\n        self.connection_string = connection_string\n        self.connected = False\n        print(f\"DatabaseService created with connection: {connection_string}\")\n\n    def connect(self):\n        print(f\"Connecting to {self.connection_string}\")\n        self.connected = True\n\n    def execute_query(self, query: str):\n        if not self.connected:\n            self.connect()\n        print(f\"Executing query: {query}\")\n        return {\"result\": \"data from database\"}\n\n# Then, create a resolver for this service\nclass DatabaseResolver(DependencyResolver):\n    def __init__(self, connection_string: str = \"sqlite:///:memory:\"):\n        super().__init__()  # Important to call parent constructor\n        self.connection_string = connection_string\n        self._db_instance = None\n\n    def resolve(self, guild_id: str, agent_id: str = None) -&gt; DatabaseService:\n        \"\"\"Create or return the database service.\"\"\"\n        if self._db_instance is None:\n            self._db_instance = DatabaseService(self.connection_string)\n        return self._db_instance\n</code></pre>"},{"location":"howto/dependency_injection.html#step-2-configure-dependencies-in-your-guild-or-agent","title":"Step 2: Configure Dependencies in Your Guild or Agent","text":"<p>You can configure dependencies at the guild level (for all agents) or at the agent level (for specific agents).</p>"},{"location":"howto/dependency_injection.html#guild-level-dependencies","title":"Guild-Level Dependencies","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.guild.dsl import DependencySpec\n\n# Create a guild with a shared database dependency\nguild_builder = GuildBuilder(\"demo_guild\", \"Demo Guild\", \"A guild with shared dependencies\")\n\n# Set multiple dependencies at once\nguild_builder.set_dependency_map({\n    \"database\": DependencySpec(\n        class_name=\"your_package.resolvers.DatabaseResolver\",\n        properties={\"connection_string\": \"sqlite:///guild_db.sqlite\"}\n    )\n})\n\n# Or add a single dependency\nguild_builder.add_dependency_resolver(\n    \"logger\",\n    DependencySpec(\n        class_name=\"your_package.resolvers.LoggerResolver\",\n        properties={\"log_level\": \"INFO\"}\n    )\n)\n\n# Launch the guild\nguild = guild_builder.launch(organization_id=\"myawesomeorgid\")\n</code></pre>"},{"location":"howto/dependency_injection.html#agent-level-dependencies","title":"Agent-Level Dependencies","text":"<pre><code>from rustic_ai.core.guild.builders import AgentBuilder\n\n# Create an agent with its own database dependency\nagent_spec = AgentBuilder(MyAgent) \\\n    .set_name(\"DataAgent\") \\\n    .set_description(\"Agent with database access\") \\\n    .set_dependency_map({\n        \"database\": DependencySpec(\n            class_name=\"your_package.resolvers.DatabaseResolver\",\n            properties={\"connection_string\": \"sqlite:///agent_db.sqlite\"}\n        )\n    }) \\\n    .build_spec()\n</code></pre>"},{"location":"howto/dependency_injection.html#step-3-inject-dependencies-into-handler-methods","title":"Step 3: Inject Dependencies into Handler Methods","text":"<p>Use the <code>depends_on</code> parameter in the <code>@agent.processor</code> decorator to inject dependencies into your handler methods:</p> <pre><code>from rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\n\nclass QueryRequest(BaseModel):\n    \"\"\"A request to query the database.\"\"\"\n    query: str\n\nclass QueryResponse(BaseModel):\n    \"\"\"A response with query results.\"\"\"\n    results: dict\n\nclass DatabaseAgent(Agent[BaseAgentProps]):\n    \"\"\"An agent that uses a database dependency.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        print(f\"DatabaseAgent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=QueryRequest, depends_on=[\"database\"])\n    def execute_query(self, ctx: agent.ProcessContext[QueryRequest], database: DatabaseService):\n        \"\"\"Execute a database query using the injected database service.\"\"\"\n        query = ctx.payload.query\n        print(f\"[{self.name}] Executing query: {query}\")\n\n        # Use the injected database service\n        results = database.execute_query(query)\n\n        # Send the response\n        ctx.send(QueryResponse(results=results))\n</code></pre> <p>The key points in this example:</p> <ol> <li>The <code>depends_on=[\"database\"]</code> parameter specifies the dependency key to inject</li> <li>The handler method has a parameter <code>database: DatabaseService</code> that will receive the injected dependency</li> <li>The parameter name must match the key in <code>depends_on</code></li> <li>The type hint is optional but recommended for IDE support</li> </ol>"},{"location":"howto/dependency_injection.html#dependency-resolution-process","title":"Dependency Resolution Process","text":"<p>When an agent processes a message:</p> <ol> <li>The agent framework identifies the handler method to invoke</li> <li>It checks the <code>depends_on</code> list for the handler</li> <li>For each dependency key, it looks for a matching resolver:<ul> <li>First in the agent's dependency map</li> <li>Then in the guild's dependency map</li> </ul> </li> <li>It calls the resolver's <code>resolve()</code> method to get the dependency instance</li> <li>It injects the instance into the handler method</li> </ol>"},{"location":"howto/dependency_injection.html#dependency-lifetime-management","title":"Dependency Lifetime Management","text":"<p>In Rustic AI, dependencies are generally:</p> <ol> <li>Resolved once per agent or guild (depending on where they're defined)</li> <li>Cached by the resolver</li> <li>Shared among all handlers in an agent that request the same dependency</li> </ol> <p>This behavior can be customized by implementing different caching strategies in your resolvers:</p> <pre><code>class NonCachingResolver(DependencyResolver):\n    # Disable memoization to create a new instance each time\n    memoize_resolution = False\n\n    def resolve(self, guild_id: str, agent_id: str = None) -&gt; SomeService:\n        # Create a new instance every time\n        return SomeService()\n</code></pre>"},{"location":"howto/dependency_injection.html#testing-with-dependencies","title":"Testing with Dependencies","text":"<p>One of the main benefits of dependency injection is easier testing. You can create mock dependencies for testing:</p> <pre><code>from rustic_ai.testing.helpers import wrap_agent_for_testing\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\n\n# Create a mock resolver for testing\nclass MockDatabaseResolver(DependencyResolver):\n    def resolve(self, guild_id: str, agent_id: str = None) -&gt; DatabaseService:\n        \"\"\"Return a mock database service for testing.\"\"\"\n        mock_db = DatabaseService(\"mock://in-memory\")\n        # Override the execute_query method for testing\n        mock_db.execute_query = lambda query: {\"result\": \"mocked data\", \"query\": query}\n        return mock_db\n\n# Test setup\ndef test_database_agent():\n    # Create the agent\n    agent = AgentBuilder(DatabaseAgent) \\\n        .set_name(\"TestDBAgent\") \\\n        .build()\n\n    # Configure mock dependencies\n    mock_dependencies = {\n        \"database\": DependencySpec(\n            class_name=\"your_test_module.MockDatabaseResolver\",\n            properties={}\n        )\n    }\n\n    # Wrap the agent for testing with mock dependencies\n    test_agent, results = wrap_agent_for_testing(\n        agent,\n        GemstoneGenerator(machine_id=1),\n        dependencies=mock_dependencies\n    )\n\n    # Create a test message\n    message = Message(\n        id_obj=GemstoneGenerator(machine_id=1).get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Tester\"),\n        payload=QueryRequest(query=\"SELECT * FROM test\").model_dump(),\n        format=QueryRequest.model_json_schema()[\"$id\"]\n    )\n\n    # Process the message\n    test_agent._on_message(message)\n\n    # Check results\n    assert len(results) == 1\n    assert \"mocked data\" in results[0].payload[\"results\"][\"result\"]\n</code></pre>"},{"location":"howto/dependency_injection.html#advanced-dependency-injection-patterns","title":"Advanced Dependency Injection Patterns","text":""},{"location":"howto/dependency_injection.html#multiple-dependencies","title":"Multiple Dependencies","text":"<p>You can inject multiple dependencies into a single handler:</p> <pre><code>@agent.processor(clz=ComplexRequest, depends_on=[\"database\", \"api_client\", \"logger\"])\ndef handle_complex_request(\n    self, \n    ctx: agent.ProcessContext[ComplexRequest], \n    database: DatabaseService, \n    api_client: ApiClient,\n    logger: Logger\n):\n    # Use all three dependencies\n    logger.info(\"Processing complex request\")\n    db_data = database.execute_query(\"SELECT * FROM data\")\n    api_result = api_client.call_api(\"endpoint\", db_data)\n    ctx.send(ComplexResponse(result=api_result))\n</code></pre>"},{"location":"howto/dependency_injection.html#dependency-hierarchies","title":"Dependency Hierarchies","text":"<p>Dependencies can depend on other dependencies:</p> <pre><code>class ApiClientResolver(DependencyResolver):\n    def __init__(self, api_key: str, cache_service_key: str = \"cache\"):\n        super().__init__()\n        self.api_key = api_key\n        self.cache_service_key = cache_service_key\n        self._api_client = None\n\n    def resolve(self, guild_id: str, agent_id: str = None) -&gt; ApiClient:\n        if self._api_client is None:\n            # Inject another dependency using the inject method\n            cache_service = self.inject(CacheService, self.cache_service_key, guild_id, agent_id)\n            self._api_client = ApiClient(self.api_key, cache_service)\n        return self._api_client\n</code></pre>"},{"location":"howto/dependency_injection.html#best-practices-for-dependency-injection","title":"Best Practices for Dependency Injection","text":"<ol> <li> <p>Keep Resolvers Simple: Resolvers should focus on creating and configuring the service, not on business logic.</p> </li> <li> <p>Use Guild-Level Dependencies for shared resources that should be the same for all agents.</p> </li> <li> <p>Use Agent-Level Dependencies for resources that are specific to a single agent.</p> </li> <li> <p>Cache Appropriately: Most resolvers should cache dependency instances, but be careful with resources that need explicit cleanup.</p> </li> <li> <p>Type Hint Your Dependencies: Use type hints to make your code more readable and catch errors early.</p> </li> <li> <p>Design for Testability: Make your dependencies easy to mock for testing.</p> </li> <li> <p>Document Dependencies: Clearly document what dependencies your agents need and what they do.</p> </li> </ol>"},{"location":"howto/dependency_injection.html#example-a-complete-agent-with-dependency-injection","title":"Example: A Complete Agent with Dependency Injection","text":"<p>Here's a complete example of an agent that uses dependency injection:</p> <pre><code>from pydantic import BaseModel\nfrom typing import Dict, Any, List\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\n\n# Message models\nclass ApiRequest(BaseModel):\n    \"\"\"A request to call an API.\"\"\"\n    endpoint: str\n    data: Dict[str, Any]\n\nclass ApiResponse(BaseModel):\n    \"\"\"A response from an API call.\"\"\"\n    result: Dict[str, Any]\n\n# External service\nclass ApiService:\n    def __init__(self, api_key: str, base_url: str):\n        self.api_key = api_key\n        self.base_url = base_url\n        print(f\"ApiService initialized with key '{api_key}' and URL '{base_url}'\")\n\n    def call_api(self, endpoint: str, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Call an API endpoint.\"\"\"\n        print(f\"Calling API endpoint '{endpoint}' with data: {data}\")\n        # In a real implementation, this would make an HTTP request\n        return {\n            \"endpoint\": endpoint,\n            \"input\": data,\n            \"result\": \"API response data\",\n            \"timestamp\": \"2023-01-01T12:00:00Z\"\n        }\n\n# Dependency resolver\nclass ApiServiceResolver(DependencyResolver):\n    def __init__(self, api_key: str = \"default_key\", base_url: str = \"https://api.example.com\"):\n        super().__init__()\n        self.api_key = api_key\n        self.base_url = base_url\n        self._api_service = None\n\n    def resolve(self, guild_id: str, agent_id: str = None) -&gt; ApiService:\n        \"\"\"Create or return the API service.\"\"\"\n        if self._api_service is None:\n            self._api_service = ApiService(self.api_key, self.base_url)\n        return self._api_service\n\n# Agent that uses the dependency\nclass ApiAgent(Agent[BaseAgentProps]):\n    \"\"\"An agent that makes API calls using an injected API service.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        print(f\"ApiAgent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=ApiRequest, depends_on=[\"api_service\"])\n    def call_api(self, ctx: agent.ProcessContext[ApiRequest], api_service: ApiService):\n        \"\"\"Call an API using the injected API service.\"\"\"\n        request = ctx.payload\n\n        print(f\"[{self.name}] Calling API endpoint '{request.endpoint}'\")\n\n        # Use the injected API service\n        result = api_service.call_api(request.endpoint, request.data)\n\n        # Send the response\n        ctx.send(ApiResponse(result=result))\n</code></pre>"},{"location":"howto/dependency_injection.html#next-steps","title":"Next Steps","text":"<p>Now that you understand dependency injection, you might want to:</p> <ul> <li>Learn how to manage state in agents</li> <li>Explore creating custom guild specifications</li> <li>Understand testing and debugging agents with dependencies</li> </ul> <p>For a complete example, see the Dependency Injection Example - <code>examples/basic_agents/dependency_injection_example.py</code> in the examples directory. </p>"},{"location":"howto/guild_specifications.html","title":"Guild Specifications","text":"<p>This guide explains how to create and work with Guild Specifications (GuildSpec) in Rustic AI.</p>"},{"location":"howto/guild_specifications.html#what-is-a-guildspec","title":"What is a GuildSpec?","text":"<p>A <code>GuildSpec</code> is a declarative blueprint that defines the structure and behavior of a Guild. It specifies which agents are part of the guild, how they communicate, how they're executed, and what dependencies they have access to.</p>"},{"location":"howto/guild_specifications.html#creating-a-guildspec","title":"Creating a GuildSpec","text":"<p>There are two main ways to create a <code>GuildSpec</code>:</p>"},{"location":"howto/guild_specifications.html#1-using-the-guildbuilder-api","title":"1. Using the GuildBuilder API","text":"<p>The <code>GuildBuilder</code> provides a fluent interface for constructing guild specifications programmatically:</p> <pre><code>from rustic_ai.core.guild.builders import GuildBuilder, AgentBuilder\nfrom rustic_ai.agents.utils.user_proxy_agent import UserProxyAgent\nfrom rustic_ai.agents.llm.litellm.litellm_agent import LiteLLMAgent\n\n# Create a guild builder\nguild_builder = GuildBuilder(guild_name=\"MyGuild\") \\\n    .set_description(\"An example guild\") \\\n    .set_execution_engine(\"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\") \\\n    .set_messaging(\n        backend_module=\"rustic_ai.core.messaging.backend\",\n        backend_class=\"InMemoryMessagingBackend\",\n        backend_config={}\n    )\n\n# Add agent specifications\nuser_agent_spec = AgentBuilder(UserProxyAgent) \\\n    .set_id(\"user_agent\") \\\n    .set_name(\"User Interface\") \\\n    .set_description(\"Handles user interactions\") \\\n    .build_spec()\n\nllm_agent_spec = AgentBuilder(LiteLLMAgent) \\\n    .set_id(\"llm_agent\") \\\n    .set_name(\"Language Model\") \\\n    .set_description(\"Processes language tasks\") \\\n    .set_properties({\n        \"model\": \"gpt-3.5-turbo\",\n        \"temperature\": 0.7\n    }) \\\n    .build_spec()\n\n# Add the agents to the guild\nguild_builder.add_agent_spec(user_agent_spec)\nguild_builder.add_agent_spec(llm_agent_spec)\n\n# Build the GuildSpec\nguild_spec = guild_builder.build_spec()\n</code></pre>"},{"location":"howto/guild_specifications.html#2-using-yaml-or-json-configuration","title":"2. Using YAML or JSON Configuration","text":"<p>You can also define your guild specification in a YAML or JSON file:</p> <pre><code>id: \"my_guild_01\"\nname: \"MyGuild\"\ndescription: \"An example guild\"\nproperties:\n  execution_engine: \"rustic_ai.core.guild.execution.sync.sync_exec_engine.SyncExecutionEngine\"\n  messaging:\n    backend_module: \"rustic_ai.core.messaging.backend\"\n    backend_class: \"InMemoryMessagingBackend\"\n    backend_config: {}\nagents:\n  - id: \"user_agent\"\n    name: \"User Interface\"\n    description: \"Handles user interactions\"\n    class_name: \"rustic_ai.agents.utils.user_proxy_agent.UserProxyAgent\"\n    properties: {}\n  - id: \"llm_agent\"\n    name: \"Language Model\"\n    description: \"Processes language tasks\"\n    class_name: \"rustic_ai.agents.llm.litellm.litellm_agent.LiteLLMAgent\"\n    properties:\n      model: \"gpt-3.5-turbo\"\n      temperature: 0.7\n</code></pre> <p>Then load it in your code:</p> <pre><code>from rustic_ai.core.guild.dsl import GuildSpec\nimport yaml\n\n# Load from YAML file\nwith open(\"my_guild.yaml\", \"r\") as f:\n    guild_data = yaml.safe_load(f)\n\n# Parse into a GuildSpec\nguild_spec = GuildSpec.parse_obj(guild_data)\n</code></pre>"},{"location":"howto/guild_specifications.html#key-components-of-a-guildspec","title":"Key Components of a GuildSpec","text":"<p>A complete <code>GuildSpec</code> includes:</p> <ul> <li>Basic Information: <code>id</code>, <code>name</code>, <code>description</code></li> <li>Properties: Configures execution engines, messaging systems, etc.</li> <li>Agents: List of <code>AgentSpec</code> objects defining the member agents</li> <li>Dependencies: Resources available to agents via dependency injection</li> <li>Routes: Message routing rules for agent communication</li> </ul>"},{"location":"howto/guild_specifications.html#instantiating-a-guild-from-a-guildspec","title":"Instantiating a Guild from a GuildSpec","text":"<p>Once you have a <code>GuildSpec</code>, you can instantiate and launch a guild:</p> <pre><code># For development and testing\nguild = guild_builder.launch(organization_id=\"myawesomeorgid\")\n\n# For production (with persistence)\nguild = guild_builder.bootstrap(metastore_database_url=\"sqlite:///guild_store.db\", organization_id=\"myawesomeorgid\")\n</code></pre>"},{"location":"howto/guild_specifications.html#persisting-and-loading-guildspecs","title":"Persisting and Loading GuildSpecs","text":"<p>You can save and load guild specifications:</p> <pre><code># Save to JSON\nguild_spec_json = guild_spec.json(indent=2)\nwith open(\"guild_spec.json\", \"w\") as f:\n    f.write(guild_spec_json)\n\n# Load from JSON\nfrom rustic_ai.core.guild.dsl import GuildSpec\nimport json\n\nwith open(\"guild_spec.json\", \"r\") as f:\n    loaded_spec_data = json.load(f)\n\nloaded_guild_spec = GuildSpec.parse_obj(loaded_spec_data)\n</code></pre>"},{"location":"howto/guild_specifications.html#best-practices","title":"Best Practices","text":"<ol> <li>Modular Design: Break complex guilds into logical groups of agents</li> <li>Clear Naming: Use descriptive names for guilds and agents</li> <li>Version Control: Store guild specifications in version control</li> <li>Environment Variables: Use environment variables for sensitive configuration</li> <li>Documentation: Include clear descriptions for guilds and agents</li> </ol> <p>For more detailed information about guilds, see the Guilds core documentation. </p>"},{"location":"howto/state_management.html","title":"Managing State in Agents","text":"<p>This guide explains how to manage state in Rustic AI agents, allowing them to maintain data between message processing and share state across the guild.</p>"},{"location":"howto/state_management.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: - Installed Rustic AI and its dependencies - Basic understanding of agents (see Creating Your First Agent) - Familiarity with Rustic AI core concepts</p>"},{"location":"howto/state_management.html#understanding-state-in-rustic-ai","title":"Understanding State in Rustic AI","text":"<p>Rustic AI provides a robust state management system that allows agents to: - Maintain their own state across message processing - Access the shared guild state - Persist state using state backends - Update state safely with concurrency control</p>"},{"location":"howto/state_management.html#types-of-state","title":"Types of State","text":"<p>There are two primary types of state in a Rustic AI guild:</p> <ol> <li>Agent State: Private to each agent instance</li> <li>Guild State: Shared across all agents in the guild</li> </ol>"},{"location":"howto/state_management.html#accessing-state","title":"Accessing State","text":"<p>By default, every agent has access to:</p> <ul> <li><code>self._state</code>: A dictionary containing the agent's current state</li> <li><code>self._guild_state</code>: A dictionary containing the guild's shared state</li> </ul> <p>However, you should not modify these dictionaries directly. Instead, use the state management APIs described below.</p>"},{"location":"howto/state_management.html#basic-state-management-using-staterefreshermixin","title":"Basic State Management Using <code>StateRefresherMixin</code>","text":"<p>The <code>StateRefresherMixin</code> is automatically included in all agents via the <code>AgentMetaclass</code>. It provides methods for state management:</p> <pre><code>from rustic_ai.core.state.models import StateUpdateFormat\n\nclass MyStatefulAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        self.counter = 0  # Local instance variable (not persisted)\n\n    @agent.processor(clz=IncrementRequest)\n    def increment_counter(self, ctx: agent.ProcessContext[IncrementRequest]):\n        # Read from state\n        current_count = self._state.get(\"count\", 0)\n\n        # Update local variable\n        self.counter += 1\n\n        # Calculate new state\n        new_count = current_count + ctx.payload.amount\n\n        # Update state using StateRefresherMixin methods\n        self.update_state(\n            ctx=ctx,\n            update_format=StateUpdateFormat.MERGE_DICT,\n            update={\"count\": new_count, \"last_updated\": time.time()}\n        )\n\n        # Similarly, you can update guild state\n        self.update_guild_state(\n            ctx=ctx,\n            update_format=StateUpdateFormat.MERGE_DICT,\n            update={\"last_action\": f\"Increment by {ctx.payload.amount}\"}\n        )\n\n        # Respond with the new state\n        ctx.send(CountResponse(count=new_count))\n</code></pre>"},{"location":"howto/state_management.html#state-update-formats","title":"State Update Formats","text":"<p>Rustic AI supports several formats for updating state:</p> <ol> <li><code>MERGE_DICT</code>: Merges the update dictionary with the existing state</li> <li><code>REPLACE_DICT</code>: Completely replaces the state with the new dictionary</li> <li><code>JMESPATH_UPDATE</code>: Uses JMESPath expressions for more targeted updates</li> </ol> <p>Example of JMESPATH_UPDATE:</p> <pre><code># Update a nested value\nself.update_state(\n    ctx=ctx,\n    update_format=StateUpdateFormat.JMESPATH_UPDATE,\n    update={\"users[0].visits\": self._state[\"users\"][0][\"visits\"] + 1}\n)\n</code></pre>"},{"location":"howto/state_management.html#requesting-state-explicitly","title":"Requesting State Explicitly","text":"<p>You can request the latest state explicitly:</p> <pre><code>@agent.processor(clz=StateRequest)\ndef handle_state_request(self, ctx: agent.ProcessContext[StateRequest]):\n    # Request my own state\n    self.request_state(ctx)\n\n    # Request guild state\n    self.request_guild_state(ctx)\n\n    # The StateRefresherMixin will automatically update self._state and self._guild_state\n    # when the responses arrive\n</code></pre>"},{"location":"howto/state_management.html#state-lifecycle-and-persistence","title":"State Lifecycle and Persistence","text":"<p>States in Rustic AI are managed by a <code>StateManager</code> which handles:</p> <ol> <li>Persistence: Storing state in a chosen backend</li> <li>Versioning: Maintaining version history of state changes</li> <li>Concurrency: Handling concurrent updates to the same state</li> <li>Distribution: Managing state across distributed agents</li> </ol> <p>The state lifecycle flows as follows:</p> <ol> <li>Agent requests state using <code>request_state()</code></li> <li>State manager responds with current state</li> <li>Agent's <code>self._state</code> is updated via <code>StateRefresherMixin</code></li> <li>Agent performs operations using state data</li> <li>Agent requests state update using <code>update_state()</code></li> <li>State manager applies the update and returns the new state</li> <li>Agent's <code>self._state</code> is updated again</li> </ol>"},{"location":"howto/state_management.html#example-implementing-a-counter-agent","title":"Example: Implementing a Counter Agent","text":"<p>Here's a complete example of a counter agent that maintains its count in state:</p> <pre><code>from pydantic import BaseModel\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\nfrom rustic_ai.core.state.models import StateUpdateFormat\n\nclass CounterRequest(BaseModel):\n    \"\"\"Request to manipulate the counter.\"\"\"\n    action: str  # \"increment\", \"decrement\", \"reset\", \"get\"\n    amount: int = 1\n\nclass CounterResponse(BaseModel):\n    \"\"\"Response with the current counter value.\"\"\"\n    count: int\n    operation: str\n\nclass CounterAgent(Agent[BaseAgentProps]):\n    \"\"\"An agent that maintains a counter in its state.\"\"\"\n\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n        print(f\"CounterAgent initialized with ID: {self.id}\")\n\n    @agent.processor(clz=CounterRequest)\n    def process_counter_request(self, ctx: agent.ProcessContext[CounterRequest]):\n        \"\"\"Process a counter request.\"\"\"\n        # Get current count from state or default to 0\n        current_count = self._state.get(\"count\", 0)\n        action = ctx.payload.action\n        amount = ctx.payload.amount\n\n        # Determine the new count based on the action\n        if action == \"increment\":\n            new_count = current_count + amount\n            operation = f\"Incremented by {amount}\"\n        elif action == \"decrement\":\n            new_count = current_count - amount\n            operation = f\"Decremented by {amount}\"\n        elif action == \"reset\":\n            new_count = 0\n            operation = \"Reset to 0\"\n        elif action == \"get\":\n            new_count = current_count\n            operation = \"Retrieved current value\"\n        else:\n            ctx.send(CounterResponse(count=current_count, operation=\"Unknown operation\"))\n            return\n\n        # Update the state\n        self.update_state(\n            ctx=ctx,\n            update_format=StateUpdateFormat.MERGE_DICT,\n            update={\"count\": new_count}\n        )\n\n        # Also update guild state to track the last operation\n        self.update_guild_state(\n            ctx=ctx,\n            update_format=StateUpdateFormat.MERGE_DICT,\n            update={\"last_counter_operation\": operation}\n        )\n\n        # Send the response\n        ctx.send(CounterResponse(count=new_count, operation=operation))\n</code></pre>"},{"location":"howto/state_management.html#using-this-agent-in-a-guild","title":"Using This Agent in a Guild","text":"<pre><code>import asyncio\nfrom rustic_ai.core.guild.builders import AgentBuilder, GuildBuilder\nfrom rustic_ai.core.agents.testutils.probe_agent import ProbeAgent\n\nasync def main():\n    # Create and launch a guild\n    guild = GuildBuilder(\"counter_guild\", \"Counter Guild\", \"A guild with a stateful counter agent\") \\\n        .launch(organization_id=\"myawesomeorgid\", add_probe=True)\n\n    # Get the probe agent\n    probe_agent = guild.get_agent_of_type(ProbeAgent)\n\n    # Create and launch the counter agent\n    counter_agent_spec = AgentBuilder(CounterAgent) \\\n        .set_name(\"Counter\") \\\n        .set_description(\"A stateful counter agent\") \\\n        .build_spec()\n\n    guild.launch_agent(counter_agent_spec)\n\n    # Test the counter operations\n    operations = [\n        CounterRequest(action=\"increment\", amount=5),\n        CounterRequest(action=\"increment\", amount=3),\n        CounterRequest(action=\"decrement\", amount=2),\n        CounterRequest(action=\"get\")\n    ]\n\n    for op in operations:\n        print(f\"\\nSending {op.action} request...\")\n        probe_agent.publish(\"default_topic\", op)\n        await asyncio.sleep(0.5)  # Allow time for processing\n\n        # Get and clear messages\n        messages = probe_agent.get_messages()\n        for msg in messages:\n            if hasattr(msg.payload, \"count\"):\n                print(f\"Count: {msg.payload.count}, Operation: {msg.payload.operation}\")\n        probe_agent.clear_messages()\n\n    # Shutdown the guild\n    guild.shutdown()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"howto/state_management.html#best-practices-for-state-management","title":"Best Practices for State Management","text":"<ol> <li> <p>Use Helper Methods: Always use <code>update_state()</code> and <code>update_guild_state()</code> instead of directly modifying <code>self._state</code> or <code>self._guild_state</code>.</p> </li> <li> <p>Keep State Clean: Store only serializable data in state. Complex objects, file handles, or connection objects should not be stored in state.</p> </li> <li> <p>Minimize State Size: Keep state reasonably sized. Large states can impact performance, especially with distributed backends.</p> </li> <li> <p>Handle State Carefully: Consider potential race conditions when updating state based on its current value.</p> </li> <li> <p>Structure Your State: Use a consistent schema for your state to make it easier to reason about.</p> </li> <li> <p>Version Your State: Consider including a version field in your state to handle schema migrations.</p> </li> </ol>"},{"location":"howto/state_management.html#advanced-state-management","title":"Advanced State Management","text":""},{"location":"howto/state_management.html#custom-state-backends","title":"Custom State Backends","text":"<p>Rustic AI supports various state backends such as: - In-memory (default) - Redis - SQLite - Custom backends</p> <p>To configure a custom state backend, you would typically do this at the guild level:</p> <pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.core.state.manager import SQLiteStateManager\n\n# Create a guild with a custom state manager\nguild = GuildBuilder(\"my_guild\", \"My Guild\", \"A guild with custom state management\") \\\n    .set_state_manager(SQLiteStateManager(db_path=\"my_guild_state.db\")) \\\n    .launch(organization_id=\"myawesomeorgid\")\n</code></pre>"},{"location":"howto/state_management.html#state-snapshots-and-version-control","title":"State Snapshots and Version Control","text":"<p>You can manage state versions:</p> <pre><code># Get a specific version of state\nself.request_state(ctx, version=5)\n\n# Get state at a specific timestamp\nself.request_state(ctx, timestamp=1610000000000)\n</code></pre>"},{"location":"howto/state_management.html#next-steps","title":"Next Steps","text":"<p>Now that you understand state management, you might want to: - Learn about dependency injection for more complex agent configurations - Explore creating custom guild specifications - Understand testing and debugging stateful agents</p> <p>For a complete example, see the Stateful Counter Agent - <code>examples/basic_agents/stateful_counter_agent.py</code> in the examples directory. </p>"},{"location":"howto/testing_agents.html","title":"Testing Agents in Rustic AI","text":"<p>This guide explains how to effectively test agents in the Rustic AI framework. Testing is a crucial aspect of developing robust multi-agent systems, and Rustic AI provides several utilities to make testing straightforward.</p>"},{"location":"howto/testing_agents.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: - Installed Rustic AI and its dependencies - Basic understanding of agents (see Creating Your First Agent) - Familiarity with Python testing frameworks like pytest</p>"},{"location":"howto/testing_agents.html#types-of-testing","title":"Types of Testing","text":"<p>When testing Rustic AI agents, you'll typically perform several types of tests:</p> <ol> <li>Unit Tests: Testing individual agents in isolation</li> <li>Integration Tests: Testing how multiple agents interact within a guild</li> <li>System Tests: Testing complete guild behaviors and workflows</li> <li>Performance Tests: Testing agent performance under load</li> </ol> <p>This guide primarily focuses on unit testing agents in isolation, which is the most common starting point.</p>"},{"location":"howto/testing_agents.html#using-wrap_agent_for_testing","title":"Using <code>wrap_agent_for_testing</code>","text":"<p>Rustic AI provides a powerful utility <code>wrap_agent_for_testing</code> (from <code>rustic_ai.testing.helpers</code>) that simplifies agent testing by:</p> <ol> <li>Setting up the agent in a testing environment</li> <li>Managing dependencies</li> <li>Capturing outgoing messages</li> <li>Providing tools to simulate incoming messages</li> </ol> <p>Here's how to use it:</p> <pre><code>import pytest\nfrom pydantic import BaseModel\nfrom typing import List\n\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\nfrom rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.priority import Priority\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\n\n# Define message models\nclass GreetRequest(BaseModel):\n    name: str\n\nclass GreetResponse(BaseModel):\n    greeting: str\n\n# Define the agent to test\nclass GreeterAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n\n    @agent.processor(clz=GreetRequest)\n    def greet(self, ctx: agent.ProcessContext[GreetRequest]):\n        name = ctx.payload.name\n        ctx.send(GreetResponse(greeting=f\"Hello, {name}!\"))\n\n# Test fixture\n@pytest.fixture\ndef greeter_agent():\n    # Create the agent instance\n    agent = AgentBuilder(GreeterAgent)\\\n        .set_name(\"TestGreeter\")\\\n        .build()\n\n    # Set up for testing\n    id_generator = GemstoneGenerator(machine_id=1)\n    test_agent, results = wrap_agent_for_testing(agent, id_generator)\n\n    return test_agent, results, id_generator\n\n# Test function\ndef test_greeter_agent(greeter_agent):\n    agent, results, id_generator = greeter_agent\n\n    # Create a test message\n    msg = Message(\n        id_obj=id_generator.get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Test User\"),\n        payload=GreetRequest(name=\"Alice\").model_dump(),\n        format=GreetRequest.model_json_schema()[\"$id\"],\n    )\n\n    # Deliver message to the agent\n    agent._on_message(msg)\n\n    # Verify the response\n    assert len(results) == 1, \"Expected exactly one response message\"\n    response = GreetResponse.model_validate(results[0].payload)\n    assert response.greeting == \"Hello, Alice!\"\n</code></pre>"},{"location":"howto/testing_agents.html#testing-agents-with-dependencies","title":"Testing Agents with Dependencies","text":"<p>For agents that use dependency injection, you need to provide mock versions of the dependencies:</p> <pre><code>from rustic_ai.core.guild.dsl import DependencySpec\nfrom rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencyResolver\n\n# Mock database service\nclass MockDatabaseService:\n    def __init__(self):\n        self.data = {}\n\n    def save(self, key, value):\n        self.data[key] = value\n        return True\n\n    def get(self, key):\n        return self.data.get(key)\n\n# Mock database resolver\nclass MockDatabaseResolver(DependencyResolver):\n    def resolve(self, guild_id, agent_id=None):\n        return MockDatabaseService()\n\n# Test for an agent with dependencies\ndef test_agent_with_database():\n    # Create the agent instance\n    agent = AgentBuilder(DatabaseAgent)\\\n        .set_name(\"TestDatabaseAgent\")\\\n        .build()\n\n    # Set up testing with mock dependencies\n    id_generator = GemstoneGenerator(machine_id=1)\n    dependencies = {\n        \"database\": DependencySpec(\n            class_name=\"__main__.MockDatabaseResolver\",\n            properties={}\n        )\n    }\n\n    test_agent, results = wrap_agent_for_testing(\n        agent,\n        id_generator,\n        dependencies=dependencies\n    )\n\n    # Create and send test messages...\n    # ... assertions ...\n</code></pre>"},{"location":"howto/testing_agents.html#testing-stateful-agents","title":"Testing Stateful Agents","text":"<p>When testing agents that maintain state, you need to consider how state updates are processed:</p> <pre><code>def test_stateful_counter_agent():\n    # Create and wrap the agent for testing\n    agent = AgentBuilder(CounterAgent)\\\n        .set_name(\"TestCounter\")\\\n        .build()\n\n    id_generator = GemstoneGenerator(machine_id=1)\n    test_agent, results = wrap_agent_for_testing(agent, id_generator)\n\n    # The agent's _state is directly accessible in tests\n    assert test_agent._state.get(\"count\", 0) == 0\n\n    # Send increment message\n    msg = Message(\n        id_obj=id_generator.get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Test User\"),\n        payload=IncrementRequest(amount=5).model_dump(),\n        format=IncrementRequest.model_json_schema()[\"$id\"],\n    )\n\n    test_agent._on_message(msg)\n\n    # In testing, StateRefresherMixin will update _state directly\n    # So we can check it after processing\n    assert test_agent._state.get(\"count\", 0) == 5\n\n    # Also verify the response message\n    assert len(results) == 1\n    response = CounterResponse.model_validate(results[0].payload)\n    assert response.count == 5\n</code></pre>"},{"location":"howto/testing_agents.html#testing-asynchronous-handlers","title":"Testing Asynchronous Handlers","text":"<p>If your agent has asynchronous handlers, you'll need to use pytest-asyncio:</p> <pre><code>import pytest\nimport asyncio\n\n# Decorate the test function with pytest.mark.asyncio\n@pytest.mark.asyncio\nasync def test_async_agent():\n    # Set up agent for testing\n    agent, results, id_generator = setup_async_agent_for_testing()\n\n    # Send test message\n    test_message = create_test_message(id_generator)\n    agent._on_message(test_message)\n\n    # Allow time for async operations to complete\n    await asyncio.sleep(0.1)\n\n    # Now check the results\n    assert len(results) == 1\n    # ... more assertions ...\n</code></pre>"},{"location":"howto/testing_agents.html#integration-testing-with-multiple-agents","title":"Integration Testing with Multiple Agents","text":"<p>To test interactions between multiple agents, you can set up a test guild:</p> <pre><code>@pytest.fixture\ndef test_guild():\n    # Create a test guild with required agents\n    guild = GuildBuilder(\"test_guild\", \"Test Guild\", \"Guild for testing\")\\\n        .launch(add_probe=True)\n\n    # Create and launch test agents\n    agent1_spec = AgentBuilder(Agent1Class)\\\n        .set_name(\"Agent1\")\\\n        .build_spec()\n\n    agent2_spec = AgentBuilder(Agent2Class)\\\n        .set_name(\"Agent2\")\\\n        .build_spec()\n\n    guild.launch_agent(agent1_spec)\n    guild.launch_agent(agent2_spec)\n\n    # Return the guild and its probe agent\n    probe_agent = guild.get_agent_of_type(ProbeAgent)\n    yield guild, probe_agent\n\n    # Cleanup after tests\n    guild.shutdown()\n\ndef test_agent_interaction(test_guild):\n    guild, probe_agent = test_guild\n\n    # Send a message that should trigger a chain of agent interactions\n    probe_agent.publish(\"default_topic\", StartMessage(data=\"test\"))\n\n    # Allow time for message processing\n    time.sleep(0.5)\n\n    # Get messages captured by the probe\n    messages = probe_agent.get_messages()\n\n    # Verify the expected interaction happened\n    assert len(messages) &gt;= 2\n    # ... detailed assertions about the messages ...\n</code></pre>"},{"location":"howto/testing_agents.html#using-mocks-for-external-services","title":"Using Mocks for External Services","text":"<p>For agents that interact with external services, use unittest.mock to control test behavior:</p> <pre><code>from unittest.mock import patch, MagicMock\n\ndef test_agent_with_external_service():\n    # Create and wrap the agent\n    agent, results, id_generator = setup_agent_for_testing()\n\n    # Mock the external service call\n    with patch(\"external_module.service_function\") as mock_service:\n        # Configure the mock\n        mock_service.return_value = {\"result\": \"mock_data\"}\n\n        # Send test message\n        test_message = create_test_message(id_generator)\n        agent._on_message(test_message)\n\n        # Verify service was called with correct parameters\n        mock_service.assert_called_once_with(\"expected_param\")\n\n        # Verify agent response\n        assert len(results) == 1\n        assert results[0].payload[\"data\"] == \"mock_data\"\n</code></pre>"},{"location":"howto/testing_agents.html#testing-error-handling","title":"Testing Error Handling","text":"<p>It's important to test how your agents handle errors:</p> <pre><code>def test_agent_error_handling():\n    agent, results, id_generator = setup_agent_for_testing()\n\n    # Send a message that should trigger an error\n    error_message = Message(\n        id_obj=id_generator.get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Test User\"),\n        payload=InvalidRequest().model_dump(),\n        format=InvalidRequest.model_json_schema()[\"$id\"],\n    )\n\n    # The agent should handle the error and send an error message\n    agent._on_message(error_message)\n\n    # Verify error response\n    assert len(results) == 1\n    assert results[0].is_error_message\n    assert \"error\" in results[0].payload\n</code></pre>"},{"location":"howto/testing_agents.html#performance-testing","title":"Performance Testing","text":"<p>To test performance, you might want to measure how quickly an agent processes messages:</p> <pre><code>import time\n\ndef test_agent_performance():\n    agent, results, id_generator = setup_agent_for_testing()\n\n    # Generate a large number of test messages\n    messages = [create_test_message(id_generator, i) for i in range(100)]\n\n    # Measure processing time\n    start_time = time.time()\n\n    for msg in messages:\n        agent._on_message(msg)\n\n    elapsed_time = time.time() - start_time\n\n    # Assert on performance criteria\n    assert elapsed_time &lt; 1.0, f\"Processing took too long: {elapsed_time:.2f}s\"\n    assert len(results) == 100, \"Not all messages were processed\"\n</code></pre>"},{"location":"howto/testing_agents.html#debugging-tips","title":"Debugging Tips","text":"<p>When tests fail, here are some debugging strategies:</p> <ol> <li> <p>Increase Logging: Add logging in your agent's handlers to trace execution paths.</p> </li> <li> <p>Inspect Test Messages: Print the contents of <code>results</code> to see what messages the agent is actually sending.</p> </li> <li> <p>Check State: For stateful agents, examine <code>_state</code> during test execution to verify it's being updated correctly.</p> </li> <li> <p>Step Through Execution: Use a debugger to step through the agent's message processing flow.</p> </li> <li> <p>Isolate Components: If testing a complex agent, try to isolate and test individual features first.</p> </li> </ol>"},{"location":"howto/testing_agents.html#testing-best-practices","title":"Testing Best Practices","text":"<ol> <li> <p>Test Each Handler: Create separate tests for each message handler in your agent.</p> </li> <li> <p>Cover Edge Cases: Test how your agent handles unexpected inputs, missing fields, etc.</p> </li> <li> <p>Use Fixtures: Create pytest fixtures for common setup code to keep tests DRY.</p> </li> <li> <p>Test State Transitions: For stateful agents, verify that state transitions occur correctly.</p> </li> <li> <p>Mock External Dependencies: Always mock external services and APIs for deterministic tests.</p> </li> <li> <p>Test Error Cases: Ensure your agent handles errors gracefully.</p> </li> <li> <p>Keep Tests Fast: Aim for quick-running tests to maintain a fast feedback loop during development.</p> </li> </ol>"},{"location":"howto/testing_agents.html#example-a-complete-test-suite","title":"Example: A Complete Test Suite","text":"<p>Here's an example of a more complete test suite for an agent:</p> <pre><code>import pytest\nfrom pydantic import BaseModel\nfrom typing import Dict, Any\n\nfrom rustic_ai.core.guild import Agent, agent\nfrom rustic_ai.core.guild.dsl import AgentSpec, BaseAgentProps\nfrom rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.messaging.core.message import Message, AgentTag\nfrom rustic_ai.core.utils.priority import Priority\nfrom rustic_ai.core.utils.gemstone_id import GemstoneGenerator\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\n\n# Message models\nclass CalculationRequest(BaseModel):\n    operation: str  # \"add\", \"subtract\", \"multiply\", \"divide\"\n    a: float\n    b: float\n\nclass CalculationResponse(BaseModel):\n    result: float\n    operation: str\n\n# Agent implementation\nclass CalculatorAgent(Agent[BaseAgentProps]):\n    def __init__(self, agent_spec: AgentSpec[BaseAgentProps]):\n        super().__init__(agent_spec)\n\n    @agent.processor(clz=CalculationRequest)\n    def calculate(self, ctx: agent.ProcessContext[CalculationRequest]):\n        req = ctx.payload\n        result = None\n\n        if req.operation == \"add\":\n            result = req.a + req.b\n        elif req.operation == \"subtract\":\n            result = req.a - req.b\n        elif req.operation == \"multiply\":\n            result = req.a * req.b\n        elif req.operation == \"divide\":\n            if req.b == 0:\n                ctx.send_error({\"error\": \"Division by zero\"})\n                return\n            result = req.a / req.b\n        else:\n            ctx.send_error({\"error\": f\"Unknown operation: {req.operation}\"})\n            return\n\n        ctx.send(CalculationResponse(\n            result=result,\n            operation=req.operation\n        ))\n\n# Test fixtures\n@pytest.fixture\ndef calculator_setup():\n    # Create agent\n    agent = AgentBuilder(CalculatorAgent)\\\n        .set_name(\"TestCalculator\")\\\n        .build()\n\n    # Wrap for testing\n    id_generator = GemstoneGenerator(machine_id=1)\n    test_agent, results = wrap_agent_for_testing(agent, id_generator)\n\n    return test_agent, results, id_generator\n\n# Helper function to create test messages\ndef create_calc_message(id_generator, operation, a, b):\n    return Message(\n        id_obj=id_generator.get_id(Priority.NORMAL),\n        topics=[\"test_topic\"],\n        sender=AgentTag(id=\"test_sender\", name=\"Test User\"),\n        payload=CalculationRequest(operation=operation, a=a, b=b).model_dump(),\n        format=CalculationRequest.model_json_schema()[\"$id\"],\n    )\n\n# Test functions\ndef test_addition(calculator_setup):\n    agent, results, id_generator = calculator_setup\n\n    msg = create_calc_message(id_generator, \"add\", 2, 3)\n    agent._on_message(msg)\n\n    assert len(results) == 1\n    response = CalculationResponse.model_validate(results[0].payload)\n    assert response.result == 5\n    assert response.operation == \"add\"\n\ndef test_division(calculator_setup):\n    agent, results, id_generator = calculator_setup\n\n    msg = create_calc_message(id_generator, \"divide\", 10, 2)\n    agent._on_message(msg)\n\n    assert len(results) == 1\n    response = CalculationResponse.model_validate(results[0].payload)\n    assert response.result == 5\n    assert response.operation == \"divide\"\n\ndef test_division_by_zero(calculator_setup):\n    agent, results, id_generator = calculator_setup\n\n    msg = create_calc_message(id_generator, \"divide\", 10, 0)\n    agent._on_message(msg)\n\n    assert len(results) == 1\n    assert results[0].is_error_message\n    assert \"error\" in results[0].payload\n    assert \"Division by zero\" in results[0].payload[\"error\"]\n\ndef test_unknown_operation(calculator_setup):\n    agent, results, id_generator = calculator_setup\n\n    msg = create_calc_message(id_generator, \"power\", 2, 3)\n    agent._on_message(msg)\n\n    assert len(results) == 1\n    assert results[0].is_error_message\n    assert \"Unknown operation\" in results[0].payload[\"error\"]\n</code></pre>"},{"location":"howto/testing_agents.html#next-steps","title":"Next Steps","text":"<p>Now that you understand how to test agents, you might want to:</p> <ul> <li>Learn about state management in agents</li> <li>Explore dependency injection</li> <li>Understand how to create a guild with multiple agents</li> </ul> <p>For complete examples, see the unit tests in the Rustic AI framework codebase, which demonstrate best practices for testing various agent types. </p>"},{"location":"howto/writing_effective_agent_tests.html","title":"Writing Effective Tests for Rustic AI Agents","text":"<p>This guide provides practical advice and patterns for writing effective tests for Rustic AI agents. It builds on the concepts in the Testing Agents guide, with a focus on real-world testing examples from the Rustic AI codebase.</p>"},{"location":"howto/writing_effective_agent_tests.html#key-testing-patterns-in-rustic-ai","title":"Key Testing Patterns in Rustic AI","text":"<p>When examining tests across the Rustic AI ecosystem (including specialized agents like PlaywrightAgent, SERPAgent, and LiteLLMAgent), several effective patterns emerge:</p> <ol> <li>Isolation testing with <code>wrap_agent_for_testing</code></li> <li>Integration testing with probe agents</li> <li>Targeted dependency mocking for external service dependencies</li> <li>Async testing with <code>asyncio</code> for agents with asynchronous operations</li> <li>Environment setup and cleanup using pytest fixtures</li> <li>Conditional tests that skip when external service credentials aren't available</li> </ol>"},{"location":"howto/writing_effective_agent_tests.html#testing-external-service-agents","title":"Testing External Service Agents","text":"<p>Many Rustic AI agents integrate with external services like APIs, databases, or other tools. Here's a pattern for testing such agents:</p> <pre><code>import pytest\nimport os\nfrom unittest.mock import patch\n\nfrom rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.core.messaging.core.message import AgentTag, Message\nfrom rustic_ai.core.utils.priority import Priority\nfrom rustic_ai.core.utils.basic_class_utils import get_qualified_class_name\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\nfrom rustic_ai.your_module.agent import YourServiceAgent, ServiceRequest, ServiceResponse\n\nclass TestYourServiceAgent:\n    # Test with real API if credentials are available\n    @pytest.mark.skipif(\n        os.getenv(\"YOUR_API_KEY\") is None, \n        reason=\"YOUR_API_KEY environment variable not set\"\n    )\n    def test_with_real_api(self, generator):\n        # Create and wrap the agent\n        agent, results = wrap_agent_for_testing(\n            AgentBuilder(YourServiceAgent)\n            .set_name(\"TestServiceAgent\")\n            .set_id(\"test_agent\")\n            .set_description(\"Test Service Agent\")\n            .build(),\n            generator,\n        )\n\n        # Create a test request message\n        request = Message(\n            topics=\"default_topic\",\n            sender=AgentTag(id=\"testerId\", name=\"tester\"),\n            format=get_qualified_class_name(ServiceRequest),\n            payload={\"param1\": \"value1\", \"param2\": \"value2\"},\n            id_obj=generator.get_id(Priority.NORMAL),\n        )\n\n        # Send the message\n        agent._on_message(request)\n\n        # Assert on the results\n        assert len(results) == 1\n        assert results[0].in_response_to == request.id\n\n        # Validate the response\n        response = ServiceResponse.model_validate(results[0].payload)\n        assert response.success == True\n        assert response.data is not None\n\n    # Test with mocked API\n    def test_with_mocked_api(self, generator):\n        # Mock the external service\n        with patch(\"your_module.service.Client.call_api\") as mock_api:\n            # Configure the mock\n            mock_api.return_value = {\"result\": \"mocked_data\"}\n\n            # Create and wrap the agent\n            agent, results = wrap_agent_for_testing(\n                AgentBuilder(YourServiceAgent)\n                .set_name(\"TestServiceAgent\")\n                .set_id(\"test_agent\")\n                .set_description(\"Test Service Agent\")\n                .build(),\n                generator,\n            )\n\n            # Create a test request message\n            request = Message(\n                topics=\"default_topic\",\n                sender=AgentTag(id=\"testerId\", name=\"tester\"),\n                format=get_qualified_class_name(ServiceRequest),\n                payload={\"param1\": \"value1\", \"param2\": \"value2\"},\n                id_obj=generator.get_id(Priority.NORMAL),\n            )\n\n            # Send the message\n            agent._on_message(request)\n\n            # Assert the mock was called correctly\n            mock_api.assert_called_once_with(\"value1\", \"value2\")\n\n            # Assert on the results\n            assert len(results) == 1\n            response = ServiceResponse.model_validate(results[0].payload)\n            assert response.data[\"result\"] == \"mocked_data\"\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#testing-asynchronous-agents","title":"Testing Asynchronous Agents","text":"<p>For agents that perform asynchronous operations (like web scraping or API calls), your tests need to account for the asynchronous nature:</p> <pre><code>import asyncio\nimport pytest\n\nfrom rustic_ai.core.guild.builders import AgentBuilder\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\nfrom rustic_ai.your_module.agent import AsyncAgent\n\nclass TestAsyncAgent:\n    @pytest.mark.asyncio  # Requires pytest-asyncio\n    async def test_async_operation(self, generator):\n        # Create and wrap the agent\n        agent, results = wrap_agent_for_testing(\n            AgentBuilder(AsyncAgent)\n            .set_name(\"TestAsyncAgent\")\n            .set_id(\"test_agent\")\n            .build(),\n            generator,\n        )\n\n        # Create and send a test message\n        # ... code to create message ...\n        agent._on_message(message)\n\n        # Wait for async operations to complete\n        # This is important! We need to give the async operations time to run\n        tries = 0\n        while True:\n            await asyncio.sleep(0.5)  # Wait a bit\n            tries += 1\n            # Exit when we get the expected results or timeout\n            if len(results) &gt; 0 or tries &gt; 10:\n                break\n\n        # Now perform assertions\n        assert len(results) &gt; 0\n        # ... more specific assertions ...\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#testing-with-external-dependencies","title":"Testing with External Dependencies","text":"<p>Agents often depend on external services. You can inject mock or real dependencies during testing:</p> <pre><code>from rustic_ai.core.guild.agent_ext.depends.dependency_resolver import DependencySpec\nfrom rustic_ai.testing.helpers import wrap_agent_for_testing\n\ndef test_agent_with_dependencies(generator):\n    # Define test dependencies\n    filesystem = DependencySpec(\n        class_name=\"rustic_ai.core.guild.agent_ext.depends.filesystem.FileSystemResolver\",\n        properties={\n            \"path_base\": \"/tmp/test\", \n            \"protocol\": \"file\",\n            \"storage_options\": {\"auto_mkdir\": True},\n        },\n    )\n\n    # Create and wrap the agent with dependencies\n    agent, results = wrap_agent_for_testing(\n        AgentBuilder(YourAgent)\n        .set_id(\"test_agent\")\n        .set_name(\"TestAgent\")\n        .build(),\n        generator,\n        {\"filesystem\": filesystem},  # Inject dependencies here\n    )\n\n    # Create and send a test message\n    # ... code to create and send message ...\n\n    # You can even access and test the injected dependency\n    fs = filesystem.to_resolver().resolve(agent.guild_id, \"GUILD_GLOBAL\")\n    assert fs.exists(some_path)\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#testing-agent-error-handling","title":"Testing Agent Error Handling","text":"<p>Good agent tests not only verify correct behavior but also proper error handling:</p> <pre><code>def test_error_handling(generator):\n    # Create and wrap the agent\n    agent, results = wrap_agent_for_testing(\n        AgentBuilder(YourAgent)\n        .set_name(\"TestAgent\")\n        .set_id(\"test_agent\")\n        .build(),\n        generator,\n    )\n\n    # 1. Test with invalid input\n    invalid_message = create_message_with_invalid_payload()\n    agent._on_message(invalid_message)\n\n    # Verify agent produces appropriate error response\n    assert len(results) == 1\n    assert results[0].is_error_message\n    assert \"Invalid input\" in results[0].payload.get(\"error\", \"\")\n\n    # 2. Test when a dependency fails\n    with patch(\"some_dependency.method\") as mock_dep:\n        mock_dep.side_effect = Exception(\"Dependency failed\")\n\n        results.clear()  # Clear previous results\n        valid_message = create_valid_message()\n        agent._on_message(valid_message)\n\n        # Verify agent handles dependency failure gracefully\n        assert len(results) == 1\n        assert results[0].is_error_message\n        assert \"Dependency failed\" in results[0].payload.get(\"error\", \"\")\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#integration-testing-with-probe-agent","title":"Integration Testing with Probe Agent","text":"<p>The <code>ProbeAgent</code> is a powerful tool for testing agent interactions within a guild:</p> <pre><code>import pytest\nimport time\n\nfrom rustic_ai.core.agents.testutils.probe_agent import ProbeAgent\nfrom rustic_ai.core.guild.builders import AgentBuilder, GuildBuilder\n\n@pytest.fixture\ndef test_guild():\n    # Create a guild for testing\n    guild = GuildBuilder(\"test_guild\", \"Test Guild\", \"Guild for testing\").launch(add_probe=True)\n\n    # Add your test agents\n    agent1_spec = AgentBuilder(Agent1Class).set_name(\"Agent1\").build_spec()\n    agent2_spec = AgentBuilder(Agent2Class).set_name(\"Agent2\").build_spec()\n\n    guild.launch_agent(agent1_spec)\n    guild.launch_agent(agent2_spec)\n\n    # Get the probe agent\n    probe_agent = guild.get_agent_of_type(ProbeAgent)\n\n    # Return guild and probe agent\n    try:\n        yield guild, probe_agent\n    finally:\n        # Always clean up\n        guild.shutdown()\n\ndef test_agent_interaction(test_guild):\n    guild, probe_agent = test_guild\n\n    # Send an initial message to trigger interaction\n    probe_agent.publish(\"default_topic\", StartMessage(data=\"test\"))\n\n    # Wait for messages to be processed\n    time.sleep(0.01)\n\n    # Get all messages captured by the probe\n    messages = probe_agent.get_messages()\n\n    # Verify the correct sequence of interactions\n    assert len(messages) &gt;= 2\n    assert messages[0].sender.id == \"agent1\"\n    assert messages[1].sender.id == \"agent2\"\n    # ... more detailed assertions about message content ...\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#testing-llm-based-agents","title":"Testing LLM-based Agents","text":"<p>For agents that use language models (like LiteLLMAgent), you can use the mock_response pattern:</p> <pre><code>from rustic_ai.core.guild.agent_ext.depends.llm.models import (\n    ChatCompletionRequest, SystemMessage, UserMessage\n)\n\ndef test_llm_agent(probe_agent, guild):\n    # Create and add the LLM agent to the guild\n    agent = AgentBuilder(LLMAgent) \\\n        .set_name(\"Test LLM Agent\") \\\n        .set_id(\"llm_agent\") \\\n        .build()\n\n    guild._add_local_agent(agent)\n\n    # Create a request with a mock response to avoid real API calls\n    chat_completion_request = ChatCompletionRequest(\n        messages=[UserMessage(content=\"What is the capital of France?\")],\n        mock_response=\"The capital of France is Paris.\",  # Mock response\n    )\n\n    # Send the request\n    probe_agent.publish_dict(\n        guild.DEFAULT_TOPIC,\n        chat_completion_request,\n        format=ChatCompletionRequest,\n    )\n\n    time.sleep(0.01)  # Wait for processing\n\n    # Check the results\n    messages = probe_agent.get_messages()\n    assert len(messages) == 1\n    assert \"Paris\" in messages[0].payload[\"choices\"][0][\"message\"][\"content\"]\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#common-testing-pitfalls-and-solutions","title":"Common Testing Pitfalls and Solutions","text":""},{"location":"howto/writing_effective_agent_tests.html#1-race-conditions-in-async-tests","title":"1. Race Conditions in Async Tests","text":"<p>Problem: Tests sometimes pass, sometimes fail due to timing issues.</p> <p>Solution: Use <code>asyncio.sleep()</code> with retries to wait for operations to complete:</p> <pre><code># Instead of a fixed sleep time:\ntries = 0\nwhile True:\n    await asyncio.sleep(0.2)\n    tries += 1\n    # Exit condition based on expected state\n    if len(results) &gt; 0 or tries &gt; 10:  # Timeout after 10 tries\n        break\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#2-resource-cleanup-in-tests","title":"2. Resource Cleanup in Tests","text":"<p>Problem: Tests leave behind resources that affect other tests.</p> <p>Solution: Use pytest fixtures with cleanup:</p> <pre><code>@pytest.fixture\ndef resource_fixture():\n    # Setup\n    resource = create_resource()\n\n    yield resource  # Provide the resource to the test\n\n    # Cleanup (always runs, even if test fails)\n    resource.cleanup()\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#3-external-service-dependency","title":"3. External Service Dependency","text":"<p>Problem: Tests fail when run without access to external services.</p> <p>Solution: Use <code>pytest.mark.skipif</code> to conditionally skip tests:</p> <pre><code>@pytest.mark.skipif(\n    os.getenv(\"REQUIRED_API_KEY\") is None,\n    reason=\"API key not available\"\n)\ndef test_with_external_service():\n    # Test that requires external service\n</code></pre>"},{"location":"howto/writing_effective_agent_tests.html#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li> <p>Parametrize Common Tests: Use <code>@pytest.mark.parametrize</code> to run the same test with different inputs.</p> </li> <li> <p>Keep Dependencies Consistent: Use the same dependency structure in tests as in production code.</p> </li> <li> <p>Test Failure Modes: Don't just test the happy path; test how your agent handles errors.</p> </li> <li> <p>Mock External Services: Use <code>unittest.mock.patch</code> to replace external API calls.</p> </li> <li> <p>Combine Unit and Integration Tests: Test components in isolation first, then together.</p> </li> <li> <p>Use Descriptive Test Names: Make your test names describe the behavior being tested.</p> </li> <li> <p>Isolate Test State: Ensure tests don't interfere with each other's state.</p> </li> </ol>"},{"location":"howto/writing_effective_agent_tests.html#real-world-examples-from-rustic-ai","title":"Real-World Examples from Rustic AI","text":"<p>To see these patterns in action, examine the test suites for these agents:</p> <ol> <li>PlaywrightAgent: Tests asynchronous web scraping with injected filesystem dependency</li> <li>SERPAgent: Tests API calls with both real and mocked services</li> <li>LiteLLMAgent: Tests LLM integration with mock responses</li> </ol> <p>These examples demonstrate how to effectively test agents with different requirements and complexity levels.</p>"},{"location":"howto/writing_effective_agent_tests.html#conclusion","title":"Conclusion","text":"<p>Effective testing is crucial for building reliable agent-based systems. By following these patterns and guidelines, you can create tests that validate your agents' behavior, handle edge cases, and catch regressions early. Remember that good tests not only verify that the right thing happens when the right input is provided, but also that the right thing happens when something goes wrong. </p>"},{"location":"ray/index.html","title":"Ray Integration","text":"<p>This section contains documentation for Rustic AI's Ray integration, which provides distributed execution capabilities for scalable agent systems.</p>"},{"location":"ray/index.html#overview","title":"Overview","text":"<p>Ray is a unified framework for scaling AI and Python applications. The Rustic AI Ray integration allows you to:</p> <ul> <li>Scale your agent systems across multiple machines</li> <li>Distribute agent workloads efficiently</li> <li>Manage resources adaptively based on demand</li> <li>Build high-performance, resilient multi-agent applications</li> </ul>"},{"location":"ray/index.html#features","title":"Features","text":"<ul> <li>Distributed Execution Engine - Run agents across a Ray cluster</li> <li>Resource Management - Allocate CPU, GPU, and memory resources intelligently</li> <li>Fault Tolerance - Recover from node failures automatically</li> <li>Dynamic Scaling - Add or remove compute resources as needed</li> </ul>"},{"location":"ray/index.html#getting-started","title":"Getting Started","text":"<p>To use the Ray integration, you'll need:</p> <ol> <li>Ray installed in your environment</li> <li>A Ray cluster (can be local or distributed)</li> <li>Rustic AI core framework configured properly</li> </ol>"},{"location":"ray/index.html#basic-example","title":"Basic Example","text":"<pre><code>from rustic_ai.core.guild.builders import GuildBuilder\nfrom rustic_ai.ray.execution_engine import RayExecutionEngine\n\n# Configure a guild to use Ray for execution\nguild_builder = GuildBuilder(guild_name=\"DistributedGuild\") \\\n    .set_description(\"A guild using Ray for distributed execution\") \\\n    .set_execution_engine(\"rustic_ai.ray.execution_engine.RayExecutionEngine\") \\\n    .set_execution_engine_config({\n        \"address\": \"auto\",  # Connect to existing Ray cluster\n        \"resources_per_agent\": {\"CPU\": 1, \"GPU\": 0.1}\n    })\n\n# Add agents and launch\n# ...\n</code></pre>"},{"location":"ray/index.html#documentation","title":"Documentation","text":"<p>Comprehensive documentation for all Ray integration features is currently under development. Please check back for updates as we expand this section. </p>"},{"location":"showcase/index.html","title":"Rustic AI Showcase","text":"<p>Welcome to the Rustic AI Showcase section. This area features example applications, demos, and case studies that highlight the capabilities and potential use cases of the Rustic AI framework.</p>"},{"location":"showcase/index.html#featured-examples","title":"Featured Examples","text":""},{"location":"showcase/index.html#conversational-assistants","title":"Conversational Assistants","text":"<p>Build sophisticated conversational agents that can maintain context, access tools, and provide helpful responses to users.</p>"},{"location":"showcase/index.html#research-automation","title":"Research Automation","text":"<p>Create agent systems that can search, summarize, and synthesize information from multiple sources to assist with research tasks.</p>"},{"location":"showcase/index.html#content-generation","title":"Content Generation","text":"<p>Implement agent systems for generating various forms of content, from written articles and reports to images and multimedia.</p>"},{"location":"showcase/index.html#data-analysis-pipelines","title":"Data Analysis Pipelines","text":"<p>Design multi-agent systems that can extract, process, analyze, and visualize data from diverse sources.</p>"},{"location":"showcase/index.html#getting-started-with-examples","title":"Getting Started with Examples","text":"<p>Each example in the showcase includes:</p> <ul> <li>Complete source code</li> <li>Step-by-step explanations</li> <li>Architecture diagrams</li> <li>Usage instructions</li> <li>Customization guidelines</li> </ul> <p>To run the examples locally, clone the Rustic AI repository and follow the setup instructions included with each example.</p>"},{"location":"showcase/index.html#contributing-to-the-showcase","title":"Contributing to the Showcase","text":"<p>We welcome contributions to the Rustic AI Showcase! If you've built an interesting application or system using Rustic AI, consider sharing it with the community.</p> <p>Refer to the contribution guidelines for information on how to submit your example to the showcase. </p>"}]}